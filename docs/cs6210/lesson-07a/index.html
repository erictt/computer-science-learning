<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/favicon.png" />
    

    <title>
        
          Eric&#39;s CS Notes
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    
<link rel="stylesheet" href="/css/book.css">

    
<script src="/js/book.js"></script>


    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.css">
    
    <!-- katex css -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous">

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/">
    <img src="/favicon.png">
    <span>ERIC&#39;S CS NOTES</span>
  </a>
</div>

    <div class="book-menu">
  <!--
## Introduction to Probability

* [Unit 1: Probability models and axioms](/introduction-to-probability/unit-1/index.html)
* [Unit 2: Conditioning and independence](/introduction-to-probability/unit-2/index.html)
* [Unit 3: Counting](/introduction-to-probability/unit-3/index.html)
* [Unit 4: Discrete random variables](/introduction-to-probability/unit-4/index.html)
* [Unit 5: Continuous random variables](/introduction-to-probability/unit-5/index.html)
* [Unit 6: Further topics on random variables](/introduction-to-probability/unit-6/index.html)
* [Unit 7: Bayesian inference](/introduction-to-probability/unit-7/index.html)
* [Unit 8: Limit theorems and classical statistics](/introduction-to-probability/unit-8/index.html)
* [Unit 9: Bernoulli and Poisson processes](/introduction-to-probability/unit-9/index.html)
* [Unit 10: Markov chains](/introduction-to-probability/unit-10/index.html)
-->
<!--
## Multivariable Calculus

* [Unit 1: Thinking about multivariable functions](/multivariable-calculus/unit-1/index.html)
* [Unit 2: Derivatives of multivariable functions](/multivariable-calculus/unit-2/index.html)

* [Unit 3: Applications of multivariable derivatives](/multivariable-calculus/unit-3/index.html)
* [Unit 4: Integrating multivariable functions](/multivariable-calculus/unit-4/index.html)
* [Unit 5: Green's, Stokes', and the divergence theorems](/multivariable-calculus/unit-5/index.html)
-->
<h2 id="cs6210-advanced-operating-systems"><a class="markdownIt-Anchor" href="#cs6210-advanced-operating-systems"></a> CS6210: Advanced Operating Systems</h2>
<ul>
<li><a href="/cs6210/lesson-02/index.html">Lesson 2: OS Structure</a></li>
<li><a href="/cs6210/lesson-03/index.html">Lesson 3: Virtualization</a></li>
<li><a href="/cs6210/lesson-04a/index.html">Lesson 4: Parallel Systems - Part 1</a></li>
<li><a href="/cs6210/lesson-04b/index.html">Lesson 4: Parallel Systems - Part 2</a></li>
<li><a href="/cs6210/lesson-05/index.html">Lesson 5: Distributed Systems</a></li>
<li><a href="/cs6210/lesson-06/index.html">Lesson 6: Distributed Objects and Middleware</a></li>
<li><a href="/cs6210/lesson-07a/index.html">Lesson 7: Distributed Subsystems - GMS</a></li>
<li><a href="/cs6210/lesson-07b/index.html">Lesson 7: Distributed Subsystems - DSM</a></li>
<li><a href="/cs6210/lesson-07c/index.html">Lesson 7: Distributed Subsystems - DFS</a></li>
<li><a href="/cs6210/lesson-09/index.html">Lesson 9: Internet Computing</a></li>
</ul>
<!--
* [Lesson 10: RT and Multimedia](/cs6210/lesson-10/index.html)
* [Lesson 8: Failures and Recovery](/cs6210/lesson-08/index.html)
* [Lesson 11: Security](/cs6210/lesson-11/index.html)
-->
<h2 id="cs6250-computer-networks"><a class="markdownIt-Anchor" href="#cs6250-computer-networks"></a> CS6250 Computer Networks</h2>
<ul>
<li><a href="/cs6250/week-1-internet-architecture/index.html">Week 1 - Internet Architecture</a></li>
<li><a href="/cs6250/week-2-transport-and-application-layers/index.html">Week 2 - Transport and Application Layers</a></li>
<li><a href="/cs6250/week-3-intradomain-routing/index.html">Week 3 - Intradomain Routing</a></li>
<li><a href="/cs6250/week-4-as-relationships-and-interdomain-routing/index.html">Week 4 - AS Relationships and Interdomain Routing</a></li>
<li><a href="/cs6250/week-5-router-design-and-algorithems-part-1/index.html">Week 5 - Router Design and Algorithms (Part 1)</a></li>
<li><a href="/cs6250/week-6-router-design-and-algorithems-part-2/index.html">Week 6 - Router Design and Algorithms (Part 2)</a></li>
<li><a href="/cs6250/week-7-software-defined-networking-part-1/index.html">Week 7 - Software Defined Networking (Part 1)</a></li>
<li><a href="/cs6250/week-8-software-defined-networking-part-2/index.html">Week 8 - Software Defined Networking (Part 2)</a></li>
<li><a href="/cs6250/week-9-internet-security/index.html">Week 9 - Internet Security</a></li>
<li><a href="/cs6250/week-10-internet-surveillance-and-censorship/index.html">Week 10 - Internet Surveillance and Censorship</a></li>
<li><a href="/cs6250/week-11-applications-video/index.html">Week 11 - Applications Videos</a></li>
<li><a href="/cs6250/week-12-applications-cdns-and-overlay-networks/index.html">Week 12 - Applications CDNs and Overlay Networks</a></li>
</ul>
<h2 id="cs6200-graduate-introduction-to-operating-systems"><a class="markdownIt-Anchor" href="#cs6200-graduate-introduction-to-operating-systems"></a> CS6200 Graduate Introduction to Operating Systems</h2>
<ul>
<li><a href="/cs6200/p1-preparation/index.html">P0 - Preparation</a></li>
<li><a href="/cs6200/p1l2-introduction/index.html">P1L2 - Introduction</a></li>
<li><a href="/cs6200/p2l1-processes-and-process-management/index.html">P2L1 - Processes and Process Management</a></li>
<li><a href="/cs6200/p2l2-threads-and-concurrency/index.html">P2L2 - Threads and Concurrency</a></li>
<li><a href="/cs6200/p2l3-pthread/index.html">P2L3 - PThread</a></li>
<li><a href="/cs6200/p2l4-thread-design-consideration/index.html">P2L4 - Thread Design Considerations</a></li>
<li><a href="/cs6200/p2l5-thread-performance-consideration/index.html">P2L5 - Thread Performance Considerations</a></li>
<li><a href="/cs6200/p3l1-scheduling/index.html">P3L1 - Scheduling</a></li>
<li><a href="/cs6200/p3l2-memory-management/index.html">P3L2 - Memory Management</a></li>
<li><a href="/cs6200/p3l3-inter-process-communication/index.html">P3L3 - Inter-Process Communication</a></li>
<li><a href="/cs6200/p3l4-synchronization-constructs/index.html">P3L4 - Synchronization Constructs</a></li>
<li><a href="/cs6200/p3l5-io-management/index.html">P3L5 - I/O Management</a></li>
<li><a href="/cs6200/p3l6-virtualization/index.html">P3L6 - Virtualization</a></li>
</ul>
<!--
* [P4L1 - Remote Procedure Calls](/cs6200/p4l1-remote-procedure-calls/index.html) 
* [P4L2 - Distributed File Systems](/cs6200/p4l2-distributed-file-systems/index.html) 
* [P4L3 - Distributed Shared Memory](/cs6200/p4l3-distributed-shared-memory/index.html) 
* [P4L4 - Datacenter Technologies](/cs6200/p4l4-datacenter-technologies/index.html) 
-->
<h2 id="algorithms-part-ii"><a class="markdownIt-Anchor" href="#algorithms-part-ii"></a> Algorithms: Part II</h2>
<ul>
<li><a href="/algorithms-2/week-1/index.html">Week 1 - Undirected Graph &amp; Directed Graph</a></li>
<li><a href="/algorithms-2/week-2/index.html">Week 2 - Minimum Spanning Trees &amp; Shortest Path</a></li>
<li><a href="/algorithms-2/week-3/index.html">Week 3 - Maximum Flow and Minimum Cut &amp; String Sort</a></li>
<li><a href="/algorithms-2/week-4/index.html">Week 4 - Tries &amp; Substring Search</a></li>
<li><a href="/algorithms-2/week-5/index.html">Week 5 - Regular Expressions</a></li>
<li><a href="/algorithms-2/week-6/index.html">Week 6 - Reductions</a></li>
</ul>
<h2 id="algorithms-part-i"><a class="markdownIt-Anchor" href="#algorithms-part-i"></a> Algorithms: Part I</h2>
<ul>
<li><a href="/algorithms-1/week-1/index.html">Week 1 - Union-Find &amp; Analysis of Algorithms</a></li>
<li><a href="/algorithms-1/week-2/index.html">Week 2 - Stacks and Queues &amp; Elementary Sorts</a></li>
<li><a href="/algorithms-1/week-3/index.html">Week 3 - Mergesort &amp; Quicksort</a></li>
<li><a href="/algorithms-1/week-4/index.html">Week 4 - Priority Queues &amp; Elementary Symbols</a></li>
<li><a href="/algorithms-1/week-5/index.html">Week 5 - Balanced Search Trees</a></li>
<li><a href="/algorithms-1/week-6/index.html">Week 6 - Hash Tables</a></li>
</ul>
<h2 id="introduction-to-software-design-and-architecture"><a class="markdownIt-Anchor" href="#introduction-to-software-design-and-architecture"></a> Introduction to Software Design and Architecture</h2>
<ul>
<li><a href="/introduction-to-software-design-and-architecture/design-pattern/index.html">Design Pattern</a></li>
</ul>
<h2 id="calculus-two-sequences-and-series"><a class="markdownIt-Anchor" href="#calculus-two-sequences-and-series"></a> Calculus Two: Sequences and Series</h2>
<ul>
<li><a href="/calculus-two/week-1/index.html">Week 1 - Sequences</a></li>
<li><a href="/calculus-two/week-2/index.html">Week 2 - Series</a></li>
<li><a href="/calculus-two/week-3/index.html">Week 3 - Convergence Tests</a></li>
<li><a href="/calculus-two/week-4/index.html">Week 4 - Alternating Series</a></li>
<li><a href="/calculus-two/week-5/index.html">Week 5 - Power Series</a></li>
<li><a href="/calculus-two/week-6/index.html">Week 6 - Taylor Series</a></li>
</ul>
<h2 id="laff-linear-algebra"><a class="markdownIt-Anchor" href="#laff-linear-algebra"></a> LAFF Linear Algebra</h2>
<ul>
<li><a href="/laff-linear-algebra/week-1/index.html">Week 1 - Vectors in Linear Algebra</a></li>
<li><a href="/laff-linear-algebra/week-2/index.html">Week 2 - Linear Transformations and Matrices</a></li>
<li><a href="/laff-linear-algebra/week-3/index.html">Week 3 - Matrix-Vector Operations</a></li>
<li><a href="/laff-linear-algebra/week-4/index.html">Week 4 - Matrix-Vector to Matrix-Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-5/index.html">Week 5 - Matrix- Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-6/index.html">Week 6 - Gaussian Elimination</a></li>
<li><a href="/laff-linear-algebra/week-7/index.html">Week 7 - More Gaussian Elimination and Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-8/index.html">Week 8 - More on Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-9/index.html">Week 9 - Vector Spaces</a></li>
<li><a href="/laff-linear-algebra/week-10/index.html">Week 10 - Vector Spaces, Orthogonality, and Linear Least-Squares</a></li>
<li><a href="/laff-linear-algebra/week-11/index.html">Week 11 - Orthogonal Projection, Low Rank Approximation, and Orthogonal Bases</a></li>
<li><a href="/laff-linear-algebra/week-12/index.html">Week 12 - Eigenvalues and Eigenvectors</a></li>
</ul>
<h2 id="stanford-machine-learning"><a class="markdownIt-Anchor" href="#stanford-machine-learning"></a> Stanford Machine Learning</h2>
<ul>
<li><a href="/stanford-machine-learning/week-1/index.html">Week 1 - Introduction</a></li>
<li><a href="/stanford-machine-learning/week-2/index.html">Week 2 - Linear Regression with Multiple Variables</a></li>
<li><a href="/stanford-machine-learning/week-3/index.html">Week 3 - Logistic Regression &amp; Regularization</a></li>
<li><a href="/stanford-machine-learning/week-4/index.html">Week 4 - Neural Networks: Representation</a></li>
<li><a href="/stanford-machine-learning/week-5/index.html">Week 5 - Neural Networks: Learning</a></li>
<li><a href="/stanford-machine-learning/week-6a/index.html">Week 6a - Advice for Applying Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-6b/index.html">Week 6b - Machine Learning System Design</a></li>
<li><a href="/stanford-machine-learning/week-7/index.html">Week 7 - Support Vector Machines</a></li>
<li><a href="/stanford-machine-learning/week-8/index.html">Week 8 - Unsupervised Learning &amp; Dimensionality Reduction</a></li>
<li><a href="/stanford-machine-learning/week-9a/index.html">Week 9a - Anomaly Detection</a></li>
<li><a href="/stanford-machine-learning/week-9b/index.html">Week 9b - Recommender Systems</a></li>
<li><a href="/stanford-machine-learning/week-10/index.html">Week 10 - Large Scale Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-11/index.html">Week 11 - Application Example: Photo OCR</a></li>
</ul>
<h2 id="calculus-one"><a class="markdownIt-Anchor" href="#calculus-one"></a> Calculus One</h2>
<ul>
<li><a href="/calculus-one/week-2-3/index.html">Week 2-3 - Functions &amp; Limits</a></li>
<li><a href="/calculus-one/week-4/index.html">Week 4 - The Beginning of Derivatives</a></li>
<li><a href="/calculus-one/week-5/index.html">Week 5 - Techniques of Differentiation</a></li>
<li><a href="/calculus-one/week-6/index.html">Week 6 - Chain Rule</a></li>
<li><a href="/calculus-one/week-7/index.html">Week 7 - Derivatives of Trigonometric Functions</a></li>
<li><a href="/calculus-one/week-8/index.html">Week 8 - Derivatives in the Real World</a></li>
<li><a href="/calculus-one/week-9/index.html">Week 9 - Optimization</a></li>
<li><a href="/calculus-one/week-10/index.html">Week 10 - Linear Approximation</a></li>
<li><a href="/calculus-one/week-11-12/index.html">Week 11-12 - Antidifferentiation &amp; Integration</a></li>
<li><a href="/calculus-one/week-13/index.html">Week 13 - Fundamental Theorem of Calculus</a></li>
<li><a href="/calculus-one/week-14/index.html">Week 14 - Substitution Rule</a></li>
<li><a href="/calculus-one/week-15/index.html">Week 15 - Techniques of Integration</a></li>
<li><a href="/calculus-one/week-16/index.html">Week 16 - Applications of Integration</a></li>
</ul>
<h2 id="computational-thinking"><a class="markdownIt-Anchor" href="#computational-thinking"></a> Computational Thinking</h2>
<ul>
<li><a href="/computational-thinking/lecture-1/index.html">Lecture 1 - Optimization and Knapsack Problem</a></li>
<li><a href="/computational-thinking/lecture-2/index.html">Lecture 2 - Decision Trees and Dynamic Programming</a>
<ul>
<li><a href="/computational-thinking/lecture-2-powerset/index.html">Exercise: Power Set Function</a></li>
</ul>
</li>
<li><a href="/computational-thinking/lecture-3/index.html">Lecture 3 - Graphs</a></li>
<li><a href="/computational-thinking/lecture-4-5/index.html">Lecture 4-5 - Plotting</a></li>
<li><a href="/computational-thinking/lecture-6-7/index.html">Lecture 6-7 - Stochastic Programs &amp; Inferential Statistics</a></li>
<li><a href="/computational-thinking/lecture-8/index.html">Lecture 8 - Monte Carlo Simulation</a></li>
<li><a href="/computational-thinking/lecture-9/index.html">Lecture 9 - Sampling and Standard Error</a></li>
<li><a href="/computational-thinking/lecture-10-11/index.html">Lecture 10-11 - Experimental Data</a></li>
<li><a href="/computational-thinking/lecture-12/index.html">Lecture 12 - Machine Learning</a></li>
<li><a href="/computational-thinking/lecture-13/index.html">Lecture 13 - Statistical Abuses</a></li>
</ul>
<h2 id="effective-thinking-through-mathematics"><a class="markdownIt-Anchor" href="#effective-thinking-through-mathematics"></a> Effective Thinking Through Mathematics</h2>
<ul>
<li><a href="/effective-thinking-through-mathematics/note/index.html">Note</a></li>
<li><a href="/effective-thinking-through-mathematics/week-4-telling-the-story-of-infinity/index.html">Week 4 (/Telling the Story of Infinity)</a></li>
<li><a href="/effective-thinking-through-mathematics/week-5-telling-the-story-of-the-euler-circuit-theorem/index.html">Week 5 (/Telling the Story of Euler Circuit Theorem)</a></li>
</ul>
<h2 id="cs50-introduction-to-computer-science"><a class="markdownIt-Anchor" href="#cs50-introduction-to-computer-science"></a> CS50 Introduction to Computer Science</h2>
<ul>
<li><a href="/cs50/week-1/index.html">Week 1 - C</a></li>
<li><a href="/cs50/week-2/index.html">Week 2 - Arrays</a></li>
<li><a href="/cs50/week-3/index.html">Week 3 - Algorithms</a></li>
<li><a href="/cs50/week-4/index.html">Week 4 - Memory</a></li>
<li><a href="/cs50/week-5/index.html">Week 5 - Data Structures</a></li>
<li><a href="/cs50/week-6/index.html">Week 6 - HTTP</a></li>
<li><a href="/cs50/week-7-10/index.html">Week 7-10 - Machine Learning/Python/SQL/Javascript</a></li>
</ul>
<h2 id="others"><a class="markdownIt-Anchor" href="#others"></a> Others</h2>
<ul>
<li><a href="/symbols/index.html">Symbols of Mathematics</a></li>
<li><a href="/glossary/index.html">Glossary</a></li>
</ul>
<h2 id="about-me"><a class="markdownIt-Anchor" href="#about-me"></a> <a target="_blank" rel="noopener" href="https://ericy.me/about/">About Me</a></h2>

</div>


<script src="/js/book-menu.js"></script>

  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1 id="lesson-7-distributed-subsystems-l0-global-memory-systemsgms"><a class="markdownIt-Anchor" href="#lesson-7-distributed-subsystems-l0-global-memory-systemsgms"></a> Lesson 7: Distributed Subsystems L0- Global Memory Systems(GMS)</h1>
<ul>
<li>How can we use peer memory for paging across LAN?</li>
</ul>
<p>In a working set of multiple machines connected to LAN, some machines have more memory presure than the others. To utilize the memory from other machines to alleviate the busy ones is the main goal of GMS. The assumption is accessing the local disks take much more time than using the memory for paging accross the network. (Modern LANs can provide Gigabit or even 10 Gigabit connectivity between nodes, which can make it faster to access data from remote nodes than accessing data from a local disk.) In addition, we want to use idl cluster memory for other nodes in the network.</p>
<p>Comparing to tradition memory management: virtrual address -&gt; physical address or disk, GMS trades network communication for disk I/O, changes the mapping to: virtrual address -&gt; physical address or cluster memory or disk.</p>
<p>GMS only works for read across the network. The only pages that been paged out to the cluster memories are not dirty. GMS only serves as another level in the memory hierachy. The disk always has all of the copies of the pges.</p>
<h2 id="basics"><a class="markdownIt-Anchor" href="#basics"></a> Basics</h2>
<ul>
<li>In GSM, “cache” refers to physical memory, specifically dynamic random access memory (DRAM).</li>
<li>Physical memory at each node is split into “local” (working set of currently executing processes) and “global” (community service for holding swapped out pages from fellow nodes).</li>
<li>The split between local and global is dynamic and responds to memory pressure.</li>
</ul>
<ul>
<li>Pages can be private or shared, and shared pages are the concern of the application for maintaining the <strong>page coherence</strong>.
<ul>
<li>The pages in “global” are always private to some processes.</li>
<li>The pages in “local” can be private or shared among multiple processes.</li>
</ul>
</li>
</ul>
<ul>
<li>GSM serves as a paging facility for remote paging and uses a page replacement algorithm (typically LRU) to manage memory.</li>
<li>One of the key technical contributions of GSM is managing age information to pick the globally oldest page for replacement in the community service for handling page faults.</li>
</ul>
<h2 id="handling-page-faults"><a class="markdownIt-Anchor" href="#handling-page-faults"></a> Handling Page Faults</h2>
<h3 id="case-1"><a class="markdownIt-Anchor" href="#case-1"></a> Case 1</h3>
<img src="https://i.imgur.com/JADVQuh.png" style="width: 800px" />
- Physical memory on each host is divided into local and global parts.
- Page fault handling in GMS involves finding if the page is in the global cache of another node in the cluster.
- If the page is found in another node's global cache, that node sends the page to the requesting node.
- The requesting node's local allocation of physical memory increases by one.
- To make space for the new page, the requesting node sends the oldest page from its global cache to the node that had the requested page in its cache.
- The global allocation (community service part) of the requesting node decreases by one, while the global allocation of the sending node remains unchanged.
<h3 id="case-2"><a class="markdownIt-Anchor" href="#case-2"></a> Case 2</h3>
<img src="https://i.imgur.com/XSHGtGw.png" style="width: 800px" />
<ul>
<li>In this case, there is no community service happening on host P due to high memory pressure.</li>
<li>If there is another page fault, the only option is to throw out some page from its current working set to make room for the missing page.</li>
<li>The victim candidate for the page is chosen from the local part of host P.</li>
<li>The oldest page from the local part of host P is sent out as a victim.</li>
<li>The distribution of local and global on host P remains unchanged, as global is already zero.</li>
<li>There is no change on host Q in terms of the split between local and global.</li>
</ul>
<h3 id="case-3"><a class="markdownIt-Anchor" href="#case-3"></a> Case 3</h3>
<img src="https://i.imgur.com/30dNwHF.png" style="width: 800px" />
- In this case, the faulting page is not available in the cluster memories and needs to be fetched from disk.
- The local allocation of physical memory on host P increases by one as the working set grows due to the page fault.
- To make room for the new page, the global allocation on host P decreases by one and the oldest page from the global cache is sent to a peer memory in the cluster.
- The peer memory that receives the replacement page could be either in the local or global part of the host.
- If the oldest page on the peer memory is in the global cache, it is discarded. If it is in the local part, it could be dirty and needs to be written back to disk.
- The local allocation of physical memory on the peer memory could decrease if the globally oldest page is in the local part and can be thrown out.
- The local and global allocation on host P changes as described above, while the allocation on the peer memory could remain unchanged or decrease depending on the globally oldest page.
<h3 id="case-4"><a class="markdownIt-Anchor" href="#case-4"></a> Case 4</h3>
<img src="https://i.imgur.com/ONGX0Ip.png" style="width: 800px" />
<ul>
<li>In this case, a page is actively shared between host P and host Q.</li>
<li>When a page fault occurs on host P for page X, GMS finds that page X is in the local cache of host Q and makes a copy of it into the local cache of host P.</li>
<li>The working set on host P increases, so the local allocation of physical memory on host P goes up by one and the global allocation goes down by one.</li>
<li>GMS picks an arbitrary page from the global cache on host P to send to the host R that has the globally oldest page.</li>
<li>The total memory pressure in the cluster goes up by one, so host R must pick an LRU candidate from its physical memory to send to the disk and make room for the incoming page from host P.</li>
<li>If the LRU candidate comes from the local cache of host R, the working set on host R decreases and the local allocation goes down by one, while the global allocation goes up by one.</li>
<li>The active sharing of page X between host P and host Q does not concern GMS for maintaining coherence between the copies on multiple nodes.</li>
</ul>
<h2 id="local-and-global-boundary"><a class="markdownIt-Anchor" href="#local-and-global-boundary"></a> Local and Global Boundary</h2>
<img src="https://i.imgur.com/PF6RiZy.png" style="width: 800px" />
<ul>
<li>In all cases except where the global part of the faulting node’s cache is empty, the local part goes up by one and the global part comes down by one.</li>
<li>When the faulting page is in the global cache of a different node, there is no change in the balance between local and global on either node.</li>
<li>If the faulting page is on disk, we have to make space in the cluster memory by throwing out a page, and if the LRU page on the node with the globally oldest page is in the local cache, the local part goes down by one and the global part goes up by one.</li>
<li>If the page is actively shared, there is no change in the balance between local and global on either node, but one of the node’s global pages has to be sent to the node with the globally oldest page, and if the replacement candidate comes from the local cache, the local part shrinks by one and the global part increases by one to accommodate the new page.</li>
</ul>
<h2 id="behavior-of-algorithm"><a class="markdownIt-Anchor" href="#behavior-of-algorithm"></a> Behavior of Algorithm</h2>
<ul>
<li>The behavior of GMS global memory management is dynamic, not static.</li>
<li>The split between local and global cache changes based on the memory pressure at a particular node.</li>
<li>Idle nodes with a decreasing working set can become memory servers for peers on the network.</li>
<li>The algorithm does not handle coherence maintenance, which must be managed at a higher level of software.</li>
<li>The global cache acts as a surrogate for the disk, providing faster access to pages than the disk itself.</li>
<li>The algorithm optimizes memory usage by swapping pages between nodes in the LAN.</li>
</ul>
<h2 id="geriatricsage-management"><a class="markdownIt-Anchor" href="#geriatricsage-management"></a> Geriatrics!(Age management)</h2>
<img src="https://i.imgur.com/XAZXJfL.png" style="width: 800px" />
<ul>
<li>Age management is a critical part of the GMS system, as it determines which pages should be evicted and replaced with new pages.</li>
<li>The age of a page represents how long it has been since it was last accessed, with smaller ages indicating more recently accessed pages.</li>
<li>The GMS system breaks age management into epochs, which are time periods during which management work is done by a single node.</li>
<li>The duration of an epoch is set by the parameter T, which is the maximum duration that an epoch can last.</li>
<li>The epoch management work is either time-bound (limited by T) or space-bound (limited by M replacements). M is another parameter that represents the maximum number of page replacements that can occur in an epoch.</li>
<li>At the beginning of each epoch, each node sends its age information to the initiator node. This includes the age of all local and global pages residing on the node.</li>
<li>The initiator node calculates the minimum age of the M pages that will be replaced in the upcoming epoch. It also computes the weight for each node, which represents the fraction of replacements that will come from that node.</li>
<li>The node with the highest weight becomes the initiator for the next epoch.</li>
<li>When a page fault occurs, the node checks the age of the page that needs to be replaced. If the age is greater than the minimum age, the page is discarded. If it is less than the minimum age, the node sends the page to a peer node based on the weight distribution.</li>
<li>By using age management to approximate a global LRU (Least Recently Used) algorithm, the GMS system ensures that older pages are evicted and replaced with newer pages, thus improving overall system performance.</li>
<li>The GMS system also follows the principle of thinking globally but acting locally, where global information is used to make local decisions.</li>
</ul>
<h2 id="implementation-in-unix"><a class="markdownIt-Anchor" href="#implementation-in-unix"></a> Implementation in Unix</h2>
<img src="https://i.imgur.com/hD6Yv6m.png" style="width: 800px" />
<ul>
<li>In systems research, identifying a pain point and coming up with a clever solution is important.</li>
<li>Implementing the solution, even if it’s a simple idea, requires heavy lifting and technical details.</li>
<li>Implementation tricks and techniques can be reusable knowledge for other systems research.</li>
<li>The authors of GSM used the OSF/1 operating system by DEC(Digital Equipment Corporation) operating system as the base system for their memory management system.</li>
<li>The OSF/1 memory system has two key components: the virtual memory system (VM) and the unified buffer cache (UBC).</li>
<li>The virtual memory system (VM) is responsible for mapping process virtual address space to physical memory, and the unified buffer cache (UBC) is used by the file system to cache disk-resident files in physical memory.</li>
<li>The GMS implementation required modifying both the VM and UBC components of the operating system to support the global memory system.</li>
<li>Writing pages to disk remains unchanged in the GMS implementation, as only page faults are redirected to the cluster memory.</li>
<li>Collecting age information for anonymous pages in the VM is challenging since the operating system doesn’t see individual memory accesses made by a user process. To address this, the GMS implementation includes a daemon that periodically dumps the contents of the Translation Lookaside Buffer (TLB) to collect age information for anonymous pages.</li>
<li>The GMS implementation also includes modifications to the pageout daemon and free list maintenance for allocating and freeing frames on each node.</li>
<li>The technical details of how GMS integrates with the VM, UBC, and other components of the operating system are important and may be reusable knowledge for other systems research.</li>
</ul>
<h2 id="data-structures"><a class="markdownIt-Anchor" href="#data-structures"></a> Data Structures</h2>
<img src="https://i.imgur.com/UNrPfGS.png" style="width: 800px" />
<ul>
<li>GMS uses distributed data structures for virtual memory management across the cluster.</li>
<li>The virtual address is converted into a universal ID (UID) to uniquely identify a virtual address.</li>
<li>Three key data structures are used: PFD (Page frame Directory), GCD (Global Cache Directory), and POD (Page Ownership Directory).</li>
<li>The <strong>POD tells which node owns which pages</strong>, and it is replicated on all nodes in the cluster. The <strong>GCD maps UIDs (unique identifiers for virtual addresses) to the nodes that host the corresponding PFDs</strong>. The <strong>PFD contains the mapping between UIDs and page frame numbers (PFNs)</strong> and is stored on the node that owns the page.</li>
<li>When a <strong>page fault occurs</strong>, the node first converts the virtual address to a UID and uses the POD to determine the owner of the page. It then uses the GCD to find the node that hosts the PFD for that UID and sends the UID to that node. The node with the PFD retrieves the page and sends it back to the requesting node.
<ul>
<li>
<img src="https://i.imgur.com/FA1JAou.png" style="width: 800px" />
</li>
<li>Node A converts virtual address to UID and goes to page ownership directory (POD)</li>
<li>POD tells Node A who the owner of the page is (Node B), which has the Global Page Frame Directory (GCD)</li>
<li>Node B looks up its GCD and sends UID to node C, which has the Page Frame Directory (PFD) for that UID</li>
<li>Node C retrieves the page, sends it to Node A, which maps it and resumes the process</li>
</ul>
</li>
<li>Network communication occurs only when there is a page fault, and most page faults are for non-shared pages, meaning the POD and GCD are co-resident on the same node. In this case, there is no network communication to look up the GCD.</li>
<li>There can be a <strong>miss when requesting a page</strong>, which can happen if the page has been evicted from the PFD or if the POD information is stale due to changes in the network. In these cases, the request can be retried after looking up the updated POD or GCD.
<ul>
<li>
<img src="https://i.imgur.com/Ie6o0Rf.png" style="width: 800px" />
</li>
<li>Misses are uncommon compared to page faults, and network communication is mostly local to the node</li>
</ul>
</li>
<li>To handle <strong>page evictions</strong>, each node has a paging daemon that puts evicted pages onto a candidate node based on weight information obtained from the geriatric management system (GMS). The paging daemon also coordinates with the GMS to update the GCD with the new PFD location for the corresponding UID. This happens in an aggregated manner when the free list falls below a threshold.
<ul>
<li>
<img src="https://i.imgur.com/e1KKUws.png" style="width: 800px" />
</li>
</ul>
</li>
</ul>
<h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2>
<p>The concept of paging across a network is interesting but may not be feasible in certain environments such as individual-owned workstations. However, it may be feasible in large-scale clusters in data centers. The enduring aspects of this research are the techniques, distributed data structures, and algorithms for implementing the concept. The next lesson module will feature another thought experiment on using cluster memory.</p>

</div>


  <div class="book-comments">
    




  </div>



<script src="/js/book-post.js"></script>


<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">
  
  <div class="divider"></div>
</div>

  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>


<script src="/js/book-toc.js"></script>

</div>

      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>


<script src="/js/book.js"></script>
