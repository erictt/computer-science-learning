<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/favicon.png" />
    

    <title>
        
          Eric&#39;s CS Notes
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    
<link rel="stylesheet" href="/css/book.css">

    
<script src="/js/book.js"></script>


    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.css">
    
    <!-- katex css -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous">

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/">
    <img src="/favicon.png">
    <span>ERIC&#39;S CS NOTES</span>
  </a>
</div>

    <div class="book-menu">
  <!--
## Introduction to Probability

* [Unit 1: Probability models and axioms](/introduction-to-probability/unit-1/index.html)
* [Unit 2: Conditioning and independence](/introduction-to-probability/unit-2/index.html)
* [Unit 3: Counting](/introduction-to-probability/unit-3/index.html)
* [Unit 4: Discrete random variables](/introduction-to-probability/unit-4/index.html)
* [Unit 5: Continuous random variables](/introduction-to-probability/unit-5/index.html)
* [Unit 6: Further topics on random variables](/introduction-to-probability/unit-6/index.html)
* [Unit 7: Bayesian inference](/introduction-to-probability/unit-7/index.html)
* [Unit 8: Limit theorems and classical statistics](/introduction-to-probability/unit-8/index.html)
* [Unit 9: Bernoulli and Poisson processes](/introduction-to-probability/unit-9/index.html)
* [Unit 10: Markov chains](/introduction-to-probability/unit-10/index.html)
-->
<!--
## Multivariable Calculus

* [Unit 1: Thinking about multivariable functions](/multivariable-calculus/unit-1/index.html)
* [Unit 2: Derivatives of multivariable functions](/multivariable-calculus/unit-2/index.html)

* [Unit 3: Applications of multivariable derivatives](/multivariable-calculus/unit-3/index.html)
* [Unit 4: Integrating multivariable functions](/multivariable-calculus/unit-4/index.html)
* [Unit 5: Green's, Stokes', and the divergence theorems](/multivariable-calculus/unit-5/index.html)
-->
<h2 id="CS6210-Advanced-Operating-Systems">CS6210: Advanced Operating Systems</h2>
<ul>
<li><a href="/cs6210/lesson-02/index.html">Lesson 02: OS Structure</a></li>
<li><a href="/cs6210/lesson-03/index.html">Lesson 3: Virtualization</a></li>
<li><a href="/cs6210/lesson-04-1/index.html">Lesson 4: Parallel Systems - Part 1</a></li>
<li><a href="/cs6210/lesson-04-2/index.html">Lesson 4: Parallel Systems - Part 2</a></li>
<li><a href="/cs6210/lesson-05/index.html">Lesson 5: Distributed Systems</a></li>
<li><a href="/cs6210/lesson-06/index.html">Lesson 6: Distributed Objects and Middleware</a></li>
</ul>
<!--
* [Lesson 7: Distributed Subsystems](/cs6210/lesson-07/index.html)
* [Lesson 9: Internet Computing](/cs6210/lesson-09/index.html)
* [Lesson 10: RT and Multimedia](/cs6210/lesson-10/index.html)
* [Lesson 8: Failures and Recovery](/cs6210/lesson-08/index.html)
* [Lesson 11: Security](/cs6210/lesson-11/index.html)
-->
<h2 id="CS6250-Computer-Networks">CS6250 Computer Networks</h2>
<ul>
<li><a href="/cs6250/week-1-internet-architecture/index.html">Week 1 - Internet Architecture</a></li>
<li><a href="/cs6250/week-2-transport-and-application-layers/index.html">Week 2 - Transport and Application Layers</a></li>
<li><a href="/cs6250/week-3-intradomain-routing/index.html">Week 3 - Intradomain Routing</a></li>
<li><a href="/cs6250/week-4-as-relationships-and-interdomain-routing/index.html">Week 4 - AS Relationships and Interdomain Routing</a></li>
<li><a href="/cs6250/week-5-router-design-and-algorithems-part-1/index.html">Week 5 - Router Design and Algorithms (Part 1)</a></li>
<li><a href="/cs6250/week-6-router-design-and-algorithems-part-2/index.html">Week 6 - Router Design and Algorithms (Part 2)</a></li>
<li><a href="/cs6250/week-7-software-defined-networking-part-1/index.html">Week 7 - Software Defined Networking (Part 1)</a></li>
<li><a href="/cs6250/week-8-software-defined-networking-part-2/index.html">Week 8 - Software Defined Networking (Part 2)</a></li>
<li><a href="/cs6250/week-9-internet-security/index.html">Week 9 - Internet Security</a></li>
<li><a href="/cs6250/week-10-internet-surveillance-and-censorship/index.html">Week 10 - Internet Surveillance and Censorship</a></li>
<li><a href="/cs6250/week-11-applications-video/index.html">Week 11 - Applications Videos</a></li>
<li><a href="/cs6250/week-12-applications-cdns-and-overlay-networks/index.html">Week 12 - Applications CDNs and Overlay Networks</a></li>
</ul>
<h2 id="CS6200-Graduate-Introduction-to-Operating-Systems">CS6200 Graduate Introduction to Operating Systems</h2>
<ul>
<li><a href="/cs6200/p1-preparation/index.html">P0 - Preparation</a></li>
<li><a href="/cs6200/p1l2-introduction/index.html">P1L2 - Introduction</a></li>
<li><a href="/cs6200/p2l1-processes-and-process-management/index.html">P2L1 - Processes and Process Management</a></li>
<li><a href="/cs6200/p2l2-threads-and-concurrency/index.html">P2L2 - Threads and Concurrency</a></li>
<li><a href="/cs6200/p2l3-pthread/index.html">P2L3 - PThread</a></li>
<li><a href="/cs6200/p2l4-thread-design-consideration/index.html">P2L4 - Thread Design Considerations</a></li>
<li><a href="/cs6200/p2l5-thread-performance-consideration/index.html">P2L5 - Thread Performance Considerations</a></li>
<li><a href="/cs6200/p3l1-scheduling/index.html">P3L1 - Scheduling</a></li>
<li><a href="/cs6200/p3l2-memory-management/index.html">P3L2 - Memory Management</a></li>
<li><a href="/cs6200/p3l3-inter-process-communication/index.html">P3L3 - Inter-Process Communication</a></li>
<li><a href="/cs6200/p3l4-synchronization-constructs/index.html">P3L4 - Synchronization Constructs</a></li>
<li><a href="/cs6200/p3l5-io-management/index.html">P3L5 - I/O Management</a></li>
<li><a href="/cs6200/p3l6-virtualization/index.html">P3L6 - Virtualization</a></li>
</ul>
<!--
* [P4L1 - Remote Procedure Calls](/cs6200/p4l1-remote-procedure-calls/index.html) 
* [P4L2 - Distributed File Systems](/cs6200/p4l2-distributed-file-systems/index.html) 
* [P4L3 - Distributed Shared Memory](/cs6200/p4l3-distributed-shared-memory/index.html) 
* [P4L4 - Datacenter Technologies](/cs6200/p4l4-datacenter-technologies/index.html) 
-->
<h2 id="Algorithms-Part-II">Algorithms: Part II</h2>
<ul>
<li><a href="/algorithms-2/week-1/index.html">Week 1 - Undirected Graph &amp; Directed Graph</a></li>
<li><a href="/algorithms-2/week-2/index.html">Week 2 - Minimum Spanning Trees &amp; Shortest Path</a></li>
<li><a href="/algorithms-2/week-3/index.html">Week 3 - Maximum Flow and Minimum Cut &amp; String Sort</a></li>
<li><a href="/algorithms-2/week-4/index.html">Week 4 - Tries &amp; Substring Search</a></li>
<li><a href="/algorithms-2/week-5/index.html">Week 5 - Regular Expressions</a></li>
<li><a href="/algorithms-2/week-6/index.html">Week 6 - Reductions</a></li>
</ul>
<h2 id="Algorithms-Part-I">Algorithms: Part I</h2>
<ul>
<li><a href="/algorithms-1/week-1/index.html">Week 1 - Union-Find &amp; Analysis of Algorithms</a></li>
<li><a href="/algorithms-1/week-2/index.html">Week 2 - Stacks and Queues &amp; Elementary Sorts</a></li>
<li><a href="/algorithms-1/week-3/index.html">Week 3 - Mergesort &amp; Quicksort</a></li>
<li><a href="/algorithms-1/week-4/index.html">Week 4 - Priority Queues &amp; Elementary Symbols</a></li>
<li><a href="/algorithms-1/week-5/index.html">Week 5 - Balanced Search Trees</a></li>
<li><a href="/algorithms-1/week-6/index.html">Week 6 - Hash Tables</a></li>
</ul>
<h2 id="Introduction-to-Software-Design-and-Architecture">Introduction to Software Design and Architecture</h2>
<ul>
<li><a href="/introduction-to-software-design-and-architecture/design-pattern/index.html">Design Pattern</a></li>
</ul>
<h2 id="Calculus-Two-Sequences-and-Series">Calculus Two: Sequences and Series</h2>
<ul>
<li><a href="/calculus-two/week-1/index.html">Week 1 - Sequences</a></li>
<li><a href="/calculus-two/week-2/index.html">Week 2 - Series</a></li>
<li><a href="/calculus-two/week-3/index.html">Week 3 - Convergence Tests</a></li>
<li><a href="/calculus-two/week-4/index.html">Week 4 - Alternating Series</a></li>
<li><a href="/calculus-two/week-5/index.html">Week 5 - Power Series</a></li>
<li><a href="/calculus-two/week-6/index.html">Week 6 - Taylor Series</a></li>
</ul>
<h2 id="LAFF-Linear-Algebra">LAFF Linear Algebra</h2>
<ul>
<li><a href="/laff-linear-algebra/week-1/index.html">Week 1 - Vectors in Linear Algebra</a></li>
<li><a href="/laff-linear-algebra/week-2/index.html">Week 2 - Linear Transformations and Matrices</a></li>
<li><a href="/laff-linear-algebra/week-3/index.html">Week 3 - Matrix-Vector Operations</a></li>
<li><a href="/laff-linear-algebra/week-4/index.html">Week 4 - Matrix-Vector to Matrix-Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-5/index.html">Week 5 - Matrix- Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-6/index.html">Week 6 - Gaussian Elimination</a></li>
<li><a href="/laff-linear-algebra/week-7/index.html">Week 7 - More Gaussian Elimination and Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-8/index.html">Week 8 - More on Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-9/index.html">Week 9 - Vector Spaces</a></li>
<li><a href="/laff-linear-algebra/week-10/index.html">Week 10 - Vector Spaces, Orthogonality, and Linear Least-Squares</a></li>
<li><a href="/laff-linear-algebra/week-11/index.html">Week 11 - Orthogonal Projection, Low Rank Approximation, and Orthogonal Bases</a></li>
<li><a href="/laff-linear-algebra/week-12/index.html">Week 12 - Eigenvalues and Eigenvectors</a></li>
</ul>
<h2 id="Stanford-Machine-Learning">Stanford Machine Learning</h2>
<ul>
<li><a href="/stanford-machine-learning/week-1/index.html">Week 1 - Introduction</a></li>
<li><a href="/stanford-machine-learning/week-2/index.html">Week 2 - Linear Regression with Multiple Variables</a></li>
<li><a href="/stanford-machine-learning/week-3/index.html">Week 3 - Logistic Regression &amp; Regularization</a></li>
<li><a href="/stanford-machine-learning/week-4/index.html">Week 4 - Neural Networks: Representation</a></li>
<li><a href="/stanford-machine-learning/week-5/index.html">Week 5 - Neural Networks: Learning</a></li>
<li><a href="/stanford-machine-learning/week-6a/index.html">Week 6a - Advice for Applying Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-6b/index.html">Week 6b - Machine Learning System Design</a></li>
<li><a href="/stanford-machine-learning/week-7/index.html">Week 7 - Support Vector Machines</a></li>
<li><a href="/stanford-machine-learning/week-8/index.html">Week 8 - Unsupervised Learning &amp; Dimensionality Reduction</a></li>
<li><a href="/stanford-machine-learning/week-9a/index.html">Week 9a - Anomaly Detection</a></li>
<li><a href="/stanford-machine-learning/week-9b/index.html">Week 9b - Recommender Systems</a></li>
<li><a href="/stanford-machine-learning/week-10/index.html">Week 10 - Large Scale Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-11/index.html">Week 11 - Application Example: Photo OCR</a></li>
</ul>
<h2 id="Calculus-One">Calculus One</h2>
<ul>
<li><a href="/calculus-one/week-2-3/index.html">Week 2-3 - Functions &amp; Limits</a></li>
<li><a href="/calculus-one/week-4/index.html">Week 4 - The Beginning of Derivatives</a></li>
<li><a href="/calculus-one/week-5/index.html">Week 5 - Techniques of Differentiation</a></li>
<li><a href="/calculus-one/week-6/index.html">Week 6 - Chain Rule</a></li>
<li><a href="/calculus-one/week-7/index.html">Week 7 - Derivatives of Trigonometric Functions</a></li>
<li><a href="/calculus-one/week-8/index.html">Week 8 - Derivatives in the Real World</a></li>
<li><a href="/calculus-one/week-9/index.html">Week 9 - Optimization</a></li>
<li><a href="/calculus-one/week-10/index.html">Week 10 - Linear Approximation</a></li>
<li><a href="/calculus-one/week-11-12/index.html">Week 11-12 - Antidifferentiation &amp; Integration</a></li>
<li><a href="/calculus-one/week-13/index.html">Week 13 - Fundamental Theorem of Calculus</a></li>
<li><a href="/calculus-one/week-14/index.html">Week 14 - Substitution Rule</a></li>
<li><a href="/calculus-one/week-15/index.html">Week 15 - Techniques of Integration</a></li>
<li><a href="/calculus-one/week-16/index.html">Week 16 - Applications of Integration</a></li>
</ul>
<h2 id="Computational-Thinking">Computational Thinking</h2>
<ul>
<li><a href="/computational-thinking/lecture-1/index.html">Lecture 1 - Optimization and Knapsack Problem</a></li>
<li><a href="/computational-thinking/lecture-2/index.html">Lecture 2 - Decision Trees and Dynamic Programming</a>
<ul>
<li><a href="/computational-thinking/lecture-2-powerset/index.html">Exercise: Power Set Function</a></li>
</ul>
</li>
<li><a href="/computational-thinking/lecture-3/index.html">Lecture 3 - Graphs</a></li>
<li><a href="/computational-thinking/lecture-4-5/index.html">Lecture 4-5 - Plotting</a></li>
<li><a href="/computational-thinking/lecture-6-7/index.html">Lecture 6-7 - Stochastic Programs &amp; Inferential Statistics</a></li>
<li><a href="/computational-thinking/lecture-8/index.html">Lecture 8 - Monte Carlo Simulation</a></li>
<li><a href="/computational-thinking/lecture-9/index.html">Lecture 9 - Sampling and Standard Error</a></li>
<li><a href="/computational-thinking/lecture-10-11/index.html">Lecture 10-11 - Experimental Data</a></li>
<li><a href="/computational-thinking/lecture-12/index.html">Lecture 12 - Machine Learning</a></li>
<li><a href="/computational-thinking/lecture-13/index.html">Lecture 13 - Statistical Abuses</a></li>
</ul>
<h2 id="Effective-Thinking-Through-Mathematics">Effective Thinking Through Mathematics</h2>
<ul>
<li><a href="/effective-thinking-through-mathematics/note/index.html">Note</a></li>
<li><a href="/effective-thinking-through-mathematics/week-4-telling-the-story-of-infinity/index.html">Week 4 (/Telling the Story of Infinity)</a></li>
<li><a href="/effective-thinking-through-mathematics/week-5-telling-the-story-of-the-euler-circuit-theorem/index.html">Week 5 (/Telling the Story of Euler Circuit Theorem)</a></li>
</ul>
<h2 id="CS50-Introduction-to-Computer-Science">CS50 Introduction to Computer Science</h2>
<ul>
<li><a href="/cs50/week-1/index.html">Week 1 - C</a></li>
<li><a href="/cs50/week-2/index.html">Week 2 - Arrays</a></li>
<li><a href="/cs50/week-3/index.html">Week 3 - Algorithms</a></li>
<li><a href="/cs50/week-4/index.html">Week 4 - Memory</a></li>
<li><a href="/cs50/week-5/index.html">Week 5 - Data Structures</a></li>
<li><a href="/cs50/week-6/index.html">Week 6 - HTTP</a></li>
<li><a href="/cs50/week-7-10/index.html">Week 7-10 - Machine Learning/Python/SQL/Javascript</a></li>
</ul>
<h2 id="Others">Others</h2>
<ul>
<li><a href="/symbols/index.html">Symbols of Mathematics</a></li>
<li><a href="/glossary/index.html">Glossary</a></li>
</ul>
<h2 id="About-Me"><a target="_blank" rel="noopener" href="https://ericyy.me/about/">About Me</a></h2>

</div>


<script src="/js/book-menu.js"></script>

  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1>Test 1</h1>
<h2 id="OS-Structure">OS Structure</h2>
<h3 id="I-SPIN">I. SPIN</h3>
<ol>
<li>[3 points] [True/False with justification] Distinct protection domains require distinct hardware address spaces.
<ul>
<li>False. Small protection domains can share one hardware address space, separated by the boundary of segment registers.</li>
</ul>
</li>
<li>[4 points] SPIN promotes implementing an entire OS in a strongly typed high level language like Modula-3. Give 2 examples scenarios in which the OS may have to go outside the boundaries of language enforced protection model.
<ul>
<li>The core services that need to control the hardware resources will go out of the boundaries, such as the services like CPU scheduler and memory management.</li>
<li>When CPU schedulier switch processes, it needs to store process’s PCB into memory and load the next PCB for the next process.</li>
<li>Memory management. e.g. create and destroy the address spaces.</li>
</ul>
</li>
<li>[4 points] Give any two techniques that underlie SPIN’s ability to achieve their goals of extensibility, safety, and good performance.
<ul>
<li>co-location of the extensions within the kernel allows efficient communication between the kernel and the extension (good performance).</li>
<li>SPIN offers the concept of generic interfaces and allow developers to implement the OS services such as file system, network protocols (extensibility).</li>
</ul>
</li>
</ol>
<h3 id="II-Exokernel">II. Exokernel</h3>
<ol>
<li>[6 points] A library OS implements a paged virtual memory on top of Exokernel. An application running in this OS encounters a page fault. List the steps from the time the page fault occurs to the resumption of this application. For this problem assume the following:
<ul>
<li>The processor architecture has only a TLB for address translation (i.e., a TLB miss triggers a page fault)</li>
<li>The library OS has already acquired all the necessary capabilities from Exokernel (writing to the memory mapped device controller registers to start the DMA from the disk to a memory buffer)</li>
<li>The library OS has a pool of free page frames already preallocated to it by Exokernel.
<ol>
<li>Exokernel will upcall the page fault to the library OS through a “Registered Handler”.</li>
<li>The library OS serves the page fault and performs the required mapping.</li>
<li>This mapping is then presented to the Exokernel with the TLB entry.</li>
<li>The Exokernel will validate the key and install the mapping into the HW TLB (privileged operations).</li>
</ol>
</li>
</ul>
</li>
<li>[2 points] [True/False with justification] When exokernel receives an interrupt and the library OS to which the interrupt is to be delivered is not currently running, exokernel ignores the interrupt.
<ol>
<li>False. Exokernel buffers the interrupt and delivers it to the lib OS when it’s scheduled.</li>
</ol>
</li>
<li>[3 points] Give ONE similarity and ONE difference between the approaches to extensibility of SPIN and Exokernel
<ol>
<li>Similar: To reduce the impact of boarder crossing, Exokernel allows downloading code into the kernel. SPIN co-locate the extension and the kernel to the kernel address space.</li>
<li>Diff: Exokernel allow downloading arbitrary code into kernel, less secure. SPIN’s extension are created at compile time and follow the rules enforced by the programming language.</li>
</ol>
</li>
</ol>
<h3 id="III-L3-Microkernel">III. L3 Microkernel</h3>
<ol>
<li>[2 points] [True/False with justification] In designing the L3 microkernel, Liedtke further strengthens the conclusions of SPIN/Exokernel.
<ul>
<li>False, Liedtke approved that microkernel can be efficient.</li>
</ul>
</li>
<li>[2 points] [True/False with justification] If a CPU architecture does not support address-space tagged TLB, a TLB flush is unavoidable when moving from one user-level protection domain to another.
<ul>
<li>False. We can use segment registers to specify the range of virtual addresses that a process can legally access. Since each process have it’s own protection domain, the process will not clash when querying the TLB. therefore, there is no need to flush the TLB.</li>
</ul>
</li>
<li>[2 points] [True/False with justification] To implement a high-performance microkernel, the microkernel abstractions should be architecture independent.
<ul>
<li>False. It should be processor-specific, and take advantage of the processor architecture offers such as segment register.</li>
</ul>
</li>
</ol>
<h2 id="Virtualization">Virtualization</h2>
<h3 id="IV-Para-virtualization">IV. Para virtualization</h3>
<p>An architecture supports a TLB that is entirely software-managed in kernel mode. The size of the TLB is an architectural parameter that is published and known to the system software. The ISA of the processor provides the following instructions:<br>
• Set-AS(AS-ID): Stores the AS-ID in a register called Address Space Register (ASR) that can be accessed only in kernel mode.<br>
• Enter(AS-ID, VPN, PFN): Stores the tuple &lt;AS-ID, VPN, PFN&gt; in the TLB. If the TLB is full, this instruction will fail silently.<br>
• Delete(AS-ID, VPN, PFN): Deletes the tuple &lt;AS-ID, VPN, PFN&gt; from the TLB. If the entry is non-existent the instruction is a NOP.</p>
<p>You are designing a hypervisor for supporting para-virtualized guest OSes on top of this architecture.</p>
<ol>
<li>
<p>[2 points] What advantage does this architecture have over x86-style architecture (that has a page-table plus hardware managed TLB) for implementing a para-virtualized guest OS?</p>
<ul>
<li>The fact that TLB is AS-tagged allow guest OSes and the hypervisor coexist in separate address spaces, and we can switch between guest OS and hypervisor without flushing the TLB.</li>
</ul>
</li>
<li>
<p>[2 points] How would you provide memory isolation/independence/integrity for each guest OS?</p>
<ul>
<li>Each guest OS has its own software-based TLB space. The hypervisor will install the software TLB for the guest when running it.</li>
</ul>
</li>
<li>
<p>[6 points] How can each guest-OS provide memory isolation/independence/integrity for processes created within it?</p>
<ul>
<li>
<p>The guest OS creates AS-ID qprocess and call <code>Set-AS</code> to allocate it to the CPU, then use both <code>Enter</code> and <code>Delete</code> instructions to manage the hardware space for the process.</p>
</li>
<li>
<p>The guest OS allocates a page frame as the page table data structure for the newly created process</p>
</li>
<li>
<p>It initializes the page table</p>
</li>
<li>
<p>It uses an API provided by the hypervisor to give the page frame address to the hypervisor.</p>
</li>
<li>
<p>The hypervisor records this address as one of the valid page table pointers for this guest OS</p>
</li>
<li>
<p>Whenever the guest OS wishes to schedule this process it will use an API provided by the hypervisor (e.g., “Switch PT”) to tell the hypervisor to load the PTBR with the address of the page table it has registered with the hypervisor earlier</p>
</li>
<li>
<p>When a process has a page fault, the hypervisor upcalls the guest OS which resolves the page fault and presents a valid mapping (VPN to MPN) to the hypervisor using an API (e.g., “Install Mapping”) which is entered into the page table named by the API call.</p>
</li>
<li>
<p>Since each process has its own page table and thus its own address space, it has the guarantees of isolation and protection.</p>
</li>
</ul>
<ol start="2">
<li>A guest OS can issue a “Hypercall” to the Hypervisor to <strong>create</strong> (allocate and initialize) a HW page frame and the guest OS can target this page frame to host a page table data structure.</li>
<li>When a process starts to run, the guest OS issues another Hypercall to the Hypervisor to <strong>switch</strong> the page table to the previously given location.</li>
<li>The guest OS can also <strong>update</strong> this page table.</li>
</ol>
</li>
</ol>
<h3 id="V-Full-virtualization">V. Full virtualization</h3>
<ol>
<li>[2 points] [True/False with justification] A fully virtualized environment with multiple Guest OSes has a single shadow page table.
<ul>
<li>False. The s-PT is per guest OS.</li>
</ul>
</li>
<li>Assume that a fully virtualized OS is running on top of x86 processor that has a page table and TLB. The guest-OS maps a process’s virtual page number (VPN) to a physical page number (PPN). However, PPN is an illusion of the guest-OS which must be translated to the machine page number (MPN).
<ol>
<li>[2 points] How is this illusion of physical memory being contiguous for the guest-OS not result in inefficiency in a fully virtualized setting?
<ul>
<li>When the guest os tries to update the page table, it will trap to the hypervisor.</li>
<li>The hypervisor updates the shadow PT to map the PPN to MPN, and set VPN -&gt; MPN in the guest OS’s TLB.</li>
<li>Then we have a hardware-accessible page table that translate virtual-to-machine pages at hardware speed.</li>
</ul>
</li>
<li>[2 points] How does the processor translate the virtual page number generated by the currently running process to its corresponding machine page number in memory?
<ul>
<li>Every time a process generates a virtual address, we won’t go through the guest OS to do the translation, since the translation has already ben installed in TLB and the hardware page table.</li>
</ul>
</li>
</ol>
</li>
<li>[2 points] State the difference between fully virtualized and para virtualized environments when it comes to updating the process page table after servicing a page fault.
<ul>
<li>In full, the guest OS try to execute a privileged instruction to update the mapping, which will trap to the hypervisor. The hypervisor will update the shadow page table along with the TLB and hardware address space.</li>
<li>In para, the guest OS makes hypercall to explicitly ask the hypervisor to update the page table.</li>
</ul>
</li>
</ol>
<h3 id="VI-Memory-Management-Y">VI. Memory Management [Y]</h3>
<ol>
<li>[2 points] Explain concisely, how can the ballooning mechanism be used with a fully virtualized OS?
<ul>
<li>Hypervisor installs the ballon device driver in every guest OS</li>
<li>When any guest OS asking for more memory, the hypervisor will inflate the balloon driver on other guest OS to force them page out unused pages.</li>
<li>The balloon driver give back the memory to the hypervisor to reallocate.</li>
<li>Conversely, the hypervisor can deflate the balloon driver to give the guest OS more memory to page in the pages from disk.</li>
</ul>
</li>
<li>[2 points] [True/False with justification] In VM oblivious page sharing, if there is a hash match between the page (call it incoming page) being brought in from the disk and an existing hash entry in the hypervisor’s hash table, then the machine page associated with the incoming page can be safely discarded.
<ul>
<li>False. A hash match only hints that there could be a possible match. The content might have been updated since then. A full comparison is require before discarding the page.</li>
</ul>
</li>
<li>[2 points] [True/False with justification] Inflating the balloon driver of a Guest OS will result in more machine memory being allocated to that OS.
<ul>
<li>False. inflate results more memory goes to the ballon drive, hence less memory for the guest OS.</li>
</ul>
</li>
</ol>
<h2 id="Parallel-systems">Parallel systems</h2>
<h3 id="VII-Atomicity">VII. Atomicity</h3>
<ol>
<li>[4 points] Consider a SMP with invalidation-based CC and whose Instruction-set Architecture (ISA) provides instructions for atomic read and atomic write. The OS supports multi-threaded applications and implements scheduling at the level of individual threads at available CPU cores. You have implemented the mutual exclusion algorithm as below:</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// L is a shared variable </span></span><br><span class="line">Lock(L):</span><br><span class="line">    back:</span><br><span class="line">    <span class="keyword">if</span> (L == <span class="number">0</span>) L = <span class="number">1</span>; <span class="comment">// success</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        While (L == <span class="number">1</span>); <span class="comment">// spin go back;</span></span><br><span class="line">Unlock(L):</span><br><span class="line">    L = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>Will this lock algorithm work? If not, why not?
<ul>
<li>No. it’s possible that two threads encounter the <code>if(L==0)</code> situation, and they both acquired the lock. We need RMW instruction for this.</li>
</ul>
</li>
</ul>
<ol start="2">
<li>[2 points] [True/False with justification] An atomic read-modify-write instruction is not a necessity in the processor’s ISA for implementing Anderson’s mutual exclusion lock algorithm.
<ul>
<li>False. A processor needs to use the <code>fetch_and_inc</code> instruction to mark itself in the queue. If <code>fetch_and_inc</code> is not provided, we need to implement it with <code>test_and_set</code>.</li>
</ul>
</li>
<li>[2 points] [True/False with justification] An atomic read-modify-write instruction is a necessity in the processor’s ISA for implementing any barrier synchronization algorithm.
<ul>
<li>False. E.g. the MCS barrier only rely on atomic read and write.</li>
</ul>
</li>
</ol>
<h3 id="VIII-Barriers">VIII. Barriers</h3>
<p>[3 points] Consider the sense reversing barrier implementation in C as follows where count, sense are shared variables across threads which are initialized to N and False respectively. Will this code work? If yes explain why, if no, give brief reasoning and an example!</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// global variables visible to all threads </span></span><br><span class="line"><span class="type">bool</span> sense = <span class="literal">false</span>; </span><br><span class="line"><span class="type">int</span> count = N;</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread specific static variable </span></span><br><span class="line"><span class="type">bool</span> local_sense = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">barrier</span><span class="params">()</span>&#123;</span><br><span class="line">    count--; </span><br><span class="line">    <span class="keyword">if</span>(count == <span class="number">0</span>)&#123; </span><br><span class="line">        sense = !local_sense;</span><br><span class="line">        count = N;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">while</span>(local_sense == sense);</span><br><span class="line">    &#125; </span><br><span class="line">    local_sense = !local_sense;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>No. There are several race problems.</li>
<li>One is, multiple threads try to decrease count at the same time, resulting count never reach 0.</li>
<li>Another one is, any threads can go to the next barrier and decrease the count before the count reset to N. Then after the count reset to N, it will never reach 0 since one thread decrease it before the reset.</li>
</ul>
<h3 id="IX-Potpourri">IX. Potpourri</h3>
<ol>
<li>[2 points][True/False with justification] Each position in the array of flags defined in Anderson’s queue lock is statically allocated to a designated processor to ensure fairness.
<ul>
<li>False. The fairness is given from the fact that the processors are sequenced and processed who gets in line first. In fact the threads are dynamically allocated.</li>
</ul>
</li>
<li>[2 points] [True/False with justification] MCS mutual exclusion lock can be implemented on a multi-processor that supports <strong>only a globally atomic T&amp;S</strong> primitive.
<ul>
<li>True. There are two instructions that been used in MCS. One is <code>fetch_and_store</code>, the other is <code>compare_and_swap</code>. Both can be implemented with <code>test_and_set</code>.</li>
</ul>
</li>
<li>[3 points] Explain why the MCS barrier algorithm will work even on an NCC NUMA machine.
<ul>
<li>A NUMA machine consists of a set of nodes connected through an interconnection network.</li>
<li>The parent spins on a memory location in its NUMA piece of the memory. The child will reach across the ICN to modify the memory location. The change will be seen by the parent since there is a hardware cache coherence within each node of the NCC NUMA architecture.</li>
</ul>
</li>
<li>[2 points] [True/False with justification] In Tornado parallel OS, the representation of clustered object – namely, replication, partitioning across the processors – is decided at the design time of a given subsystem and does not change.
<ul>
<li>False. E.g. Tornado can monitor the use of the regions over time and potentially carve them up into smaller regions if it would be advantageous.</li>
</ul>
</li>
<li>[4 points] Explain why in a vanilla client/server RPC package there are 4 message copies between the client’s invocation and the server procedure starting to execute.
<ol>
<li>A client stub will copy the data from the client stack to a serialized RPC packet.</li>
<li>The kernel copies the RPC packet to kernel buffer.</li>
<li>The kernel copies the packet from its buffer to the server’s domain.</li>
<li>The server de-serialize the packet and copy it to its working stack.</li>
</ol>
</li>
</ol>

</div>


  <div class="book-comments">
    




  </div>



<script src="/js/book-post.js"></script>


<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">
  
  <div class="divider"></div>
</div>

  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>


<script src="/js/book-toc.js"></script>

</div>

      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>


<script src="/js/book.js"></script>
