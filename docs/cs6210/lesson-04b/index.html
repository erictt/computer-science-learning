<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/favicon.png" />
    

    <title>
        
          Eric&#39;s CS Notes
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    
<link rel="stylesheet" href="/css/book.css">

    
<script src="/js/book.js"></script>


    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.css">
    
    <!-- katex css -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous">

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/">
    <img src="/favicon.png">
    <span>ERIC&#39;S CS NOTES</span>
  </a>
</div>

    <div class="book-menu">
  <!--
## Introduction to Probability

* [Unit 1: Probability models and axioms](/introduction-to-probability/unit-1/index.html)
* [Unit 2: Conditioning and independence](/introduction-to-probability/unit-2/index.html)
* [Unit 3: Counting](/introduction-to-probability/unit-3/index.html)
* [Unit 4: Discrete random variables](/introduction-to-probability/unit-4/index.html)
* [Unit 5: Continuous random variables](/introduction-to-probability/unit-5/index.html)
* [Unit 6: Further topics on random variables](/introduction-to-probability/unit-6/index.html)
* [Unit 7: Bayesian inference](/introduction-to-probability/unit-7/index.html)
* [Unit 8: Limit theorems and classical statistics](/introduction-to-probability/unit-8/index.html)
* [Unit 9: Bernoulli and Poisson processes](/introduction-to-probability/unit-9/index.html)
* [Unit 10: Markov chains](/introduction-to-probability/unit-10/index.html)
-->
<!--
## Multivariable Calculus

* [Unit 1: Thinking about multivariable functions](/multivariable-calculus/unit-1/index.html)
* [Unit 2: Derivatives of multivariable functions](/multivariable-calculus/unit-2/index.html)

* [Unit 3: Applications of multivariable derivatives](/multivariable-calculus/unit-3/index.html)
* [Unit 4: Integrating multivariable functions](/multivariable-calculus/unit-4/index.html)
* [Unit 5: Green's, Stokes', and the divergence theorems](/multivariable-calculus/unit-5/index.html)
-->
<h2 id="CS6210-Advanced-Operating-Systems">CS6210: Advanced Operating Systems</h2>
<ul>
<li><a href="/cs6210/lesson-02/index.html">Lesson 02: OS Structure</a></li>
<li><a href="/cs6210/lesson-03/index.html">Lesson 3: Virtualization</a></li>
<li><a href="/cs6210/lesson-04a/index.html">Lesson 4: Parallel Systems - Part 1</a></li>
<li><a href="/cs6210/lesson-04b/index.html">Lesson 4: Parallel Systems - Part 2</a></li>
<li><a href="/cs6210/lesson-05/index.html">Lesson 5: Distributed Systems</a></li>
<li><a href="/cs6210/lesson-06/index.html">Lesson 6: Distributed Objects and Middleware</a></li>
<li><a href="/cs6210/lesson-07a/index.html">Lesson 7: Distributed Subsystems - GMS</a></li>
<li><a href="/cs6210/lesson-07b/index.html">Lesson 7: Distributed Subsystems - DSM</a></li>
<li><a href="/cs6210/lesson-07c/index.html">Lesson 7: Distributed Subsystems - DFS</a></li>
<li><a href="/cs6210/lesson-09/index.html">Lesson 9: Internet Computing</a></li>
</ul>
<!--
* [Lesson 10: RT and Multimedia](/cs6210/lesson-10/index.html)
* [Lesson 8: Failures and Recovery](/cs6210/lesson-08/index.html)
* [Lesson 11: Security](/cs6210/lesson-11/index.html)
-->
<h2 id="CS6250-Computer-Networks">CS6250 Computer Networks</h2>
<ul>
<li><a href="/cs6250/week-1-internet-architecture/index.html">Week 1 - Internet Architecture</a></li>
<li><a href="/cs6250/week-2-transport-and-application-layers/index.html">Week 2 - Transport and Application Layers</a></li>
<li><a href="/cs6250/week-3-intradomain-routing/index.html">Week 3 - Intradomain Routing</a></li>
<li><a href="/cs6250/week-4-as-relationships-and-interdomain-routing/index.html">Week 4 - AS Relationships and Interdomain Routing</a></li>
<li><a href="/cs6250/week-5-router-design-and-algorithems-part-1/index.html">Week 5 - Router Design and Algorithms (Part 1)</a></li>
<li><a href="/cs6250/week-6-router-design-and-algorithems-part-2/index.html">Week 6 - Router Design and Algorithms (Part 2)</a></li>
<li><a href="/cs6250/week-7-software-defined-networking-part-1/index.html">Week 7 - Software Defined Networking (Part 1)</a></li>
<li><a href="/cs6250/week-8-software-defined-networking-part-2/index.html">Week 8 - Software Defined Networking (Part 2)</a></li>
<li><a href="/cs6250/week-9-internet-security/index.html">Week 9 - Internet Security</a></li>
<li><a href="/cs6250/week-10-internet-surveillance-and-censorship/index.html">Week 10 - Internet Surveillance and Censorship</a></li>
<li><a href="/cs6250/week-11-applications-video/index.html">Week 11 - Applications Videos</a></li>
<li><a href="/cs6250/week-12-applications-cdns-and-overlay-networks/index.html">Week 12 - Applications CDNs and Overlay Networks</a></li>
</ul>
<h2 id="CS6200-Graduate-Introduction-to-Operating-Systems">CS6200 Graduate Introduction to Operating Systems</h2>
<ul>
<li><a href="/cs6200/p1-preparation/index.html">P0 - Preparation</a></li>
<li><a href="/cs6200/p1l2-introduction/index.html">P1L2 - Introduction</a></li>
<li><a href="/cs6200/p2l1-processes-and-process-management/index.html">P2L1 - Processes and Process Management</a></li>
<li><a href="/cs6200/p2l2-threads-and-concurrency/index.html">P2L2 - Threads and Concurrency</a></li>
<li><a href="/cs6200/p2l3-pthread/index.html">P2L3 - PThread</a></li>
<li><a href="/cs6200/p2l4-thread-design-consideration/index.html">P2L4 - Thread Design Considerations</a></li>
<li><a href="/cs6200/p2l5-thread-performance-consideration/index.html">P2L5 - Thread Performance Considerations</a></li>
<li><a href="/cs6200/p3l1-scheduling/index.html">P3L1 - Scheduling</a></li>
<li><a href="/cs6200/p3l2-memory-management/index.html">P3L2 - Memory Management</a></li>
<li><a href="/cs6200/p3l3-inter-process-communication/index.html">P3L3 - Inter-Process Communication</a></li>
<li><a href="/cs6200/p3l4-synchronization-constructs/index.html">P3L4 - Synchronization Constructs</a></li>
<li><a href="/cs6200/p3l5-io-management/index.html">P3L5 - I/O Management</a></li>
<li><a href="/cs6200/p3l6-virtualization/index.html">P3L6 - Virtualization</a></li>
</ul>
<!--
* [P4L1 - Remote Procedure Calls](/cs6200/p4l1-remote-procedure-calls/index.html) 
* [P4L2 - Distributed File Systems](/cs6200/p4l2-distributed-file-systems/index.html) 
* [P4L3 - Distributed Shared Memory](/cs6200/p4l3-distributed-shared-memory/index.html) 
* [P4L4 - Datacenter Technologies](/cs6200/p4l4-datacenter-technologies/index.html) 
-->
<h2 id="Algorithms-Part-II">Algorithms: Part II</h2>
<ul>
<li><a href="/algorithms-2/week-1/index.html">Week 1 - Undirected Graph &amp; Directed Graph</a></li>
<li><a href="/algorithms-2/week-2/index.html">Week 2 - Minimum Spanning Trees &amp; Shortest Path</a></li>
<li><a href="/algorithms-2/week-3/index.html">Week 3 - Maximum Flow and Minimum Cut &amp; String Sort</a></li>
<li><a href="/algorithms-2/week-4/index.html">Week 4 - Tries &amp; Substring Search</a></li>
<li><a href="/algorithms-2/week-5/index.html">Week 5 - Regular Expressions</a></li>
<li><a href="/algorithms-2/week-6/index.html">Week 6 - Reductions</a></li>
</ul>
<h2 id="Algorithms-Part-I">Algorithms: Part I</h2>
<ul>
<li><a href="/algorithms-1/week-1/index.html">Week 1 - Union-Find &amp; Analysis of Algorithms</a></li>
<li><a href="/algorithms-1/week-2/index.html">Week 2 - Stacks and Queues &amp; Elementary Sorts</a></li>
<li><a href="/algorithms-1/week-3/index.html">Week 3 - Mergesort &amp; Quicksort</a></li>
<li><a href="/algorithms-1/week-4/index.html">Week 4 - Priority Queues &amp; Elementary Symbols</a></li>
<li><a href="/algorithms-1/week-5/index.html">Week 5 - Balanced Search Trees</a></li>
<li><a href="/algorithms-1/week-6/index.html">Week 6 - Hash Tables</a></li>
</ul>
<h2 id="Introduction-to-Software-Design-and-Architecture">Introduction to Software Design and Architecture</h2>
<ul>
<li><a href="/introduction-to-software-design-and-architecture/design-pattern/index.html">Design Pattern</a></li>
</ul>
<h2 id="Calculus-Two-Sequences-and-Series">Calculus Two: Sequences and Series</h2>
<ul>
<li><a href="/calculus-two/week-1/index.html">Week 1 - Sequences</a></li>
<li><a href="/calculus-two/week-2/index.html">Week 2 - Series</a></li>
<li><a href="/calculus-two/week-3/index.html">Week 3 - Convergence Tests</a></li>
<li><a href="/calculus-two/week-4/index.html">Week 4 - Alternating Series</a></li>
<li><a href="/calculus-two/week-5/index.html">Week 5 - Power Series</a></li>
<li><a href="/calculus-two/week-6/index.html">Week 6 - Taylor Series</a></li>
</ul>
<h2 id="LAFF-Linear-Algebra">LAFF Linear Algebra</h2>
<ul>
<li><a href="/laff-linear-algebra/week-1/index.html">Week 1 - Vectors in Linear Algebra</a></li>
<li><a href="/laff-linear-algebra/week-2/index.html">Week 2 - Linear Transformations and Matrices</a></li>
<li><a href="/laff-linear-algebra/week-3/index.html">Week 3 - Matrix-Vector Operations</a></li>
<li><a href="/laff-linear-algebra/week-4/index.html">Week 4 - Matrix-Vector to Matrix-Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-5/index.html">Week 5 - Matrix- Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-6/index.html">Week 6 - Gaussian Elimination</a></li>
<li><a href="/laff-linear-algebra/week-7/index.html">Week 7 - More Gaussian Elimination and Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-8/index.html">Week 8 - More on Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-9/index.html">Week 9 - Vector Spaces</a></li>
<li><a href="/laff-linear-algebra/week-10/index.html">Week 10 - Vector Spaces, Orthogonality, and Linear Least-Squares</a></li>
<li><a href="/laff-linear-algebra/week-11/index.html">Week 11 - Orthogonal Projection, Low Rank Approximation, and Orthogonal Bases</a></li>
<li><a href="/laff-linear-algebra/week-12/index.html">Week 12 - Eigenvalues and Eigenvectors</a></li>
</ul>
<h2 id="Stanford-Machine-Learning">Stanford Machine Learning</h2>
<ul>
<li><a href="/stanford-machine-learning/week-1/index.html">Week 1 - Introduction</a></li>
<li><a href="/stanford-machine-learning/week-2/index.html">Week 2 - Linear Regression with Multiple Variables</a></li>
<li><a href="/stanford-machine-learning/week-3/index.html">Week 3 - Logistic Regression &amp; Regularization</a></li>
<li><a href="/stanford-machine-learning/week-4/index.html">Week 4 - Neural Networks: Representation</a></li>
<li><a href="/stanford-machine-learning/week-5/index.html">Week 5 - Neural Networks: Learning</a></li>
<li><a href="/stanford-machine-learning/week-6a/index.html">Week 6a - Advice for Applying Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-6b/index.html">Week 6b - Machine Learning System Design</a></li>
<li><a href="/stanford-machine-learning/week-7/index.html">Week 7 - Support Vector Machines</a></li>
<li><a href="/stanford-machine-learning/week-8/index.html">Week 8 - Unsupervised Learning &amp; Dimensionality Reduction</a></li>
<li><a href="/stanford-machine-learning/week-9a/index.html">Week 9a - Anomaly Detection</a></li>
<li><a href="/stanford-machine-learning/week-9b/index.html">Week 9b - Recommender Systems</a></li>
<li><a href="/stanford-machine-learning/week-10/index.html">Week 10 - Large Scale Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-11/index.html">Week 11 - Application Example: Photo OCR</a></li>
</ul>
<h2 id="Calculus-One">Calculus One</h2>
<ul>
<li><a href="/calculus-one/week-2-3/index.html">Week 2-3 - Functions &amp; Limits</a></li>
<li><a href="/calculus-one/week-4/index.html">Week 4 - The Beginning of Derivatives</a></li>
<li><a href="/calculus-one/week-5/index.html">Week 5 - Techniques of Differentiation</a></li>
<li><a href="/calculus-one/week-6/index.html">Week 6 - Chain Rule</a></li>
<li><a href="/calculus-one/week-7/index.html">Week 7 - Derivatives of Trigonometric Functions</a></li>
<li><a href="/calculus-one/week-8/index.html">Week 8 - Derivatives in the Real World</a></li>
<li><a href="/calculus-one/week-9/index.html">Week 9 - Optimization</a></li>
<li><a href="/calculus-one/week-10/index.html">Week 10 - Linear Approximation</a></li>
<li><a href="/calculus-one/week-11-12/index.html">Week 11-12 - Antidifferentiation &amp; Integration</a></li>
<li><a href="/calculus-one/week-13/index.html">Week 13 - Fundamental Theorem of Calculus</a></li>
<li><a href="/calculus-one/week-14/index.html">Week 14 - Substitution Rule</a></li>
<li><a href="/calculus-one/week-15/index.html">Week 15 - Techniques of Integration</a></li>
<li><a href="/calculus-one/week-16/index.html">Week 16 - Applications of Integration</a></li>
</ul>
<h2 id="Computational-Thinking">Computational Thinking</h2>
<ul>
<li><a href="/computational-thinking/lecture-1/index.html">Lecture 1 - Optimization and Knapsack Problem</a></li>
<li><a href="/computational-thinking/lecture-2/index.html">Lecture 2 - Decision Trees and Dynamic Programming</a>
<ul>
<li><a href="/computational-thinking/lecture-2-powerset/index.html">Exercise: Power Set Function</a></li>
</ul>
</li>
<li><a href="/computational-thinking/lecture-3/index.html">Lecture 3 - Graphs</a></li>
<li><a href="/computational-thinking/lecture-4-5/index.html">Lecture 4-5 - Plotting</a></li>
<li><a href="/computational-thinking/lecture-6-7/index.html">Lecture 6-7 - Stochastic Programs &amp; Inferential Statistics</a></li>
<li><a href="/computational-thinking/lecture-8/index.html">Lecture 8 - Monte Carlo Simulation</a></li>
<li><a href="/computational-thinking/lecture-9/index.html">Lecture 9 - Sampling and Standard Error</a></li>
<li><a href="/computational-thinking/lecture-10-11/index.html">Lecture 10-11 - Experimental Data</a></li>
<li><a href="/computational-thinking/lecture-12/index.html">Lecture 12 - Machine Learning</a></li>
<li><a href="/computational-thinking/lecture-13/index.html">Lecture 13 - Statistical Abuses</a></li>
</ul>
<h2 id="Effective-Thinking-Through-Mathematics">Effective Thinking Through Mathematics</h2>
<ul>
<li><a href="/effective-thinking-through-mathematics/note/index.html">Note</a></li>
<li><a href="/effective-thinking-through-mathematics/week-4-telling-the-story-of-infinity/index.html">Week 4 (/Telling the Story of Infinity)</a></li>
<li><a href="/effective-thinking-through-mathematics/week-5-telling-the-story-of-the-euler-circuit-theorem/index.html">Week 5 (/Telling the Story of Euler Circuit Theorem)</a></li>
</ul>
<h2 id="CS50-Introduction-to-Computer-Science">CS50 Introduction to Computer Science</h2>
<ul>
<li><a href="/cs50/week-1/index.html">Week 1 - C</a></li>
<li><a href="/cs50/week-2/index.html">Week 2 - Arrays</a></li>
<li><a href="/cs50/week-3/index.html">Week 3 - Algorithms</a></li>
<li><a href="/cs50/week-4/index.html">Week 4 - Memory</a></li>
<li><a href="/cs50/week-5/index.html">Week 5 - Data Structures</a></li>
<li><a href="/cs50/week-6/index.html">Week 6 - HTTP</a></li>
<li><a href="/cs50/week-7-10/index.html">Week 7-10 - Machine Learning/Python/SQL/Javascript</a></li>
</ul>
<h2 id="Others">Others</h2>
<ul>
<li><a href="/symbols/index.html">Symbols of Mathematics</a></li>
<li><a href="/glossary/index.html">Glossary</a></li>
</ul>
<h2 id="About-Me"><a target="_blank" rel="noopener" href="https://ericyy.me/about/">About Me</a></h2>

</div>


<script src="/js/book-menu.js"></script>

  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1>Lesson 4: Parallel Operating System - Part 2</h1>
<h2 id="Lightweight-RPC">Lightweight RPC</h2>
<h3 id="Remote-Procedure-Call">Remote Procedure Call</h3>
<ul>
<li>Remote Procedure Call (RPC) is the mechanism used to manage communication in client-server operations on distributed systems.</li>
<li>It’s also efficient to use RPC even when the client and the server are on the same machine:
<ul>
<li><strong>Safety</strong>: We need to make sure that clients and servers are in different memory spaces. This means that RPC calls will go across different protection domains, which will hinder performance.</li>
<li>We need to make RPC across protection domains as efficient as a local procedure call.</li>
</ul>
</li>
</ul>
<h3 id="Local-Procedure-Call-LPC-vs-RPC">Local Procedure Call(LPC) vs RPC</h3>
<img src="https://i.imgur.com/Ohp3NqW.jpg" style="width: 800px" />
<ul>
<li>When a local procedure call happens
<ul>
<li>The CPU stops the calling process.</li>
<li>The CPU executes the called procedure.</li>
<li>Return to normal operation.</li>
<li>The <strong>binding and link</strong> of the local procedure call happens at <strong>compile time</strong>.
<ul>
<li>It just hits a <code>call</code> or <code>bl</code> or some other kind of <strong>brand and link</strong> instruction that sets the program counter to the target address and saves off the address of the next instruction, either on the stack or in a link register. When CPU hits a <code>ret</code> or similar instruction, the address of the caller’s next instruction will be popped off the stack or out of the link register into the program counter and execution will continue.
<ul>
<li>source: <a target="_blank" rel="noopener" href="https://edstem.org/us/courses/32553/discussion/2623222?comment=6004422">https://edstem.org/us/courses/32553/discussion/2623222?comment=6004422</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>When a Remote Procedure Call happens:
<ul>
<li>A <strong>trap</strong> is issued to the kernel.</li>
<li>The kernel <strong>validates the call</strong> and copies the arguments of the call to the kernel buffers.</li>
<li>The kernel <strong>locates the procedure</strong> to be executes and copies the arguments to its address space.</li>
<li>The kernel <strong>schedules</strong> the server to run the particular procedure.</li>
<li>When the server executes the requests procedure, it returns to the kernel in the same way (<strong>trap</strong> &amp; arguments copy).</li>
<li>The <strong>binding</strong> of an RPC can only happens at <strong>runtime</strong>.</li>
<li>Overhead = Two traps + two context switches + one procedure execution.</li>
<li>NOTE that the data are copied four times: client -&gt; kernel -&gt; server -&gt; kernel -&gt; client</li>
</ul>
</li>
<li>The copying <strong>overhead</strong> that happens with RPCs is a serious concern, since it happens 4 times with every call.
<ul>
<li>1st copy: A client stub will copy the arguments from the client stack and serialize it into an RPC packet.
<ul>
<li>Kernel isn’t involved in this step.</li>
</ul>
</li>
<li>2nd copy: The kernel will copy the arguments to its buffers.</li>
<li>3rd copy: The kernel will copy the arguments from its buffers to the server domain.</li>
<li>4th copy: The server stub will de-serialize the RPC packet and copy the arguments to the server stack.</li>
<li>These four copies are <strong>one-way</strong>, and will be <strong>executed again</strong> to pass the results back from the server to the client.</li>
<li>
<img src="https://i.imgur.com/Q2X5w1D.jpg" style="width: 800px" />
</li>
</ul>
</li>
</ul>
<h3 id="Making-RPC-Cheaper-avoid-copy-overhead">Making RPC Cheaper - avoid copy overhead</h3>
<img src="https://i.imgur.com/H9dC7JZ.jpg" style="width: 800px" />
<ul>
<li>
<p><strong>Binding</strong>: Setting up the relationship between the server and the client in the beginning. It’s a <strong>one-time cost</strong> so it’s OK to leave it as it is.</p>
</li>
<li>
<p>The Binding process:</p>
<ol>
<li>The client calls the entry point procedure of the server, generating a trap in the kernel.</li>
<li>The kernel checks with the server if this client can make calls to the server. Then the server grants permission.</li>
<li>The kernel sets up a Procedure Descriptor (PD) for each procedure provided by servers, with the entry point address, the arguments stack (A-Stack) size, and the allowed number of simultaneous calls from this specific client.</li>
<li>The kernel allocated a buffer shared between the client and the server with the size of the A-Stack (specified by the server). The client and the server can exchange data using this buffer without any intervention from the kernel.</li>
<li>The kernel provides <strong>authentication</strong> to the client in a form of a <strong>Binding Object (BO)</strong>. The client can use this BO to make a call to this specific server in the future without going through the same process. The kernel can find the corresponding server based on the BO.</li>
</ol>
</li>
<li>
<p><strong>The kernel mediation for the binding happens only one time</strong>.</p>
</li>
<li>
<p>Making the actual call:</p>
  <img src="https://i.imgur.com/ezWctT8.jpg" style="width: 800px" />
<ol>
<li>Passing arguments between the client and the server <strong>through the A-Stack</strong> can <strong>only be by value</strong>, not by reference, since the client and server don’t have access to each other’s address space.
<ul>
<li>Note this is not serialization and deserialization, but only a data structure shared by both client and server.</li>
</ul>
</li>
<li>The stub procedure <strong>copies</strong> the arguments from the client memory space into the A-Stack.</li>
<li>The client presented the BO to the kernel (trap) and blocks on the kernel’s response.</li>
<li>At this point, the client will be blocked waiting for the call to be executed. The kernel can use the client thread for executing the procedure on the server’s domain.</li>
<li>The kernel validates the BO and <strong>allocates an execution stack (E-Stack)</strong> for the server to use it <strong>for its own execution</strong>.</li>
<li>The server stub <strong>copies the arguments from the A-Stack to the E-Stack</strong>.</li>
<li>After finishing execution, the server stub <strong>will copy the results from the E-Stack to the A- Stack</strong>.</li>
<li>The server traps the kernel, and everything will be done reversely to return to the client.</li>
</ol>
</li>
<li>
<p>Results of using an A-Stack:</p>
<ol>
<li>Using an A-Stack reduces the number of copies from four to two.</li>
<li>The two copies happen in the client or server user space above the kernel.
<ol>
<li>called marshal and unmarshal</li>
</ol>
</li>
</ol>
<ul>
<li>
<img src="https://i.imgur.com/Lnx96rS.jpg" style="width: 800px" />
</li>
</ul>
</li>
</ul>
<ul>
<li>
<p>Even with this trick, we still have the overhead associated with the context switch itself:</p>
<ol>
<li>The client trap.</li>
<li>Switching the protection domain.</li>
<li>The server trap.</li>
<li>Loss of locality (implicit).</li>
</ol>
</li>
</ul>
<h3 id="RPC-on-SMP">RPC on SMP</h3>
<img src="https://i.imgur.com/hcon3SR.jpg" style="width: 800px" />
<ul>
<li>On a multiprocessor system, we can reduce context switching overhead by caching domains on idle processors. This keeps the caches warm (no TLB invalidation).</li>
<li>When a call is made, the kernel checks for a processor idling in the context of the server domain. If one is found, <strong>the kernel exchanges the processors of the calling and the idling threads</strong>. Then, the called server procedure can execute on that processor without requiring a context switch. Same can be done on return from the call.</li>
<li>Keeping the caches warm reduces the loss of locality.</li>
<li>If the same server is serving multiple clients, the kernel can <strong>pre-load the same server on multiple CPUs</strong> to be able to simultaneously serve multiple clients.</li>
</ul>
<h2 id="Scheduling">Scheduling</h2>
<h3 id="Introduction">Introduction</h3>
<ul>
<li>
<p>How should the scheduler choose the next thread to run on the CPU?</p>
<ul>
<li>First come first serve.</li>
<li>Highest static priority.</li>
<li>Highest dynamic priority.</li>
<li>Thread whose memory contents are in the CPU cache.</li>
</ul>
</li>
<li>
<p>Memory Hierarchy Refresher</p>
<ul>
<li>L1 cache: 1-2 cycles</li>
<li>L2 cache: ~10 cycles</li>
<li>…</li>
<li>Memory: ~100 cycles</li>
</ul>
</li>
<li>
<p>Cache Affinity Scheduling</p>
</li>
</ul>
<img src="https://i.imgur.com/oCPxxYT.jpg" style="width: 800px" />
<ul>
<li>If a thread T1 is running on a particular CPU P1, it’s recommended to run the next call of that thread on the same CPU. The reason behind this is that T1 is likely to find its working set in the caches of P1, which in turn saves time.
<ul>
<li><u>This can be inefficient if another thread T2 polluted the cache of P1</u> between the two calls of T1.</li>
</ul>
</li>
</ul>
<h3 id="Scheduling-Policies">Scheduling Policies</h3>
<ul>
<li>First come first serve (FCFS):
<ul>
<li>The CPU scheduling depends on the order of arrival of the threads.</li>
<li>This policy ignores affinity in favor of fairness.</li>
</ul>
</li>
<li>Fixed processor (Thread-centric):
<ul>
<li>For the first run of a thread, the scheduler will pick a CPU, and will always attach this thread to that CPU.</li>
<li>Selecting the processors might be scheduled by a load balancer depend on the CPU load.</li>
</ul>
</li>
<li>Last processor (Thread-centric):
<ul>
<li>Each CPU will pick the same thread that used to run on it in the last operation cycle.</li>
<li>The reason for this is it’s likely that the process will find its cache on that processor.</li>
<li>This policy favors affinity.</li>
</ul>
</li>
<li>Minimum Intervening (MI) (Processor-centric):
<ul>
<li>We will save the <strong>affinity</strong> of each thread with respect to every processor.</li>
<li>A thread T1 affinity will be saved in the form of an affinity index representing the number of threads that ran on the CPU between T1’s different calls. <strong>The smaller the index the higher the affinity</strong>.</li>
<li>Whenever a processor is free, it will pick the thread with the highest affinity to its cache.</li>
<li><strong>Limited</strong> Minimum Intervening: If a lot of processors are running on the system, <strong>keep only the affinity of the top few processors</strong>.</li>
</ul>
</li>
<li>Minimum Intervening + queue (Processor-centric):
<ul>
<li>This policy will take into consideration not only the affinity index, but also how many threads are in the queue of the CPU when making the scheduling decision.</li>
<li>affinity size + length of the queue</li>
</ul>
</li>
</ul>
<p>In Summary</p>
<ul>
<li>
<img src="https://i.imgur.com/dW3pKYs.jpg" style="width: 800px" />
</li>
</ul>
<h3 id="Implementation-Issues">Implementation Issues</h3>
<ul>
<li>The operating system should maintain a global queue containing all the threads that is available to all the CPUs. This queue will become very huge if the system has a lot of threads.</li>
<li>To solve this issue, the OS would maintain local policy-based queues for every processor.</li>
<li>A thread’s position in the queue will be determined by its priority.</li>
<li>Thread priority = Base priority + thread age + affinity.</li>
<li>If a specific processor ran out of threads, it will pull some threads from other processors.</li>
</ul>
<h3 id="Performance">Performance</h3>
<ul>
<li><strong>Throughput</strong>: How many threads get executed and completed per unit time.
<ul>
<li>-&gt; System centric.</li>
</ul>
</li>
<li><strong>Response time</strong>: When a thread is started, how long it takes to complete execution.
<ul>
<li>-&gt; User centric.</li>
</ul>
</li>
<li><strong>Variance</strong>: Does the response time vary by time?
<ul>
<li>-&gt; User centric.</li>
<li>When picking a scheduling policy, you need to pay attention to the load on each CPU.</li>
<li>In order to boost performance, a CPU might choose to stay idle till the thread with the <strong>highest affinity</strong> becomes available.</li>
<li>But when cpu load is heavy, fixed processor might be better than cache affinity, since the cache might gets</li>
</ul>
</li>
</ul>
<h3 id="Cache-Aware-Scheduling">Cache Aware Scheduling</h3>
<img src="https://i.imgur.com/6fAbXJU.jpg" style="width: 800px" />
<ul>
<li>In a modern multicore system, we have multiple cores on a single processor, and the cores themselves are HW multi-threaded (switching between the core’s threads based on latency).</li>
<li>We need to make sure that all the threads on a specific core can find their contents on either the core’s L1 cache, or at most the L2 cache.</li>
<li>For each core, the OS schedules some cache frugal(节俭的) threads along with some cache hungry threads. This ensures that the amount of cache needed by all threads is less than the total size of the last level cache of the CPU (e.g. L2).
<ul>
<li>cache frugal thread: require less cache</li>
<li>cache hungry thread: require more cache</li>
</ul>
</li>
<li>Determining if a thread is cache frugal or hungry can be done through <strong>system profiling</strong> (additional overhead).</li>
</ul>
<h2 id="Shared-Memory-Multiprocessor-OS">Shared Memory Multiprocessor OS</h2>
<h3 id="Challenges-of-Parallel-Systems">Challenges of Parallel Systems</h3>
<img src="https://i.imgur.com/Sgir3KV.jpg" style="width: 800px" />
* ICN - Inter-connection Network
<ul>
<li>The big size of the system results in bottlenecks for the global data structures.</li>
<li>The memory latency is huge due to faster processors and more complex controllers.</li>
<li><strong>A non-uniform memory access (NUMA) architecture</strong>: Connecting all the nodes in the system through an Inter-connecting Network. The large distance between accessing processors and the target memory results in lower performance.</li>
<li><strong>Deep memory hierarchy</strong> (Multi-cache).</li>
<li><strong>False sharing</strong>: Sometimes the cache hierarchy (large cache lines) makes the memory addresses touched by different threads on different cores to be on the same cache block. This gives the illusion that these addresses are shared (without programmatic sharing). This particularly happens on modern processors because they tend to have larger cache blocks.
<ul>
<li>e.g. An array of 4 integers, and 4 threads are updating the corresponding integer matching with their IDs. Technically they don’t share data, but the array is still shared among four threads because the array is in the same cache line. We can avoid this by forcing each element of the array to be in different cache line so they don’t share anything. But it’s too much work for developers to think of.</li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=OuzYICZUthM&amp;list=PLLX-Q6B8xqZ8n8bwjGdzBJ25X2utwnoEG&amp;index=7">https://www.youtube.com/watch?v=OuzYICZUthM&amp;list=PLLX-Q6B8xqZ8n8bwjGdzBJ25X2utwnoEG&amp;index=7</a></li>
<li><img src="media/16771805621366.jpg" alt=""></li>
</ul>
</li>
</ul>
<h3 id="OS-Design-Principles">OS Design Principles</h3>
<img src="https://i.imgur.com/kdOcyoH.jpg" style="width: 800px" />
<ul>
<li>Exploit <strong>affinity of caches</strong> when taking scheduling decisions.</li>
<li>Pay attention to <strong>locality</strong>.</li>
<li><strong>Limit the amount of sharing</strong> of data structures to reduce contention.</li>
</ul>
<h3 id="Page-Fault-Service">Page Fault Service</h3>
<img src="https://i.imgur.com/9QWTKYu.jpg" style="width: 800px" /> 
<ul>
<li>A page fault service consists of:
<ul>
<li>TLB and Page Table lookup: This is thread specific and can be done in parallel.</li>
<li>Locating the data on disk and moving it to the page frame, then updating the Page Table: This is a bottleneck because these are OS functions and have to be done in series.</li>
<li>TLB update: This is processor specific and can be done in parallel.</li>
</ul>
</li>
<li>There’re two scenarios in parallel OSs:
<ul>
<li>Multi-process workload: If each thread is running independently on a specific CPU, we’ll have distinct page tables and hence no serialization.</li>
<li>Multi-threaded workload: If the address space is shared between different threads, then the page tables and TLB will be shared as well. In this scenario, the OS should ensure that no or minimum serialization happens.</li>
</ul>
</li>
<li><strong>Principles for Scalable Structures in Parallel OS</strong>
<ul>
<li>Determine functionally needs of each service.</li>
<li>To <strong>ensure concurrent executions</strong> of services, <strong>minimize shared</strong> data structures.
<ul>
<li>Less sharing -&gt; more scalable</li>
</ul>
</li>
<li><strong>Replicate/Partition data structures that have to be shared</strong> to reduce locking, meaning more concurrency.</li>
</ul>
</li>
</ul>
<h3 id="Tornado-OS">Tornado OS</h3>
<ul>
<li>
<p>Tornado uses an <strong>object-oriented</strong> approach, where <u>every virtual and physical resource in the system is represented by an independent object</u>. This ensures locality and independence for all resources.</p>
</li>
<li>
<p>Trusted Object: Tornado uses a single object reference for all the OS parts.</p>
</li>
<li>
<p>This single object reference, however, is translated into different physical representations.</p>
</li>
<li>
<p>Degree of clustering (replicating a specific object):</p>
<ul>
<li>Implementer choice.
<ol>
<li>Single representation.</li>
<li>One representation per core.</li>
<li>One representation per CPU.</li>
<li>One representation per group of CPUs.</li>
</ol>
</li>
<li>The consistency of these representations is <strong>maintained through Protected Procedure Calls</strong>.</li>
<li>Don’t use the hardware coherence. Because the hardware cache coherence might cause overhead replicate it to all CPUs. Therefore, you have to worry about keeping these copies consistent with one another.</li>
</ul>
</li>
<li>
<p>Traditional Structure</p>
<ul>
<li>
<img src="https://i.imgur.com/Er7qdWN.jpg" style="width: 800px" />
</li>
</ul>
</li>
<li>
<p>Objectization of Memory Management:</p>
<ul>
<li>
<p>The Address Space will be represented by the “Process Object”, which will be shared by all the threads executing on the CPU.</p>
</li>
<li>
<p>The Address space will be broken into regions:</p>
<ul>
<li>→ Each region will be backed by a “File Cache Manager – FCM” on the File System.</li>
</ul>
</li>
<li>
<p>Another DRAM object will represent the Page Frame Manager, which is responsible for serving page frames for threads.</p>
</li>
<li>
<p>Another object called “Cached Object Representation – COR” will handle page I/O.</p>
</li>
<li>
<p>Whenever a thread incurs a page fault:</p>
<ol>
<li>The Process Object will decide which region this page fault fall into, given the virtual page number.</li>
<li>The Region Object will contact the File Cache Manager.</li>
<li>The FCM will contact the DRAM Object to get the physical page frame.</li>
<li>The FCM will pass the file and offset to COR, which will pull the data from the desk into the DRAM’s page frame.</li>
<li>FCM indicates to the Region Object that the physical page frame has been populated.</li>
<li>The region Object will go through the Process Object to update the TLB.</li>
</ol>
</li>
<li>
<img src="https://i.imgur.com/siuC4YU.jpg" style="width: 800px" />
</li>
<li>
<p>Objectization decisions:</p>
<ol>
<li>The Process Object can be one per CPU, since the TLB is one per CPU.</li>
<li>The Region Object should be one per group of CPUs.</li>
<li>The FCM should be one per group of CPUs.</li>
<li>COR should have a single representation.</li>
<li>DRAM Object can be one per physical memory.</li>
</ol>
</li>
<li>
<p>Advantage of clustered object: Same object reference on all nodes. We can have different replications of the same object, which decreases data structures locking.</p>
</li>
</ul>
</li>
<li>
<p>Implementation of Clustered Object:</p>
<ul>
<li>
<img src="https://i.imgur.com/SyBCNM1.jpg" style="width: 800px" />
</li>
<li>
<img src="https://i.imgur.com/zSkTVfY.jpg" style="width: 800px" />
</li>
<li>
<p>How object reference works in each CPU? Each CPU has:</p>
<ul>
<li>→ <strong>Translation Table</strong>: Maps a object reference to a representation in memory.</li>
<li>→ <strong>Miss Handling Table</strong>: If the object reference is not present in the Translation Table, the Miss Handling Table maps the object reference to Object Miss Handler that decides if this object reference should point to an already existing representation or a new representation should be created. Then, it maps this object reference to its representation and installs the mapping in the Translation Table.</li>
<li>→ <strong>Global Miss Handler</strong>: If the Object Miss Handler is not local, a Global Miss Handler will be used. Every node has a Global Miss Handler, and it knows the partitioning of the Miss Handling Table. If an object reference is presented to the Global Miss Handler, it will resolve the location of the required replica, installs it locally, and populates the Translation Table.</li>
</ul>
</li>
<li>
<p><strong>Non-Hierarchical Locking and Existence Guarantee</strong>:</p>
<ul>
<li>→ <strong>Hierarchical Locking</strong>: Whenever a thread is trying to execute a page fault, it locks the Process Object, the Region Object, the FCM, and the COR. This approach kills concurrency.</li>
<li>→ One way to resolve this is to use an <strong>Existence Guarantee</strong> and a <strong>Reference Count</strong> on the Process Object.
<ul>
<li>// TODO The Reference Count increase every time there is a new thread is referring it</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Dynamic Memory Allocation</strong>:</p>
<ul>
<li>→ Tornado OS breaks up the Heap space into multiple portions, each of which will be located on the physical memory of a specific node. That allows for scalable implementation of DMA.</li>
<li>→ This also prevents false sharing across nodes.</li>
</ul>
</li>
<li>
<p><strong>Inter-Process Communication – IPC</strong>:</p>
<ul>
<li>→ IPC is realized by Protected Procedure Calls (PPCs).
<ul>
<li>→ If the communication is on the same processor, no context switch happens.</li>
<li>→ If the communication is between different processors, full context switch happens.
<ul>
<li>When you modify one replica, you have to make a particular procedure called the other replicas to deflect the other changes that you made In the first replica. So all of these are things that are happening under the cover.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Tornado OS summary:</p>
<ul>
<li>Object oriented design for scalability.</li>
<li>Multiple implementations of OS objects.</li>
<li>Optimize for common case.
<ul>
<li>page fault handing vs region destruction
<ul>
<li>region destruction happens less frequently</li>
</ul>
</li>
</ul>
</li>
<li>No hierarchical locking.</li>
<li>Limited sharing of OS data structures.</li>
</ul>
</li>
</ul>
<h3 id="Corey-OS">Corey OS</h3>
<p>The main principle in structuring an operating system for a shared memory multiprocessor is to limit sharing kernel data structures, which both limits concurrency and increases contention.</p>
<ul>
<li><strong>Address Ranges</strong>: Similar to Tornado’s region concept. The difference is, instead of hiding the regions details from the application, on Corey, the address ranges are exposed to application so that it optimizes execution based on current thread accesses.</li>
<li><strong>Shares</strong>: A facility to be used by any process to communicate to the OS that the process will not share a specific data structure it’s currently using.</li>
<li>Dedicated cores for kernel activities.</li>
</ul>
<h3 id="Cellular-Disco">Cellular Disco</h3>
<ul>
<li>The <strong>Cellular Disco</strong> project explored the possibility of decreasing the virtualization overhead. The idea is to place a virtual layer between the guest OS and the I/O HW.</li>
</ul>
<img src="https://i.imgur.com/p2oO7iL.jpg" style="width: 800px" />
<img src="https://i.imgur.com/pr3jXUg.jpg" style="width: 800px" />
<ul>
<li>
<p>Steps in handling I/O</p>
<ul>
<li>CD runs as a multi-threaded kernel process on top of the host OS(Irix in this case)</li>
</ul>
<ol>
<li>I/O request to CD: check permission; rewrite interrupt vectors</li>
<li>CD forwards the request to the dormant host OS</li>
<li>Host kernel issues the appropriate I/O request(3)
<ul>
<li>After Irix initiates the I/O request, control returns to CD</li>
<li>puts the host kernel back into the dormant state</li>
</ul>
</li>
<li>Upon I/O completion the hardware raises an interrupt</li>
<li>CD reactivates dormant host, making it look as if the I/O interrupt had just been posted
<ul>
<li>Allows host to properly do any cleanup of I/O completion</li>
</ul>
</li>
<li>Finally, CD posts a virtual interrupt to the virtual machine to notify it of the completion of its I/O request</li>
</ol>
</li>
</ul>

</div>


  <div class="book-comments">
    




  </div>



<script src="/js/book-post.js"></script>


<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">
  
  <div class="divider"></div>
</div>

  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>


<script src="/js/book-toc.js"></script>

</div>

      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>


<script src="/js/book.js"></script>
