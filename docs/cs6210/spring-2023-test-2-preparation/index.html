<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/favicon.png" />
    

    <title>
        
          Eric&#39;s CS Notes
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    
<link rel="stylesheet" href="/css/book.css">

    
<script src="/js/book.js"></script>


    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.css">
    
    <!-- katex css -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous">

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/">
    <img src="/favicon.png">
    <span>ERIC&#39;S CS NOTES</span>
  </a>
</div>

    <div class="book-menu">
  <!--
## Introduction to Probability

* [Unit 1: Probability models and axioms](/introduction-to-probability/unit-1/index.html)
* [Unit 2: Conditioning and independence](/introduction-to-probability/unit-2/index.html)
* [Unit 3: Counting](/introduction-to-probability/unit-3/index.html)
* [Unit 4: Discrete random variables](/introduction-to-probability/unit-4/index.html)
* [Unit 5: Continuous random variables](/introduction-to-probability/unit-5/index.html)
* [Unit 6: Further topics on random variables](/introduction-to-probability/unit-6/index.html)
* [Unit 7: Bayesian inference](/introduction-to-probability/unit-7/index.html)
* [Unit 8: Limit theorems and classical statistics](/introduction-to-probability/unit-8/index.html)
* [Unit 9: Bernoulli and Poisson processes](/introduction-to-probability/unit-9/index.html)
* [Unit 10: Markov chains](/introduction-to-probability/unit-10/index.html)
-->
<!--
## Multivariable Calculus

* [Unit 1: Thinking about multivariable functions](/multivariable-calculus/unit-1/index.html)
* [Unit 2: Derivatives of multivariable functions](/multivariable-calculus/unit-2/index.html)

* [Unit 3: Applications of multivariable derivatives](/multivariable-calculus/unit-3/index.html)
* [Unit 4: Integrating multivariable functions](/multivariable-calculus/unit-4/index.html)
* [Unit 5: Green's, Stokes', and the divergence theorems](/multivariable-calculus/unit-5/index.html)
-->
<h2 id="cs6210-advanced-operating-systems"><a class="markdownIt-Anchor" href="#cs6210-advanced-operating-systems"></a> CS6210: Advanced Operating Systems</h2>
<ul>
<li><a href="/cs6210/lesson-02/index.html">Lesson 2: OS Structure</a></li>
<li><a href="/cs6210/lesson-03/index.html">Lesson 3: Virtualization</a></li>
<li><a href="/cs6210/lesson-04a/index.html">Lesson 4: Parallel Systems - Part 1</a></li>
<li><a href="/cs6210/lesson-04b/index.html">Lesson 4: Parallel Systems - Part 2</a></li>
<li><a href="/cs6210/lesson-05/index.html">Lesson 5: Distributed Systems</a></li>
<li><a href="/cs6210/lesson-06/index.html">Lesson 6: Distributed Objects and Middleware</a></li>
<li><a href="/cs6210/lesson-07a/index.html">Lesson 7: Distributed Subsystems - GMS</a></li>
<li><a href="/cs6210/lesson-07b/index.html">Lesson 7: Distributed Subsystems - DSM</a></li>
<li><a href="/cs6210/lesson-07c/index.html">Lesson 7: Distributed Subsystems - DFS</a></li>
<li><a href="/cs6210/lesson-09/index.html">Lesson 9: Internet Computing</a></li>
<li><a href="/cs6210/lesson-10/index.html">Lesson 10: RT and Multimedia</a></li>
</ul>
<!--
* [Lesson 8: Failures and Recovery](/cs6210/lesson-08/index.html)
* [Lesson 11: Security](/cs6210/lesson-11/index.html)
-->
<h2 id="cs6250-computer-networks"><a class="markdownIt-Anchor" href="#cs6250-computer-networks"></a> CS6250 Computer Networks</h2>
<ul>
<li><a href="/cs6250/week-1-internet-architecture/index.html">Week 1 - Internet Architecture</a></li>
<li><a href="/cs6250/week-2-transport-and-application-layers/index.html">Week 2 - Transport and Application Layers</a></li>
<li><a href="/cs6250/week-3-intradomain-routing/index.html">Week 3 - Intradomain Routing</a></li>
<li><a href="/cs6250/week-4-as-relationships-and-interdomain-routing/index.html">Week 4 - AS Relationships and Interdomain Routing</a></li>
<li><a href="/cs6250/week-5-router-design-and-algorithems-part-1/index.html">Week 5 - Router Design and Algorithms (Part 1)</a></li>
<li><a href="/cs6250/week-6-router-design-and-algorithems-part-2/index.html">Week 6 - Router Design and Algorithms (Part 2)</a></li>
<li><a href="/cs6250/week-7-software-defined-networking-part-1/index.html">Week 7 - Software Defined Networking (Part 1)</a></li>
<li><a href="/cs6250/week-8-software-defined-networking-part-2/index.html">Week 8 - Software Defined Networking (Part 2)</a></li>
<li><a href="/cs6250/week-9-internet-security/index.html">Week 9 - Internet Security</a></li>
<li><a href="/cs6250/week-10-internet-surveillance-and-censorship/index.html">Week 10 - Internet Surveillance and Censorship</a></li>
<li><a href="/cs6250/week-11-applications-video/index.html">Week 11 - Applications Videos</a></li>
<li><a href="/cs6250/week-12-applications-cdns-and-overlay-networks/index.html">Week 12 - Applications CDNs and Overlay Networks</a></li>
</ul>
<h2 id="cs6200-graduate-introduction-to-operating-systems"><a class="markdownIt-Anchor" href="#cs6200-graduate-introduction-to-operating-systems"></a> CS6200 Graduate Introduction to Operating Systems</h2>
<ul>
<li><a href="/cs6200/p1-preparation/index.html">P0 - Preparation</a></li>
<li><a href="/cs6200/p1l2-introduction/index.html">P1L2 - Introduction</a></li>
<li><a href="/cs6200/p2l1-processes-and-process-management/index.html">P2L1 - Processes and Process Management</a></li>
<li><a href="/cs6200/p2l2-threads-and-concurrency/index.html">P2L2 - Threads and Concurrency</a></li>
<li><a href="/cs6200/p2l3-pthread/index.html">P2L3 - PThread</a></li>
<li><a href="/cs6200/p2l4-thread-design-consideration/index.html">P2L4 - Thread Design Considerations</a></li>
<li><a href="/cs6200/p2l5-thread-performance-consideration/index.html">P2L5 - Thread Performance Considerations</a></li>
<li><a href="/cs6200/p3l1-scheduling/index.html">P3L1 - Scheduling</a></li>
<li><a href="/cs6200/p3l2-memory-management/index.html">P3L2 - Memory Management</a></li>
<li><a href="/cs6200/p3l3-inter-process-communication/index.html">P3L3 - Inter-Process Communication</a></li>
<li><a href="/cs6200/p3l4-synchronization-constructs/index.html">P3L4 - Synchronization Constructs</a></li>
<li><a href="/cs6200/p3l5-io-management/index.html">P3L5 - I/O Management</a></li>
<li><a href="/cs6200/p3l6-virtualization/index.html">P3L6 - Virtualization</a></li>
</ul>
<!--
* [P4L1 - Remote Procedure Calls](/cs6200/p4l1-remote-procedure-calls/index.html) 
* [P4L2 - Distributed File Systems](/cs6200/p4l2-distributed-file-systems/index.html) 
* [P4L3 - Distributed Shared Memory](/cs6200/p4l3-distributed-shared-memory/index.html) 
* [P4L4 - Datacenter Technologies](/cs6200/p4l4-datacenter-technologies/index.html) 
-->
<h2 id="algorithms-part-ii"><a class="markdownIt-Anchor" href="#algorithms-part-ii"></a> Algorithms: Part II</h2>
<ul>
<li><a href="/algorithms-2/week-1/index.html">Week 1 - Undirected Graph &amp; Directed Graph</a></li>
<li><a href="/algorithms-2/week-2/index.html">Week 2 - Minimum Spanning Trees &amp; Shortest Path</a></li>
<li><a href="/algorithms-2/week-3/index.html">Week 3 - Maximum Flow and Minimum Cut &amp; String Sort</a></li>
<li><a href="/algorithms-2/week-4/index.html">Week 4 - Tries &amp; Substring Search</a></li>
<li><a href="/algorithms-2/week-5/index.html">Week 5 - Regular Expressions</a></li>
<li><a href="/algorithms-2/week-6/index.html">Week 6 - Reductions</a></li>
</ul>
<h2 id="algorithms-part-i"><a class="markdownIt-Anchor" href="#algorithms-part-i"></a> Algorithms: Part I</h2>
<ul>
<li><a href="/algorithms-1/week-1/index.html">Week 1 - Union-Find &amp; Analysis of Algorithms</a></li>
<li><a href="/algorithms-1/week-2/index.html">Week 2 - Stacks and Queues &amp; Elementary Sorts</a></li>
<li><a href="/algorithms-1/week-3/index.html">Week 3 - Mergesort &amp; Quicksort</a></li>
<li><a href="/algorithms-1/week-4/index.html">Week 4 - Priority Queues &amp; Elementary Symbols</a></li>
<li><a href="/algorithms-1/week-5/index.html">Week 5 - Balanced Search Trees</a></li>
<li><a href="/algorithms-1/week-6/index.html">Week 6 - Hash Tables</a></li>
</ul>
<h2 id="introduction-to-software-design-and-architecture"><a class="markdownIt-Anchor" href="#introduction-to-software-design-and-architecture"></a> Introduction to Software Design and Architecture</h2>
<ul>
<li><a href="/introduction-to-software-design-and-architecture/design-pattern/index.html">Design Pattern</a></li>
</ul>
<h2 id="calculus-two-sequences-and-series"><a class="markdownIt-Anchor" href="#calculus-two-sequences-and-series"></a> Calculus Two: Sequences and Series</h2>
<ul>
<li><a href="/calculus-two/week-1/index.html">Week 1 - Sequences</a></li>
<li><a href="/calculus-two/week-2/index.html">Week 2 - Series</a></li>
<li><a href="/calculus-two/week-3/index.html">Week 3 - Convergence Tests</a></li>
<li><a href="/calculus-two/week-4/index.html">Week 4 - Alternating Series</a></li>
<li><a href="/calculus-two/week-5/index.html">Week 5 - Power Series</a></li>
<li><a href="/calculus-two/week-6/index.html">Week 6 - Taylor Series</a></li>
</ul>
<h2 id="laff-linear-algebra"><a class="markdownIt-Anchor" href="#laff-linear-algebra"></a> LAFF Linear Algebra</h2>
<ul>
<li><a href="/laff-linear-algebra/week-1/index.html">Week 1 - Vectors in Linear Algebra</a></li>
<li><a href="/laff-linear-algebra/week-2/index.html">Week 2 - Linear Transformations and Matrices</a></li>
<li><a href="/laff-linear-algebra/week-3/index.html">Week 3 - Matrix-Vector Operations</a></li>
<li><a href="/laff-linear-algebra/week-4/index.html">Week 4 - Matrix-Vector to Matrix-Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-5/index.html">Week 5 - Matrix- Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-6/index.html">Week 6 - Gaussian Elimination</a></li>
<li><a href="/laff-linear-algebra/week-7/index.html">Week 7 - More Gaussian Elimination and Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-8/index.html">Week 8 - More on Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-9/index.html">Week 9 - Vector Spaces</a></li>
<li><a href="/laff-linear-algebra/week-10/index.html">Week 10 - Vector Spaces, Orthogonality, and Linear Least-Squares</a></li>
<li><a href="/laff-linear-algebra/week-11/index.html">Week 11 - Orthogonal Projection, Low Rank Approximation, and Orthogonal Bases</a></li>
<li><a href="/laff-linear-algebra/week-12/index.html">Week 12 - Eigenvalues and Eigenvectors</a></li>
</ul>
<h2 id="stanford-machine-learning"><a class="markdownIt-Anchor" href="#stanford-machine-learning"></a> Stanford Machine Learning</h2>
<ul>
<li><a href="/stanford-machine-learning/week-1/index.html">Week 1 - Introduction</a></li>
<li><a href="/stanford-machine-learning/week-2/index.html">Week 2 - Linear Regression with Multiple Variables</a></li>
<li><a href="/stanford-machine-learning/week-3/index.html">Week 3 - Logistic Regression &amp; Regularization</a></li>
<li><a href="/stanford-machine-learning/week-4/index.html">Week 4 - Neural Networks: Representation</a></li>
<li><a href="/stanford-machine-learning/week-5/index.html">Week 5 - Neural Networks: Learning</a></li>
<li><a href="/stanford-machine-learning/week-6a/index.html">Week 6a - Advice for Applying Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-6b/index.html">Week 6b - Machine Learning System Design</a></li>
<li><a href="/stanford-machine-learning/week-7/index.html">Week 7 - Support Vector Machines</a></li>
<li><a href="/stanford-machine-learning/week-8/index.html">Week 8 - Unsupervised Learning &amp; Dimensionality Reduction</a></li>
<li><a href="/stanford-machine-learning/week-9a/index.html">Week 9a - Anomaly Detection</a></li>
<li><a href="/stanford-machine-learning/week-9b/index.html">Week 9b - Recommender Systems</a></li>
<li><a href="/stanford-machine-learning/week-10/index.html">Week 10 - Large Scale Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-11/index.html">Week 11 - Application Example: Photo OCR</a></li>
</ul>
<h2 id="calculus-one"><a class="markdownIt-Anchor" href="#calculus-one"></a> Calculus One</h2>
<ul>
<li><a href="/calculus-one/week-2-3/index.html">Week 2-3 - Functions &amp; Limits</a></li>
<li><a href="/calculus-one/week-4/index.html">Week 4 - The Beginning of Derivatives</a></li>
<li><a href="/calculus-one/week-5/index.html">Week 5 - Techniques of Differentiation</a></li>
<li><a href="/calculus-one/week-6/index.html">Week 6 - Chain Rule</a></li>
<li><a href="/calculus-one/week-7/index.html">Week 7 - Derivatives of Trigonometric Functions</a></li>
<li><a href="/calculus-one/week-8/index.html">Week 8 - Derivatives in the Real World</a></li>
<li><a href="/calculus-one/week-9/index.html">Week 9 - Optimization</a></li>
<li><a href="/calculus-one/week-10/index.html">Week 10 - Linear Approximation</a></li>
<li><a href="/calculus-one/week-11-12/index.html">Week 11-12 - Antidifferentiation &amp; Integration</a></li>
<li><a href="/calculus-one/week-13/index.html">Week 13 - Fundamental Theorem of Calculus</a></li>
<li><a href="/calculus-one/week-14/index.html">Week 14 - Substitution Rule</a></li>
<li><a href="/calculus-one/week-15/index.html">Week 15 - Techniques of Integration</a></li>
<li><a href="/calculus-one/week-16/index.html">Week 16 - Applications of Integration</a></li>
</ul>
<h2 id="computational-thinking"><a class="markdownIt-Anchor" href="#computational-thinking"></a> Computational Thinking</h2>
<ul>
<li><a href="/computational-thinking/lecture-1/index.html">Lecture 1 - Optimization and Knapsack Problem</a></li>
<li><a href="/computational-thinking/lecture-2/index.html">Lecture 2 - Decision Trees and Dynamic Programming</a>
<ul>
<li><a href="/computational-thinking/lecture-2-powerset/index.html">Exercise: Power Set Function</a></li>
</ul>
</li>
<li><a href="/computational-thinking/lecture-3/index.html">Lecture 3 - Graphs</a></li>
<li><a href="/computational-thinking/lecture-4-5/index.html">Lecture 4-5 - Plotting</a></li>
<li><a href="/computational-thinking/lecture-6-7/index.html">Lecture 6-7 - Stochastic Programs &amp; Inferential Statistics</a></li>
<li><a href="/computational-thinking/lecture-8/index.html">Lecture 8 - Monte Carlo Simulation</a></li>
<li><a href="/computational-thinking/lecture-9/index.html">Lecture 9 - Sampling and Standard Error</a></li>
<li><a href="/computational-thinking/lecture-10-11/index.html">Lecture 10-11 - Experimental Data</a></li>
<li><a href="/computational-thinking/lecture-12/index.html">Lecture 12 - Machine Learning</a></li>
<li><a href="/computational-thinking/lecture-13/index.html">Lecture 13 - Statistical Abuses</a></li>
</ul>
<h2 id="effective-thinking-through-mathematics"><a class="markdownIt-Anchor" href="#effective-thinking-through-mathematics"></a> Effective Thinking Through Mathematics</h2>
<ul>
<li><a href="/effective-thinking-through-mathematics/note/index.html">Note</a></li>
<li><a href="/effective-thinking-through-mathematics/week-4-telling-the-story-of-infinity/index.html">Week 4 (/Telling the Story of Infinity)</a></li>
<li><a href="/effective-thinking-through-mathematics/week-5-telling-the-story-of-the-euler-circuit-theorem/index.html">Week 5 (/Telling the Story of Euler Circuit Theorem)</a></li>
</ul>
<h2 id="cs50-introduction-to-computer-science"><a class="markdownIt-Anchor" href="#cs50-introduction-to-computer-science"></a> CS50 Introduction to Computer Science</h2>
<ul>
<li><a href="/cs50/week-1/index.html">Week 1 - C</a></li>
<li><a href="/cs50/week-2/index.html">Week 2 - Arrays</a></li>
<li><a href="/cs50/week-3/index.html">Week 3 - Algorithms</a></li>
<li><a href="/cs50/week-4/index.html">Week 4 - Memory</a></li>
<li><a href="/cs50/week-5/index.html">Week 5 - Data Structures</a></li>
<li><a href="/cs50/week-6/index.html">Week 6 - HTTP</a></li>
<li><a href="/cs50/week-7-10/index.html">Week 7-10 - Machine Learning/Python/SQL/Javascript</a></li>
</ul>
<h2 id="others"><a class="markdownIt-Anchor" href="#others"></a> Others</h2>
<ul>
<li><a href="/symbols/index.html">Symbols of Mathematics</a></li>
<li><a href="/glossary/index.html">Glossary</a></li>
</ul>
<h2 id="about-me"><a class="markdownIt-Anchor" href="#about-me"></a> <a target="_blank" rel="noopener" href="https://ericy.me/about/">About Me</a></h2>

</div>


<script src="/js/book-menu.js"></script>

  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1 id="omscs-6210-spring-2023-test-2"><a class="markdownIt-Anchor" href="#omscs-6210-spring-2023-test-2"></a> OMSCS 6210 Spring 2023 Test 2</h1>
<h2 id="distributed-systems"><a class="markdownIt-Anchor" href="#distributed-systems"></a> Distributed Systems</h2>
<h3 id="i-lamports-logical-clock"><a class="markdownIt-Anchor" href="#i-lamports-logical-clock"></a> I. Lamport’s Logical Clock</h3>
<p>A. [2 points] Lamport’s logical clock is an intellectually appealing  strategy for maintaining the state of communicating processes in a  distributed system. What is deficient about logical clocks that  necessitates the physical clock formalism by Lamport in the same  paper?</p>
<ul>
<li><strong>Lack</strong> mechanisms to <strong>synchronize</strong> processes with respect to physical time.</li>
<li><code>happen-before</code> <strong>doesn’t guarantee</strong> that the assigned timestamps will be consistent with actual <strong>real-time order</strong>.</li>
</ul>
<p>B. [4 points] Assume a system where clocks on nodes do not drift and  the network communication time is constant. Do we still need a  Lamport’s clock to determine “happened before” relations? Explain.</p>
<p>Yes.</p>
<ol>
<li>Even with no drift clock and network issue, the <strong>clock synchronization</strong> among multiple nodes is still hard to achieve. Besides, the time for processing events varies, which leaves uncertainties to the event orders. &lt;-- NTP</li>
<li>Physical locks can’t <strong>differentiate events that occur in a rapid succession</strong>. As a result, the events with close timestamps might be incorrectly ordered.</li>
<li>Lamport’s logical clocks can help establish partial orders for concurrent events based on <strong>causal relationships</strong>, which cannot be achieved using physical clocks alone.</li>
</ol>
<h3 id="ii-lamports-me-algorithm"><a class="markdownIt-Anchor" href="#ii-lamports-me-algorithm"></a> II. Lamport’s ME Algorithm</h3>
<p>A. [5 points] Construct a simple ordering of events involving two  processes (P1 and P2) where Lamport’s algorithm violates mutual  exclusion, where P2 acquires mutex when it has already been acquired  by P1.</p>
<p>Give your answer in the form of a sequence of one of the following  events. Show the state of the queues at P1 and P2 wherever  necessary, and clearly indicate which messages were delivered out of  order.</p>
<p>• SEND LOCK/ACK/UNLOCK P1 -&gt; P2 (P1 sends lock/ack/unlock to P2)<br>
• RECV LOCK/ACK/UNLOCK P1 -&gt; P2 (P2 receives lock/ack/unlock  sent by P1) <br>
• ACQUIRE P1 (P1 acquires lock)</p>
<p>–<br>
SEND LOCK P1 -&gt; P2 got delayed</p>
<ul>
<li>Queue(P1): [(P1, t1)]</li>
<li>Queue(P2): []<br>
SEND LOCK P2 -&gt; P1</li>
<li>Queue(P1): []</li>
<li>Queue(P2): [(P2, t2)]<br>
RECV LOCK P2 -&gt; P1</li>
<li>Queue(P1): [(P1, t1), (P2, t2)]</li>
<li>Queue(P2): [(P2, t2)]<br>
SEND ACK P1 -&gt; P2<br>
ACQUIRE P2 (out of order due to not receiving the lock message)<br>
RECV LOCK P1 -&gt; P2 (got the lock message, but it’s too late)</li>
<li>Queue(P1): [(P1, t1), (P2, t2)]</li>
<li>Queue(P2): [(P1, t1), (P2, t2)]<br>
SEND ACK P2 -&gt; P1<br>
ACQUIRE P1</li>
</ul>
<p>B. [3 points] Construct a simple example of a sequence of events involving two processes P1 and P2, where “progress” is violated,  that is, in a situation where the mutex previously held by P1 has  been released, but P2 is not able to acquire it.</p>
<p>Use the format shown in part (A) for the sequence of events, and  clearly indicate which message was lost.</p>
<p>SEND LOCK P1 -&gt; P2<br>
SEND LOCK P2 -&gt; P1<br>
SEND ACK P2-&gt; P1<br>
SEND ACK P1-&gt; P2<br>
ACQUIRE P1<br>
SEND UNLOCK P1-&gt;P2 (got lost)</p>
<p>C. [2 points] The correctness of the basic Lamport’s ME algorithm  depends on no message loss. You want to relax this requirement and  yet assure correctness. How would you do it?</p>
<p>So we still have message in order and queues are in total order.</p>
<p>Make it as TCP protocol-like, when receiving a message bump the SEQ number and send a ACK. If the SEQ is missed, ask for a resend.</p>
<p>D. [2 points] Your co-worker asserts that for the correctness of the  basic Lamport’s ME algorithm, messages from a given process P1 to  all other processes in the entire distributed system must arrive in  the order in which they are sent from P1. Is she right? You should  justify your answer with an explanation.</p>
<p>She is right. If messages arrive out of order, the <code>happens-before</code> relation may be violated, leading to <strong>incorrect order of lock requests</strong> in the queue.</p>
<h3 id="iii-latency-reduction-in-rpc"><a class="markdownIt-Anchor" href="#iii-latency-reduction-in-rpc"></a> III. Latency Reduction in RPC</h3>
<p>A. [2 points] Thekkath and Levy suggest using a shared descriptor  between the client stub and the kernel for marshalling arguments  during an RPC call. Your friend argues that this does not result in  reducing the copying overhead of an RPC call. How would you counter  her argument?</p>
<p>In the traditional RPC mechanism, the client stub marshals the arguments into a buffer, which is then copied into kernel space which costs significant overhead. By sharing the same descriptor, the copy from user space to kernel space can be eliminated.</p>
<p>B. [4 points] Consider the following control transfers involved in an  RPC call.</p>
<p><img src="https://lh4.googleusercontent.com/jV3e22BqOf9vlb9zpw7dSCxlyxUhVGvIkDhEvjwJ5j_rBiFMfIa_CEIRpby2HVGaXsklsmlODOOxHNsXh1VSEwR6seJYUSmOOc2OumJ30RgGynJJ4yE4H0en-dmH-aQFSBMXzmTElvqruHHcQM-9SbY" alt=""></p>
<p>Out of these, identify the ones that are in the critical path. Why are  the identified calls considered in the critical path while others are  not?</p>
<p>There are two paths are considered critical. One is when the call arrivals on the server, it needs to do context switch from other processes to serve the incoming calls. The other one is, when the results arrive to the client, the client needs to do context switch to handle the response.</p>
<p>C. [4 points] You have designed an RPC system which has the following  parameters:</p>
<p>• T: Message transmission time in either direction for sending the  arguments of the call or receiving the results (includes protocol  processing, time on the wire, and interrupt processing)</p>
<p>• CSc = 3T: Context switch time at the client node</p>
<p>• CSs= T: Context switch time at the server node</p>
<p>You notice from the logs that the server procedure execution time is  bimodal: it takes T units of time mostly but occasionally 20T units  of time.</p>
<p>How would you optimize the latency for RPC calls for this client server interaction?</p>
<p>In a normal route, the request takes 4T(1T on the wire, 1T for server to do context switch, 1T for execution, 1T for transfer back to client) to get back. So in my design, the client will do context switch if it doesn’t get a response from the server.</p>
<h3 id="iv-active-networks"><a class="markdownIt-Anchor" href="#iv-active-networks"></a> IV. Active Networks</h3>
<p>A. In an Active Network, we expect the intermediate routers to execute  code by looking at the “type” field of the capsule present in the  incoming packet. For a “type” that it has not seen before, it  requests the code from the node present in the “prev” field.</p>
<ol>
<li>[2 points] Is it possible for the “prev” node to not have the code  corresponding to the “type” of the incoming packet? Explain why.</li>
</ol>
<p>Yes, each router only has a limited size of soft store, the code might be discarded from its cache because its cache eviction policies.</p>
<ol start="3">
<li>[2 points] Given that the active store uses LRU to replace items  from it, why would the “prev” node NOT have the code corresponding  to the “type” field?</li>
</ol>
<p>In a very intense network, the request to <code>prev</code> node might get delayed, and the code gets evicted before the request arrives.</p>
<ol start="4">
<li>[2 points] How is this situation handled in Active Networks? Why?</li>
</ol>
<p>The router will drop the packet if it can’t find the code in its own cache or the prev node’s cache. We rely on higher level protocol to handle the situation, e.g. re-transmit the packet.</p>
<h2 id="distributed-objects-and-middleware"><a class="markdownIt-Anchor" href="#distributed-objects-and-middleware"></a> Distributed Objects and Middleware</h2>
<h3 id="v-spring-os"><a class="markdownIt-Anchor" href="#v-spring-os"></a> V. Spring OS</h3>
<p>A. [2 points] What purpose does the memory object abstraction serve in  the virtual memory subsystem of the Spring Kernel?</p>
<ul>
<li>Memory object abstraction allows multiple memory regions to <strong>share the same memory objects</strong>.</li>
<li>It also allows the virtual memory manager to <strong>handle various types of backing storage for memory regions</strong>, the virtual memory can be associated with backing files or swap space on disk, etc.</li>
</ul>
<p>B. [2 points] Your co-worker argues that Spring Kernel’s memory  management does not offer any extensibility features. How would you  counter that argument?</p>
<ul>
<li>VMM enables extensibility by using <strong>memory object as an abstraction layer</strong>, which allows virtual memory regions to be associated with various backing storage.</li>
<li>By using <strong>external pagers</strong> for managing the memory objects, it allows implementing different policies and algorithms for memory management.</li>
</ul>
<h3 id="vi-ejb"><a class="markdownIt-Anchor" href="#vi-ejb"></a> VI. EJB</h3>
<p>A. [6 points] You have a startup to implement a portal for airline  reservations. The clients come to you over an insecure wide-area  network. These are the objectives which are your “secret sauce” for  the startup:</p>
<p>• You want to exploit parallelism across independent client request • You want to exploit parallelism within each client request</p>
<p>• You want to protect your business logic from being exposed to the  wide-area Internet</p>
<p>You are planning to use EJB for meeting these objectives. Your N-tier  solution has a Web container, an EJB container, and a Database server.  To meet the design objectives:</p>
<ol>
<li>
<p>[2 points] What functionalities would you put into the Web container  (that interfaces with the client browsers)?</p>
</li>
<li>
<p>[4 points] What functionalities would you put into the EJB  container? Justify</p>
</li>
</ol>
<p>There are two components we need to allocate: <strong>presentation logic</strong>, <strong>business logic</strong>. The entity bean can be separated from the business logic to get better performance &amp; scalability.</p>
<p>In this question, we can put the presentation logic into web container to have parallelism across independent client requests. And put business logic into the EJB container for protection to the business logic.</p>
<p>We also need to separate the <strong>Entity Bean</strong> with the business logic so the requests within a client can be executed in parallel.</p>
<h3 id="vii-java-rmi"><a class="markdownIt-Anchor" href="#vii-java-rmi"></a> VII. Java RMI</h3>
<p>A. [4 points] Java RMI evolved from the Spring Subcontract mechanism.  Name one similarity and one difference in the implementation of the  two systems.</p>
<p>S: Both use interfaces to hide the implementation and communication details<br>
D: RMI exploits the semantics of JAVA for marshalling and unmarshalling while subcontract use IDL to be language independent.</p>
<p>B. [2 points] Java allows object references to be passed as parameters  during object invocation. What is the difference in parameter  passing (when a local object reference is passed as a<br>
parameter)  while invoking a remote object using Java RMI?</p>
<p>The difference is, the passing machanims for remote object is value/result, meaning a copy of the object is sent to the invoked method. In contrast, local objects pass a pure reference.</p>
<h2 id="distributed-subsystems"><a class="markdownIt-Anchor" href="#distributed-subsystems"></a> Distributed Subsystems</h2>
<h3 id="viii-gms"><a class="markdownIt-Anchor" href="#viii-gms"></a> VIII. GMS</h3>
<p>A. [2 points] Is it possible for a page X to be present in the “local”  part of two nodes N1 and N2 at the same time? If yes, explain how.</p>
<p>Yes, the pages in local can be shared among multiple nodes. When it happens, the page will be copied over to the others’ local for accessing.</p>
<p>B. [4 points] N1 faults on page X; N1’s global part is empty; N2 has  the oldest page in the entire cluster in its global part; the missing page X is not in cluster memory. List the steps that will  ensue to service this page fault.</p>
<ol>
<li>N1 sends its LRU page to N2’s global part</li>
<li>N2 swap out its LRU page and store the page from N1</li>
<li>N1 bring in the page X from disk into its local memory.</li>
</ol>
<p>C. [8 points] Assume that we have a set of Nodes N1, N2 and N3 in a  Global Memory System. The previous epoch of the geriatrics algorithm  has just ended. Now each of the nodes send age information for each  of their Local and Global pages to the initiator. The age  information sent by each node is shown below:</p>
<p>Node N1: [LP1: 5, LP2: 7, LP3: 4, GP1: 11, GP2: 2]</p>
<p>Node N2: [LP1: 1, LP2: 8, GP1: 3, GP2: 3, GP3: 9]</p>
<p>Node N3: [LP1: 13, LP2: 15, LP3: 4, LP4: 1, LP5: 10]</p>
<p>The integers corresponding to each page denote its age (a page with  age 10 is older than a page with age 5)</p>
<p>We choose the parameter for Max Page replacement M = 6 (assume that  the parameter T for epoch duration does not play a role here)</p>
<ol>
<li>[6 points] List down the response sent by the initiator to each  of the nodes while clearly stating what each section of the  response means. [Hint: each “weight” field in the response must  be denoted as a percentage value or as a ratio]</li>
</ol>
<p>The oldest pages are 15, 13, 11, 10, 9, 8</p>
<p>{MinAge 8, (W1 = 1/6, W2 = 2/6, W3 = 3/6)}</p>
<ol start="3">
<li>[2 point] Which node is selected as the initiator in the next  epoch? Why?</li>
</ol>
<p>N3, because it has the highest weight, hence it is the least active node.</p>
<h3 id="ix-dsm"><a class="markdownIt-Anchor" href="#ix-dsm"></a> IX. DSM</h3>
<p>A. [6 points] Consider a page-based software DSM system that implements  a single-writer multiple-reader coherence protocol. A process P on  Node N1 wants to write to page X. The page X is present in N1 but  it is marked read-only. Node N3 is the owner of page X which is  currently read-shared by nodes N1, N2, and N3. List the steps  involved in handling this situation to allow process P to be able to  write to page X.</p>
<ol>
<li>When process P on Node N1 attempts to write to the page X, a page fault occurs. The DSM software communicates with the OS to handle the page fault.</li>
<li>The DSM software on N1 determines the current owner of the page X which is N3.</li>
<li>N1 send a write permission request to N3.</li>
<li>N3 send invalidation messages to the nodes that have read-shared copies.</li>
<li>N2 and N3 acknowledge the invalidation requests.</li>
<li>N3 update the page X as write-exclusive for N1 and inform N1.</li>
<li>N1 acknowledge the update and continue the work of process P.</li>
</ol>
<h3 id="x-dfs"><a class="markdownIt-Anchor" href="#x-dfs"></a> X. DFS</h3>
<p>A. [4 points] Consider the xFS file system.</p>
<ul>
<li>Node Nf is the manager node for a file F1</li>
<li>Assume that coherence is maintained at the granularity of individual  files</li>
<li>F1 is currently read-shared by nodes N1, N2, and N3</li>
</ul>
<p>The following events happen:</p>
<ul>
<li>Time T1: Node N1 attempts to write to file Nf</li>
<li>Time T2: Node N2 attempts to read the file Nf</li>
</ul>
<ol>
<li>
<p>[2 points] List the actions that would take place at time T1</p>
</li>
<li>
<p>N1 send a request to Nf for write access to F1,</p>
</li>
<li>
<p>Nf send invalidation messages to N2 and N3.</p>
</li>
<li>
<p>Upon receiving the acknowledgements, Nf grant N1 the write-exclusive access.</p>
</li>
<li>
<p>N1 receives the confirmation and proceeds with writing to file F1.</p>
</li>
<li>
<p>[2 points] List the actions that would take place at time T2.</p>
</li>
<li>
<p>N2 send read access request to Nf</p>
</li>
<li>
<p>Nf check the status of file F1, and send a downgrade message to N1</p>
</li>
<li>
<p>N1 acknowledges the downgrade message to Nf after downgrading its access to read-shared.</p>
</li>
<li>
<p>Nf downgrade F1 as read-shared.</p>
</li>
<li>
<p>Nf grants read access to N2.</p>
</li>
<li>
<p>Up receiving the confirmation, N2 proceeds with read to the file F1.</p>
</li>
</ol>
<p>B. [2 points]  Why do file systems procrastinate writing a file to stable storage as  soon as the process that is doing the write closes the file?</p>
<p>To improve disk I/O and solve the small write problem</p>
<p>C. [2 points] In xFS, what purpose does the “log segment” data structure of the file  system serve?</p>
<p>Log segment is an append-only data structure, which improves write performance and allow more efficient, continuous disk access. It also minimizes disk seek operations and provide better write throughput.</p>
<p>D. [2 points] Distinguish between static and dynamic metadata  management.</p>
<p>Static: metadata allocation and distribution are predetermined. It simplifies metadata management and lookup. But potentially, it has load imbalance and limited scalability problem.<br>
Dynamic: metadata can be reassigned to different nodes based on factors such as load, access patterns, or system changes. It offers better load balancing, and better scalability. But also introduces complexities in metadata lookup and management.</p>
<h2 id="missing"><a class="markdownIt-Anchor" href="#missing"></a> Missing</h2>
<p>L5e<br>
L6a nucleus<br>
L7a Data Structures<br>
L7b eager RC vs lazy RC</p>

</div>


  <div class="book-comments">
    




  </div>



<script src="/js/book-post.js"></script>


<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">
  
  <div class="divider"></div>
</div>

  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>


<script src="/js/book-toc.js"></script>

</div>

      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>


<script src="/js/book.js"></script>
