<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/favicon.png" />
    

    <title>
        
          Eric&#39;s CS Notes
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    
<link rel="stylesheet" href="/css/book.css">

    
<script src="/js/book.js"></script>


    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.css">
    
    <!-- katex css -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous">

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/">
    <img src="/favicon.png">
    <span>ERIC&#39;S CS NOTES</span>
  </a>
</div>

    <div class="book-menu">
  <!--
## Introduction to Probability

* [Unit 1: Probability models and axioms](/introduction-to-probability/unit-1/index.html)
* [Unit 2: Conditioning and independence](/introduction-to-probability/unit-2/index.html)
* [Unit 3: Counting](/introduction-to-probability/unit-3/index.html)
* [Unit 4: Discrete random variables](/introduction-to-probability/unit-4/index.html)
* [Unit 5: Continuous random variables](/introduction-to-probability/unit-5/index.html)
* [Unit 6: Further topics on random variables](/introduction-to-probability/unit-6/index.html)
* [Unit 7: Bayesian inference](/introduction-to-probability/unit-7/index.html)
* [Unit 8: Limit theorems and classical statistics](/introduction-to-probability/unit-8/index.html)
* [Unit 9: Bernoulli and Poisson processes](/introduction-to-probability/unit-9/index.html)
* [Unit 10: Markov chains](/introduction-to-probability/unit-10/index.html)
-->
<!--
## Multivariable Calculus

* [Unit 1: Thinking about multivariable functions](/multivariable-calculus/unit-1/index.html)
* [Unit 2: Derivatives of multivariable functions](/multivariable-calculus/unit-2/index.html)

* [Unit 3: Applications of multivariable derivatives](/multivariable-calculus/unit-3/index.html)
* [Unit 4: Integrating multivariable functions](/multivariable-calculus/unit-4/index.html)
* [Unit 5: Green's, Stokes', and the divergence theorems](/multivariable-calculus/unit-5/index.html)
-->
<h2 id="cs6210-advanced-operating-systems"><a class="markdownIt-Anchor" href="#cs6210-advanced-operating-systems"></a> CS6210: Advanced Operating Systems</h2>
<ul>
<li><a href="/cs6210/lesson-02/index.html">Lesson 02: OS Structure</a></li>
<li><a href="/cs6210/lesson-03/index.html">Lesson 3: Virtualization</a></li>
<li><a href="/cs6210/lesson-04-1/index.html">Lesson 4: Parallel Systems - Part 1</a></li>
<li><a href="/cs6210/lesson-04-2/index.html">Lesson 4: Parallel Systems - Part 2</a></li>
<li><a href="/cs6210/lesson-05/index.html">Lesson 5: Distributed Systems</a></li>
<li><a href="/cs6210/lesson-06/index.html">Lesson 6: Distributed Objects and Middleware</a></li>
</ul>
<!--
* [Lesson 7: Distributed Subsystems](/cs6210/lesson-07/index.html)
* [Lesson 9: Internet Computing](/cs6210/lesson-09/index.html)
* [Lesson 10: RT and Multimedia](/cs6210/lesson-10/index.html)
* [Lesson 8: Failures and Recovery](/cs6210/lesson-08/index.html)
* [Lesson 11: Security](/cs6210/lesson-11/index.html)
-->
<h2 id="cs6250-computer-networks"><a class="markdownIt-Anchor" href="#cs6250-computer-networks"></a> CS6250 Computer Networks</h2>
<ul>
<li><a href="/cs6250/week-1-internet-architecture/index.html">Week 1 - Internet Architecture</a></li>
<li><a href="/cs6250/week-2-transport-and-application-layers/index.html">Week 2 - Transport and Application Layers</a></li>
<li><a href="/cs6250/week-3-intradomain-routing/index.html">Week 3 - Intradomain Routing</a></li>
<li><a href="/cs6250/week-4-as-relationships-and-interdomain-routing/index.html">Week 4 - AS Relationships and Interdomain Routing</a></li>
<li><a href="/cs6250/week-5-router-design-and-algorithems-part-1/index.html">Week 5 - Router Design and Algorithms (Part 1)</a></li>
<li><a href="/cs6250/week-6-router-design-and-algorithems-part-2/index.html">Week 6 - Router Design and Algorithms (Part 2)</a></li>
<li><a href="/cs6250/week-7-software-defined-networking-part-1/index.html">Week 7 - Software Defined Networking (Part 1)</a></li>
<li><a href="/cs6250/week-8-software-defined-networking-part-2/index.html">Week 8 - Software Defined Networking (Part 2)</a></li>
<li><a href="/cs6250/week-9-internet-security/index.html">Week 9 - Internet Security</a></li>
<li><a href="/cs6250/week-10-internet-surveillance-and-censorship/index.html">Week 10 - Internet Surveillance and Censorship</a></li>
<li><a href="/cs6250/week-11-applications-video/index.html">Week 11 - Applications Videos</a></li>
<li><a href="/cs6250/week-12-applications-cdns-and-overlay-networks/index.html">Week 12 - Applications CDNs and Overlay Networks</a></li>
</ul>
<h2 id="cs6200-graduate-introduction-to-operating-systems"><a class="markdownIt-Anchor" href="#cs6200-graduate-introduction-to-operating-systems"></a> CS6200 Graduate Introduction to Operating Systems</h2>
<ul>
<li><a href="/cs6200/p1-preparation/index.html">P0 - Preparation</a></li>
<li><a href="/cs6200/p1l2-introduction/index.html">P1L2 - Introduction</a></li>
<li><a href="/cs6200/p2l1-processes-and-process-management/index.html">P2L1 - Processes and Process Management</a></li>
<li><a href="/cs6200/p2l2-threads-and-concurrency/index.html">P2L2 - Threads and Concurrency</a></li>
<li><a href="/cs6200/p2l3-pthread/index.html">P2L3 - PThread</a></li>
<li><a href="/cs6200/p2l4-thread-design-consideration/index.html">P2L4 - Thread Design Considerations</a></li>
<li><a href="/cs6200/p2l5-thread-performance-consideration/index.html">P2L5 - Thread Performance Considerations</a></li>
<li><a href="/cs6200/p3l1-scheduling/index.html">P3L1 - Scheduling</a></li>
<li><a href="/cs6200/p3l2-memory-management/index.html">P3L2 - Memory Management</a></li>
<li><a href="/cs6200/p3l3-inter-process-communication/index.html">P3L3 - Inter-Process Communication</a></li>
<li><a href="/cs6200/p3l4-synchronization-constructs/index.html">P3L4 - Synchronization Constructs</a></li>
<li><a href="/cs6200/p3l5-io-management/index.html">P3L5 - I/O Management</a></li>
<li><a href="/cs6200/p3l6-virtualization/index.html">P3L6 - Virtualization</a></li>
</ul>
<!--
* [P4L1 - Remote Procedure Calls](/cs6200/p4l1-remote-procedure-calls/index.html) 
* [P4L2 - Distributed File Systems](/cs6200/p4l2-distributed-file-systems/index.html) 
* [P4L3 - Distributed Shared Memory](/cs6200/p4l3-distributed-shared-memory/index.html) 
* [P4L4 - Datacenter Technologies](/cs6200/p4l4-datacenter-technologies/index.html) 
-->
<h2 id="algorithms-part-ii"><a class="markdownIt-Anchor" href="#algorithms-part-ii"></a> Algorithms: Part II</h2>
<ul>
<li><a href="/algorithms-2/week-1/index.html">Week 1 - Undirected Graph &amp; Directed Graph</a></li>
<li><a href="/algorithms-2/week-2/index.html">Week 2 - Minimum Spanning Trees &amp; Shortest Path</a></li>
<li><a href="/algorithms-2/week-3/index.html">Week 3 - Maximum Flow and Minimum Cut &amp; String Sort</a></li>
<li><a href="/algorithms-2/week-4/index.html">Week 4 - Tries &amp; Substring Search</a></li>
<li><a href="/algorithms-2/week-5/index.html">Week 5 - Regular Expressions</a></li>
<li><a href="/algorithms-2/week-6/index.html">Week 6 - Reductions</a></li>
</ul>
<h2 id="algorithms-part-i"><a class="markdownIt-Anchor" href="#algorithms-part-i"></a> Algorithms: Part I</h2>
<ul>
<li><a href="/algorithms-1/week-1/index.html">Week 1 - Union-Find &amp; Analysis of Algorithms</a></li>
<li><a href="/algorithms-1/week-2/index.html">Week 2 - Stacks and Queues &amp; Elementary Sorts</a></li>
<li><a href="/algorithms-1/week-3/index.html">Week 3 - Mergesort &amp; Quicksort</a></li>
<li><a href="/algorithms-1/week-4/index.html">Week 4 - Priority Queues &amp; Elementary Symbols</a></li>
<li><a href="/algorithms-1/week-5/index.html">Week 5 - Balanced Search Trees</a></li>
<li><a href="/algorithms-1/week-6/index.html">Week 6 - Hash Tables</a></li>
</ul>
<h2 id="introduction-to-software-design-and-architecture"><a class="markdownIt-Anchor" href="#introduction-to-software-design-and-architecture"></a> Introduction to Software Design and Architecture</h2>
<ul>
<li><a href="/introduction-to-software-design-and-architecture/design-pattern/index.html">Design Pattern</a></li>
</ul>
<h2 id="calculus-two-sequences-and-series"><a class="markdownIt-Anchor" href="#calculus-two-sequences-and-series"></a> Calculus Two: Sequences and Series</h2>
<ul>
<li><a href="/calculus-two/week-1/index.html">Week 1 - Sequences</a></li>
<li><a href="/calculus-two/week-2/index.html">Week 2 - Series</a></li>
<li><a href="/calculus-two/week-3/index.html">Week 3 - Convergence Tests</a></li>
<li><a href="/calculus-two/week-4/index.html">Week 4 - Alternating Series</a></li>
<li><a href="/calculus-two/week-5/index.html">Week 5 - Power Series</a></li>
<li><a href="/calculus-two/week-6/index.html">Week 6 - Taylor Series</a></li>
</ul>
<h2 id="laff-linear-algebra"><a class="markdownIt-Anchor" href="#laff-linear-algebra"></a> LAFF Linear Algebra</h2>
<ul>
<li><a href="/laff-linear-algebra/week-1/index.html">Week 1 - Vectors in Linear Algebra</a></li>
<li><a href="/laff-linear-algebra/week-2/index.html">Week 2 - Linear Transformations and Matrices</a></li>
<li><a href="/laff-linear-algebra/week-3/index.html">Week 3 - Matrix-Vector Operations</a></li>
<li><a href="/laff-linear-algebra/week-4/index.html">Week 4 - Matrix-Vector to Matrix-Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-5/index.html">Week 5 - Matrix- Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-6/index.html">Week 6 - Gaussian Elimination</a></li>
<li><a href="/laff-linear-algebra/week-7/index.html">Week 7 - More Gaussian Elimination and Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-8/index.html">Week 8 - More on Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-9/index.html">Week 9 - Vector Spaces</a></li>
<li><a href="/laff-linear-algebra/week-10/index.html">Week 10 - Vector Spaces, Orthogonality, and Linear Least-Squares</a></li>
<li><a href="/laff-linear-algebra/week-11/index.html">Week 11 - Orthogonal Projection, Low Rank Approximation, and Orthogonal Bases</a></li>
<li><a href="/laff-linear-algebra/week-12/index.html">Week 12 - Eigenvalues and Eigenvectors</a></li>
</ul>
<h2 id="stanford-machine-learning"><a class="markdownIt-Anchor" href="#stanford-machine-learning"></a> Stanford Machine Learning</h2>
<ul>
<li><a href="/stanford-machine-learning/week-1/index.html">Week 1 - Introduction</a></li>
<li><a href="/stanford-machine-learning/week-2/index.html">Week 2 - Linear Regression with Multiple Variables</a></li>
<li><a href="/stanford-machine-learning/week-3/index.html">Week 3 - Logistic Regression &amp; Regularization</a></li>
<li><a href="/stanford-machine-learning/week-4/index.html">Week 4 - Neural Networks: Representation</a></li>
<li><a href="/stanford-machine-learning/week-5/index.html">Week 5 - Neural Networks: Learning</a></li>
<li><a href="/stanford-machine-learning/week-6a/index.html">Week 6a - Advice for Applying Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-6b/index.html">Week 6b - Machine Learning System Design</a></li>
<li><a href="/stanford-machine-learning/week-7/index.html">Week 7 - Support Vector Machines</a></li>
<li><a href="/stanford-machine-learning/week-8/index.html">Week 8 - Unsupervised Learning &amp; Dimensionality Reduction</a></li>
<li><a href="/stanford-machine-learning/week-9a/index.html">Week 9a - Anomaly Detection</a></li>
<li><a href="/stanford-machine-learning/week-9b/index.html">Week 9b - Recommender Systems</a></li>
<li><a href="/stanford-machine-learning/week-10/index.html">Week 10 - Large Scale Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-11/index.html">Week 11 - Application Example: Photo OCR</a></li>
</ul>
<h2 id="calculus-one"><a class="markdownIt-Anchor" href="#calculus-one"></a> Calculus One</h2>
<ul>
<li><a href="/calculus-one/week-2-3/index.html">Week 2-3 - Functions &amp; Limits</a></li>
<li><a href="/calculus-one/week-4/index.html">Week 4 - The Beginning of Derivatives</a></li>
<li><a href="/calculus-one/week-5/index.html">Week 5 - Techniques of Differentiation</a></li>
<li><a href="/calculus-one/week-6/index.html">Week 6 - Chain Rule</a></li>
<li><a href="/calculus-one/week-7/index.html">Week 7 - Derivatives of Trigonometric Functions</a></li>
<li><a href="/calculus-one/week-8/index.html">Week 8 - Derivatives in the Real World</a></li>
<li><a href="/calculus-one/week-9/index.html">Week 9 - Optimization</a></li>
<li><a href="/calculus-one/week-10/index.html">Week 10 - Linear Approximation</a></li>
<li><a href="/calculus-one/week-11-12/index.html">Week 11-12 - Antidifferentiation &amp; Integration</a></li>
<li><a href="/calculus-one/week-13/index.html">Week 13 - Fundamental Theorem of Calculus</a></li>
<li><a href="/calculus-one/week-14/index.html">Week 14 - Substitution Rule</a></li>
<li><a href="/calculus-one/week-15/index.html">Week 15 - Techniques of Integration</a></li>
<li><a href="/calculus-one/week-16/index.html">Week 16 - Applications of Integration</a></li>
</ul>
<h2 id="computational-thinking"><a class="markdownIt-Anchor" href="#computational-thinking"></a> Computational Thinking</h2>
<ul>
<li><a href="/computational-thinking/lecture-1/index.html">Lecture 1 - Optimization and Knapsack Problem</a></li>
<li><a href="/computational-thinking/lecture-2/index.html">Lecture 2 - Decision Trees and Dynamic Programming</a>
<ul>
<li><a href="/computational-thinking/lecture-2-powerset/index.html">Exercise: Power Set Function</a></li>
</ul>
</li>
<li><a href="/computational-thinking/lecture-3/index.html">Lecture 3 - Graphs</a></li>
<li><a href="/computational-thinking/lecture-4-5/index.html">Lecture 4-5 - Plotting</a></li>
<li><a href="/computational-thinking/lecture-6-7/index.html">Lecture 6-7 - Stochastic Programs &amp; Inferential Statistics</a></li>
<li><a href="/computational-thinking/lecture-8/index.html">Lecture 8 - Monte Carlo Simulation</a></li>
<li><a href="/computational-thinking/lecture-9/index.html">Lecture 9 - Sampling and Standard Error</a></li>
<li><a href="/computational-thinking/lecture-10-11/index.html">Lecture 10-11 - Experimental Data</a></li>
<li><a href="/computational-thinking/lecture-12/index.html">Lecture 12 - Machine Learning</a></li>
<li><a href="/computational-thinking/lecture-13/index.html">Lecture 13 - Statistical Abuses</a></li>
</ul>
<h2 id="effective-thinking-through-mathematics"><a class="markdownIt-Anchor" href="#effective-thinking-through-mathematics"></a> Effective Thinking Through Mathematics</h2>
<ul>
<li><a href="/effective-thinking-through-mathematics/note/index.html">Note</a></li>
<li><a href="/effective-thinking-through-mathematics/week-4-telling-the-story-of-infinity/index.html">Week 4 (/Telling the Story of Infinity)</a></li>
<li><a href="/effective-thinking-through-mathematics/week-5-telling-the-story-of-the-euler-circuit-theorem/index.html">Week 5 (/Telling the Story of Euler Circuit Theorem)</a></li>
</ul>
<h2 id="cs50-introduction-to-computer-science"><a class="markdownIt-Anchor" href="#cs50-introduction-to-computer-science"></a> CS50 Introduction to Computer Science</h2>
<ul>
<li><a href="/cs50/week-1/index.html">Week 1 - C</a></li>
<li><a href="/cs50/week-2/index.html">Week 2 - Arrays</a></li>
<li><a href="/cs50/week-3/index.html">Week 3 - Algorithms</a></li>
<li><a href="/cs50/week-4/index.html">Week 4 - Memory</a></li>
<li><a href="/cs50/week-5/index.html">Week 5 - Data Structures</a></li>
<li><a href="/cs50/week-6/index.html">Week 6 - HTTP</a></li>
<li><a href="/cs50/week-7-10/index.html">Week 7-10 - Machine Learning/Python/SQL/Javascript</a></li>
</ul>
<h2 id="others"><a class="markdownIt-Anchor" href="#others"></a> Others</h2>
<ul>
<li><a href="/symbols/index.html">Symbols of Mathematics</a></li>
<li><a href="/glossary/index.html">Glossary</a></li>
</ul>
<h2 id="about-me"><a class="markdownIt-Anchor" href="#about-me"></a> <a target="_blank" rel="noopener" href="https://ericyy.me/about/">About Me</a></h2>

</div>


<script src="/js/book-menu.js"></script>

  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1 id="lecture-9"><a class="markdownIt-Anchor" href="#lecture-9"></a> Lecture 9</h1>
<ul>
<li>This lecture is talking about how to find the mean of population with Standard Error(SE) and Standard Error of The Means(SEM). And how to  decide the sample size to represent the population with Confidence Interval(CI).</li>
</ul>
<h2 id="sampling-and-standard-error"><a class="markdownIt-Anchor" href="#sampling-and-standard-error"></a> Sampling and Standard Error</h2>
<h3 id="stratified-sampling"><a class="markdownIt-Anchor" href="#stratified-sampling"></a> Stratified Sampling</h3>
<ul>
<li>Partition population into subgroups</li>
<li>Take a simple random sample from each subgroup</li>
<li>When need to use:
<ul>
<li>There are small subgroups that should be represented</li>
<li>It is important that subgroups be represented proportionally to their size in the population</li>
<li>Can be used to reduced the needed size of sample</li>
</ul>
</li>
</ul>
<h4 id="for-example-predicting-temperatures-in-the-us"><a class="markdownIt-Anchor" href="#for-example-predicting-temperatures-in-the-us"></a> For example (Predicting Temperatures in the U.S.)</h4>
<ul>
<li>
<p>Data:</p>
<ul>
<li>From U.S. National Centers for Environmental Information (NCEI)</li>
<li>21 different US cities
<ul>
<li>ALBUQUERQUE, BALTIMORE, BOSTON, CHARLOTTE, CHICAGO, DALLAS, DETROIT, LAS VEGAS, LOS ANGELES, MIAMI, NEW ORLEANS, NEW YORK, PHILADELPHIA, PHOENIX, PORTLAND, SAN DIEGO, SAN FRANCISCO, SAN JUAN, SEATTLE, ST LOUIS, TAMPA</li>
</ul>
</li>
<li>1961 – 2015</li>
<li>421,848 data points (examples)</li>
</ul>
</li>
<li>
<p>First, fetch 100 random samples, get the standard deviation and mean:</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">makeHist</span>(<span class="params">data, title, xlabel, ylabel, bins = <span class="number">20</span></span>):</span><br><span class="line">   pylab.hist(data, bins = bins)</span><br><span class="line">   pylab.title(title)</span><br><span class="line">   pylab.xlabel(xlabel)</span><br><span class="line">   pylab.ylabel(ylabel)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHighs</span>():</span><br><span class="line">   inFile = <span class="built_in">open</span>(<span class="string">&#x27;temperatures.csv&#x27;</span>)</span><br><span class="line">   population = []</span><br><span class="line">   <span class="keyword">for</span> l <span class="keyword">in</span> inFile:</span><br><span class="line">       <span class="keyword">try</span>:</span><br><span class="line">           tempC = <span class="built_in">float</span>(l.split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">           population.append(tempC)</span><br><span class="line">       <span class="keyword">except</span>:</span><br><span class="line">           <span class="keyword">continue</span></span><br><span class="line">   <span class="keyword">return</span> population</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getMeansAndSDs</span>(<span class="params">population, sample, verbose = <span class="literal">False</span></span>):</span><br><span class="line">   popMean = <span class="built_in">sum</span>(population)/<span class="built_in">len</span>(population)</span><br><span class="line">   sampleMean = <span class="built_in">sum</span>(sample)/<span class="built_in">len</span>(sample)</span><br><span class="line">   <span class="keyword">if</span> verbose:</span><br><span class="line">       makeHist(population,</span><br><span class="line">                <span class="string">&#x27;Daily High 1961-2015, Population\n&#x27;</span> +\</span><br><span class="line">                <span class="string">&#x27;(mean = &#x27;</span>  + <span class="built_in">str</span>(<span class="built_in">round</span>(popMean, <span class="number">2</span>)) + <span class="string">&#x27;)&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Degrees C&#x27;</span>, <span class="string">&#x27;Number Days&#x27;</span>)</span><br><span class="line">       pylab.figure()</span><br><span class="line">       makeHist(sample, <span class="string">&#x27;Daily High 1961-2015, Sample\n&#x27;</span> +\</span><br><span class="line">                <span class="string">&#x27;(mean = &#x27;</span> + <span class="built_in">str</span>(<span class="built_in">round</span>(sampleMean, <span class="number">2</span>)) + <span class="string">&#x27;)&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Degrees C&#x27;</span>, <span class="string">&#x27;Number Days&#x27;</span>)   </span><br><span class="line">       <span class="built_in">print</span>(<span class="string">&#x27;Population mean =&#x27;</span>, popMean)</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">&#x27;Standard deviation of population =&#x27;</span>,</span><br><span class="line">             numpy.std(population))</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">&#x27;Sample mean =&#x27;</span>, sampleMean)</span><br><span class="line">       <span class="built_in">print</span>(<span class="string">&#x27;Standard deviation of sample =&#x27;</span>,</span><br><span class="line">             numpy.std(sample))</span><br><span class="line">   <span class="keyword">return</span> popMean, sampleMean,\</span><br><span class="line">          numpy.std(population), numpy.std(sample)</span><br><span class="line">    </span><br><span class="line">random.seed(<span class="number">0</span>)         </span><br><span class="line">population = getHighs()</span><br><span class="line">sample = random.sample(population, <span class="number">100</span>)</span><br><span class="line">getMeansAndSDs(population, sample, <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>Result:</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Population mean = 16.298769461986048</span><br><span class="line">Standard deviation of population = 9.4375585448</span><br><span class="line">Sample mean = 17.0685</span><br><span class="line">Standard deviation of sample = 10.390314372</span><br></pre></td></tr></table></figure>
 <img src="https://i.imgur.com/tmBmHVW.jpg" style="width:400px" />
</li>
<li>
<p>Try it 1000 times and plot <strong>the sample means</strong> results</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">random.seed(<span class="number">0</span>) </span><br><span class="line">population = getHighs()</span><br><span class="line">sampleSize = <span class="number">100</span></span><br><span class="line">numSamples = <span class="number">1000</span></span><br><span class="line">maxMeanDiff = <span class="number">0</span></span><br><span class="line">maxSDDiff = <span class="number">0</span></span><br><span class="line">sampleMeans = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numSamples):</span><br><span class="line">   sample = random.sample(population, sampleSize)</span><br><span class="line">   popMean, sampleMean, popSD, sampleSD =\</span><br><span class="line">      getMeansAndSDs(population, sample, verbose = <span class="literal">False</span>)</span><br><span class="line">   sampleMeans.append(sampleMean)</span><br><span class="line">   <span class="keyword">if</span> <span class="built_in">abs</span>(popMean - sampleMean) &gt; maxMeanDiff:</span><br><span class="line">       maxMeanDiff = <span class="built_in">abs</span>(popMean - sampleMean)</span><br><span class="line">   <span class="keyword">if</span> <span class="built_in">abs</span>(popSD - sampleSD) &gt; maxSDDiff:</span><br><span class="line">       maxSDDiff = <span class="built_in">abs</span>(popSD - sampleSD)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Mean of sample Means =&#x27;</span>,</span><br><span class="line">     <span class="built_in">round</span>(<span class="built_in">sum</span>(sampleMeans)/<span class="built_in">len</span>(sampleMeans), <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Standard deviation of sample means =&#x27;</span>,</span><br><span class="line">     <span class="built_in">round</span>(numpy.std(sampleMeans), <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Maximum difference in means =&#x27;</span>,</span><br><span class="line">     <span class="built_in">round</span>(maxMeanDiff, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Maximum difference in standard deviations =&#x27;</span>,</span><br><span class="line">     <span class="built_in">round</span>(maxSDDiff, <span class="number">3</span>))</span><br><span class="line">makeHist(sampleMeans, <span class="string">&#x27;Means of Samples&#x27;</span>, <span class="string">&#x27;Mean&#x27;</span>, <span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">pylab.axvline(x = popMean, color = <span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>Result:</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Mean of sample Means = 16.294</span><br><span class="line">Standard deviation of sample means = 0.943</span><br><span class="line">Maximum difference in means = 3.633</span><br><span class="line">Maximum difference in standard deviations = 2.457</span><br></pre></td></tr></table></figure>
 <img src="https://i.imgur.com/16s9E3I.jpg" style="width:400px" />
</li>
<li>
<p>To get a tighter bound, we tried:</p>
<ul>
<li>drawing 2000 samples instead of 1000,
<ul>
<li>doesn’t change too much</li>
</ul>
</li>
<li>or increasing sample size from 100 to 200
<ul>
<li>Standard deviation of sample means drops from 0.94 to 0.66</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Then use <code>pylab.errorbar()</code> function to plot different sample sizes [50, 100, 200, 300, 400, 500, 600]:</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pylab.errorbar(xVals, sizeMeans, \</span><br><span class="line">    yerr = <span class="number">1.96</span>*pylab.array(sizeSDs), \</span><br><span class="line">    fmt = <span class="string">&#x27;o&#x27;</span>, label = <span class="string">&#x27;95% Confidence Interval&#x27;</span>)</span><br></pre></td></tr></table></figure>
  <img src="https://i.imgur.com/LPMrEIZ.jpg" style="width:400px" />
</li>
<li>
<p>Result:</p>
<ul>
<li>Going from a sample size of 100 to 400 reduced the confidence interval from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.8</mn><msup><mtext> </mtext><mo lspace="0em" rspace="0em">∘</mo></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">1.8\ ^{\circ}C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">8</span><span class="mord"><span class="mspace"> </span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.674115em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∘</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> to about <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mtext> </mtext><mo lspace="0em" rspace="0em">∘</mo></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">1 \ ^{\circ}C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mspace"> </span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.674115em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∘</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>.</li>
</ul>
</li>
</ul>
<h4 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h4>
<ul>
<li>Bigger sample size will always be better.</li>
</ul>
<h3 id="standard-error"><a class="markdownIt-Anchor" href="#standard-error"></a> Standard Error</h3>
<ul>
<li>The <strong>Standard Error(SE)</strong> of a statistic (most commonly the mean) is the standard deviation of its <strong>sampling</strong> distribution, or sometimes an estimate of that standard deviation. Use to depict the dispersion of sample means around the population mean.</li>
<li>(标准误所代表的，是在无数次抽样结果中，一次抽样的结果可能偏离无数次抽样结果这一总体的程度。标准误越小，用这一次抽样结果来代表这无数次抽样结果的可靠性就越好。)</li>
<li>标准差是样本离散程度的一个度量。标准误是：给定样本大小，样本的某个统计量的抽样分布标准差。 – from <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/22864111">知乎</a></li>
<li><strong>Standard Error of the Mean(SEM)</strong> is the standard deviation of the sampling distribution of the <strong>sample mean</strong>.
<ul>
<li>当我们打算使用随机样本来计算整体样本的平均值。SEM 表达的是，我们使用的样本大小是否足够代表整体来计算整体平均值。</li>
<li>比如我抽了十次样，如果这十次样本平均值的标准差都很接近的话，那么它们的标准误就会很小，这个样本的大小就适合代表整体。</li>
<li>我们期望随机样本在特定 CI (比如95%=1.96个标准偏差)下的可靠度足够高。比如温度预测，我们肯定不希望95%的 CI 下差值范围超过 1 度。显然这样的预测是不准确的。</li>
<li>标准误的价值在于，通常情况下，我们无法得知整体样本的数据情况，所以必须使用随机抽样+计算SEM来保证样本大小足够以及结论的可靠性。</li>
</ul>
</li>
<li>To formulate it, SEM is estimated by the sample estimate of the population standard deviation (sample standard deviation) divided by the square root of the sample size (assuming statistical independence of the values in the sample):
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><msub><mi>E</mi><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover></msub><mo>=</mo><mfrac><mi>s</mi><msqrt><mi>n</mi></msqrt></mfrac></mrow><annotation encoding="application/x-tex">SE_{\bar{x}}=\frac{s}{\sqrt{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.24744599999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord mtight">ˉ</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.233392em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6258665em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8059050000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-2.765905em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.234095em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li>where
<ul>
<li><code>s</code> is the <strong>sample standard deviation</strong> (i.e., the sample-based estimate of the standard deviation of the population).
<ul>
<li>Because, most time, we can’t get the standard deviation of the population. Later, we will prove the sample-based estimate of the standard deviation of the population is close to the standard deviation of the population.</li>
</ul>
</li>
<li><code>n</code> is the size (number of observations) of the sample.</li>
</ul>
</li>
<li>Recall the formula (from <a href="lecture-8.md#the-central-limit-theorem-clt">CLT</a>) of the standard deviation of the sample means:
<ul>
<li>The variance of the sample means (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>σ</mi><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">\sigma_{\bar{x}}^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.061108em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord mtight">ˉ</span></span></span></span></span></span></span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>) will be close to the variance of the population (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>) divided by the sample size (N).</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>σ</mi><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mn>2</mn></msubsup><mo>=</mo><mfrac><msup><mi>σ</mi><mn>2</mn></msup><mi>N</mi></mfrac></mrow><annotation encoding="application/x-tex">\sigma^2_{\bar{x}}=\frac{\sigma^2}{N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.061108em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord mtight">ˉ</span></span></span></span></span></span></span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.36292em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01792em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li>where
<ul>
<li><code>σ</code> is the standard deviation of the population.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="prove-the-sem-theorem"><a class="markdownIt-Anchor" href="#prove-the-sem-theorem"></a> Prove the SEM theorem</h4>
<ul>
<li>First, let’s use the standard deviation of the population to calculate SEM to see if it is close to the standard deviation of the sample means of the population by simulation</li>
<li>Test with different sample sizes</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sem</span>(<span class="params">popSD, sampleSize</span>):</span><br><span class="line">   <span class="keyword">return</span> popSD/sampleSize**<span class="number">0.5</span></span><br><span class="line">    </span><br><span class="line">sampleSizes = (<span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>, <span class="number">300</span>, <span class="number">400</span>, <span class="number">500</span>, <span class="number">600</span>)</span><br><span class="line">numTrials = <span class="number">50</span></span><br><span class="line">population = getHighs()</span><br><span class="line">popSD = numpy.std(population)</span><br><span class="line">sems = []</span><br><span class="line">sampleSDs = []</span><br><span class="line"><span class="keyword">for</span> size <span class="keyword">in</span> sampleSizes:</span><br><span class="line">   sems.append(sem(popSD, size))</span><br><span class="line">   means = []</span><br><span class="line">   <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(numTrials):</span><br><span class="line">       sample = random.sample(population, size)</span><br><span class="line">       means.append(<span class="built_in">sum</span>(sample)/<span class="built_in">len</span>(sample))</span><br><span class="line">   sampleSDs.append(numpy.std(means)) <span class="comment"># calculate the standard deviation of the means of random samples from population</span></span><br><span class="line">pylab.plot(sampleSizes, sampleSDs,</span><br><span class="line">          label = <span class="string">&#x27;Std of 50 means&#x27;</span>)</span><br><span class="line">pylab.plot(sampleSizes, sems, <span class="string">&#x27;r--&#x27;</span>, label = <span class="string">&#x27;SEM&#x27;</span>)</span><br><span class="line">pylab.title(<span class="string">&#x27;SEM vs. SD for 50 Means&#x27;</span>)</span><br><span class="line">pylab.legend()</span><br></pre></td></tr></table></figure>
<img src="https://i.imgur.com/bGha13f.jpg" style="width:300px" />
<ul>
<li>So, we can say, the SEM is very close to the standard deviation of the sample means when we are using the Population Standard Deviation. But can we use the Sample Standard Deviation to instead the Population Standard Deviation?</li>
</ul>
<h4 id="compare-sample-standard-deviation"><a class="markdownIt-Anchor" href="#compare-sample-standard-deviation"></a> Compare Sample Standard Deviation</h4>
<ul>
<li>to prove that the sample estimate of the population standard deviation (sample standard deviation) is close to the population standard deviation</li>
<li>compare the differences between the Standard Deviation of <strong>Single</strong> Sample (<strong>NOT Standard Error of the Means</strong>) and the Standard Deviation of the Population:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getDiffs</span>(<span class="params">population, sampleSizes</span>):</span><br><span class="line">   popStd = numpy.std(population)</span><br><span class="line">   diffsFracs = []</span><br><span class="line">   <span class="keyword">for</span> sampleSize <span class="keyword">in</span> sampleSizes:</span><br><span class="line">       diffs = []</span><br><span class="line">       <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">           sample = random.sample(population, sampleSize)</span><br><span class="line">           diffs.append(<span class="built_in">abs</span>(popStd - numpy.std(sample))) <span class="comment"># single sample</span></span><br><span class="line">       diffMean = <span class="built_in">sum</span>(diffs)/<span class="built_in">len</span>(diffs)</span><br><span class="line">       diffsFracs.append(diffMean/popStd)</span><br><span class="line">   <span class="keyword">return</span> pylab.array(diffsFracs)*<span class="number">100</span></span><br><span class="line">   </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plotDiffs</span>(<span class="params">sampleSizes, diffs, title, label</span>):</span><br><span class="line">   pylab.plot(sampleSizes, diffs, label = label)</span><br><span class="line">   pylab.xlabel(<span class="string">&#x27;Sample Size&#x27;</span>)</span><br><span class="line">   pylab.ylabel(<span class="string">&#x27;% Difference in SD&#x27;</span>)</span><br><span class="line">   pylab.title(title)</span><br><span class="line">   pylab.legend()</span><br><span class="line">    </span><br><span class="line">sampleSizes = <span class="built_in">range</span>(<span class="number">20</span>, <span class="number">600</span>, <span class="number">1</span>)</span><br><span class="line">diffs = getDiffs(getHighs(), sampleSizes)</span><br><span class="line">plotDiffs(sampleSizes, diffs,</span><br><span class="line">         <span class="string">&#x27;Sample SD vs Population SD, Temperatures&#x27;</span>,</span><br><span class="line">         label = <span class="string">&#x27;High temps&#x27;</span>)</span><br></pre></td></tr></table></figure>
<img src="https://i.imgur.com/dz4pV7d.jpg" style="width:300px" />
<ul>
<li>Once sample reaches a reasonable size, <strong>Sample Standard Deviation</strong> is a pretty good approximation to <strong>Population Standard Deviation</strong>.</li>
</ul>
<h4 id="some-other-questions"><a class="markdownIt-Anchor" href="#some-other-questions"></a> Some Other Questions</h4>
<ul>
<li>
<p><strong>Does the Distribution of Population matter?</strong></p>
<ul>
<li>Try Three Different Distributions: Uniform, Gaussian and Exponential</li>
<li>
<img src="https://i.imgur.com/9FMFREQ.jpg" style="width:500px" />
</li>
</ul>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compareDists</span>():</span><br><span class="line">    uniform, normal, exp = [], [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100000</span>):</span><br><span class="line">        uniform.append(random.random())</span><br><span class="line">        normal.append(random.gauss(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">        exp.append(random.expovariate(<span class="number">0.5</span>))</span><br><span class="line">    sampleSizes = <span class="built_in">range</span>(<span class="number">20</span>, <span class="number">600</span>, <span class="number">1</span>)</span><br><span class="line">    udiffs = getDiffs(uniform, sampleSizes)</span><br><span class="line">    ndiffs = getDiffs(normal, sampleSizes)</span><br><span class="line">    ediffs = getDiffs(exp, sampleSizes)</span><br><span class="line">    plotDiffs(sampleSizes, udiffs,</span><br><span class="line">              <span class="string">&#x27;Sample SD vs Population SD&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Uniform population&#x27;</span>)</span><br><span class="line">    plotDiffs(sampleSizes, ndiffs,</span><br><span class="line">              <span class="string">&#x27;Sample SD vs Population SD&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Normal population&#x27;</span>)</span><br><span class="line">    plotDiffs(sampleSizes, ediffs,</span><br><span class="line">              <span class="string">&#x27;Sample SD vs Population SD&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Exponential population&#x27;</span>)</span><br><span class="line"></span><br><span class="line">compareDists()  </span><br></pre></td></tr></table></figure>
  <img src="https://i.imgur.com/8RrR9Yg.jpg" style="width:300px" />
<ul>
<li>Conclusion
<ul>
<li>It does. Different Distribution of Population has different differences.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Does Population Size Matter?</strong></p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">popSizes = (<span class="number">10000</span>, <span class="number">100000</span>, <span class="number">1000000</span>)</span><br><span class="line">sampleSizes = <span class="built_in">range</span>(<span class="number">20</span>, <span class="number">600</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> size <span class="keyword">in</span> popSizes:</span><br><span class="line">    population = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(size):</span><br><span class="line">        population.append(random.expovariate(<span class="number">0.5</span>))</span><br><span class="line">    ediffs = getDiffs(population, sampleSizes)</span><br><span class="line">    plotDiffs(sampleSizes, ediffs,</span><br><span class="line">              <span class="string">&#x27;Sample SD vs Population SD, Uniform&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;Population size = &#x27;</span> + <span class="built_in">str</span>(size))</span><br></pre></td></tr></table></figure>
  <img src="https://i.imgur.com/nq1sOP7.jpg" style="width:300px" />
<ul>
<li>Conclusion
<ul>
<li>It doesn’t. Different Population Size has almost the same  differences.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="conclusion-to-estimate-mean-from-a-single-sample"><a class="markdownIt-Anchor" href="#conclusion-to-estimate-mean-from-a-single-sample"></a> Conclusion (To Estimate Mean from a Single Sample)</h4>
<ul>
<li><strong>Prerequisite</strong>: independent random samples</li>
</ul>
<ol>
<li>Choose <strong>sample size</strong> based on estimate of skew in population
<ul>
<li><code>skew</code>: A distribution is skewed if one tail extends out further than the other. A distribution has a positive skew (is skewed to the right) if the tail to the right is longer. It has a negative skew (skewed to the left) if the tail to the left is longer.</li>
</ul>
</li>
<li>Chose a random sample from the population</li>
<li>Compute the <strong>mean</strong> and <strong>standard deviation</strong> of that sample</li>
<li>Use the standard deviation of that sample to estimate the <strong>standard error</strong></li>
<li>Use the estimated SE to generate <strong>confidence intervals</strong> around the sample mean
<ul>
<li>if the <strong>CI</strong> is small enough, then we can use this sample size to represent our population.</li>
</ul>
</li>
</ol>
<h4 id="test-the-conclusion"><a class="markdownIt-Anchor" href="#test-the-conclusion"></a> Test the Conclusion</h4>
<ul>
<li>
<p>Are 200 Samples Enough to Estimate the Mean of Population?</p>
<ul>
<li>First, we can calculate the SE of 200 samples in theorem</li>
<li>Second, to compare the true mean and the sample mean, if the difference &lt; 1.96*se, then we can say that, 200 is enough with 95% confidence.</li>
<li>And of course, we need more trails to confirm our assumption.</li>
</ul>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">random.seed(<span class="number">0</span>)</span><br><span class="line">temps = getHighs()</span><br><span class="line">popMean = <span class="built_in">sum</span>(temps)/<span class="built_in">len</span>(temps)</span><br><span class="line">sampleSize = <span class="number">200</span> <span class="comment"># conclusion(1.)</span></span><br><span class="line">numTrials = <span class="number">10000</span></span><br><span class="line">numBad = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(numTrials):</span><br><span class="line">    sample = random.sample(temps, sampleSize) <span class="comment"># conclusion(2.)</span></span><br><span class="line">    sampleMean = <span class="built_in">sum</span>(sample)/sampleSize <span class="comment"># conclusion(3.)</span></span><br><span class="line">    se = numpy.std(sample)/sampleSize**<span class="number">0.5</span> <span class="comment"># conclusion(4.)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>(popMean - sampleMean) &gt; <span class="number">1.96</span>*se: <span class="comment"># 1.96 is a confidence level of 95%</span></span><br><span class="line">        numBad += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Fraction outside 95% confidence interval =&#x27;</span>,</span><br><span class="line">      numBad/numTrials)</span><br></pre></td></tr></table></figure>
<ul>
<li>Result:
<ul>
<li>Fraction outside 95% confidence interval = 0.0511</li>
</ul>
</li>
<li>Conclusion:
<ul>
<li>It is enough for estimate the average temperatures in the U.S</li>
</ul>
</li>
</ul>
</li>
<li>
<p>What if we use continuous 200 samples ?</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(numTrials):</span><br><span class="line">    posStartingPts = <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(temps) - sampleSize)</span><br><span class="line">    start = random.choice(posStartingPts)</span><br><span class="line">    sample = temps[start:start+sampleSize]</span><br><span class="line">    sampleMean = <span class="built_in">sum</span>(sample)/sampleSize</span><br><span class="line">    se = numpy.std(sample)/sampleSize**<span class="number">0.5</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">abs</span>(popMean - sampleMean) &gt; <span class="number">1.96</span>*se: </span><br><span class="line">        numBad += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Fraction outside 95% confidence interval =&#x27;</span>,</span><br><span class="line">      numBad/numTrials)</span><br></pre></td></tr></table></figure>
<ul>
<li>Result:
<ul>
<li>Fraction outside 95% confidence interval = 0.9367</li>
</ul>
</li>
<li>Conclusion:
<ul>
<li>we have violated a key assumptions.</li>
<li>we did <strong>NOT</strong> choose independent random samples
<ul>
<li>Data organized by city</li>
<li>Temperatures correlated with city</li>
<li>Therefore examples in sample are not independent of each other</li>
<li>Obvious here, but can be subtle</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Conclusion for the last two tests</p>
<ul>
<li>All theoretical results incorporate some assumptions</li>
<li>These must be checked before applying the theory!</li>
</ul>
</li>
</ul>
<h4 id="usage-of-se-and-sem"><a class="markdownIt-Anchor" href="#usage-of-se-and-sem"></a> Usage of SE and SEM</h4>
<ul>
<li>The notation for standard error can be any one of SE, SEM (for standard error of measurement or mean), or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>E</mi></msub></mrow><annotation encoding="application/x-tex">S_{E}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li>
<li>If its sampling distribution is normally distributed, the sample mean, its standard error, and the quantiles of the normal distribution can be used to calculate confidence intervals for the mean. Like the sample, we calculate  if 200 is enough for sample size.</li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Standard_error#Assumptions_and_usage">https://en.wikipedia.org/wiki/Standard_error#Assumptions_and_usage</a></li>
</ul>
<h2 id="refers"><a class="markdownIt-Anchor" href="#refers"></a> Refers</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Standard_error">https://en.wikipedia.org/wiki/Standard_error</a></li>
</ul>

</div>


  <div class="book-comments">
    




  </div>



<script src="/js/book-post.js"></script>


<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">
  
  <div class="divider"></div>
</div>

  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>


<script src="/js/book-toc.js"></script>

</div>

      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>


<script src="/js/book.js"></script>
