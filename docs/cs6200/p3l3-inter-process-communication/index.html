<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/favicon.png" />
    

    <title>
        
          Eric&#39;s CS Notes
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    
<link rel="stylesheet" href="/css/book.css">

    
<script src="/js/book.js"></script>


    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.css">
    
    <!-- katex css -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous">

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/">
    <img src="/favicon.png">
    <span>ERIC&#39;S CS NOTES</span>
  </a>
</div>

    <div class="book-menu">
  <!--
## Introduction to Probability

* [Unit 1: Probability models and axioms](/introduction-to-probability/unit-1/index.html)
* [Unit 2: Conditioning and independence](/introduction-to-probability/unit-2/index.html)
* [Unit 3: Counting](/introduction-to-probability/unit-3/index.html)
* [Unit 4: Discrete random variables](/introduction-to-probability/unit-4/index.html)
* [Unit 5: Continuous random variables](/introduction-to-probability/unit-5/index.html)
* [Unit 6: Further topics on random variables](/introduction-to-probability/unit-6/index.html)
* [Unit 7: Bayesian inference](/introduction-to-probability/unit-7/index.html)
* [Unit 8: Limit theorems and classical statistics](/introduction-to-probability/unit-8/index.html)
* [Unit 9: Bernoulli and Poisson processes](/introduction-to-probability/unit-9/index.html)
* [Unit 10: Markov chains](/introduction-to-probability/unit-10/index.html)
-->
<!--
## Multivariable Calculus

* [Unit 1: Thinking about multivariable functions](/multivariable-calculus/unit-1/index.html)
* [Unit 2: Derivatives of multivariable functions](/multivariable-calculus/unit-2/index.html)

* [Unit 3: Applications of multivariable derivatives](/multivariable-calculus/unit-3/index.html)
* [Unit 4: Integrating multivariable functions](/multivariable-calculus/unit-4/index.html)
* [Unit 5: Green's, Stokes', and the divergence theorems](/multivariable-calculus/unit-5/index.html)
-->
<h2 id="cs6210-advanced-operating-systems"><a class="markdownIt-Anchor" href="#cs6210-advanced-operating-systems"></a> CS6210: Advanced Operating Systems</h2>
<ul>
<li><a href="/cs6210/lesson-02/index.html">Lesson 2: OS Structure</a></li>
<li><a href="/cs6210/lesson-03/index.html">Lesson 3: Virtualization</a></li>
<li><a href="/cs6210/lesson-04a/index.html">Lesson 4: Parallel Systems - Part 1</a></li>
<li><a href="/cs6210/lesson-04b/index.html">Lesson 4: Parallel Systems - Part 2</a></li>
<li><a href="/cs6210/lesson-05/index.html">Lesson 5: Distributed Systems</a></li>
<li><a href="/cs6210/lesson-06/index.html">Lesson 6: Distributed Objects and Middleware</a></li>
<li><a href="/cs6210/lesson-07a/index.html">Lesson 7: Distributed Subsystems - GMS</a></li>
<li><a href="/cs6210/lesson-07b/index.html">Lesson 7: Distributed Subsystems - DSM</a></li>
<li><a href="/cs6210/lesson-07c/index.html">Lesson 7: Distributed Subsystems - DFS</a></li>
<li><a href="/cs6210/lesson-09/index.html">Lesson 9: Internet Computing</a></li>
</ul>
<!--
* [Lesson 10: RT and Multimedia](/cs6210/lesson-10/index.html)
* [Lesson 8: Failures and Recovery](/cs6210/lesson-08/index.html)
* [Lesson 11: Security](/cs6210/lesson-11/index.html)
-->
<h2 id="cs6250-computer-networks"><a class="markdownIt-Anchor" href="#cs6250-computer-networks"></a> CS6250 Computer Networks</h2>
<ul>
<li><a href="/cs6250/week-1-internet-architecture/index.html">Week 1 - Internet Architecture</a></li>
<li><a href="/cs6250/week-2-transport-and-application-layers/index.html">Week 2 - Transport and Application Layers</a></li>
<li><a href="/cs6250/week-3-intradomain-routing/index.html">Week 3 - Intradomain Routing</a></li>
<li><a href="/cs6250/week-4-as-relationships-and-interdomain-routing/index.html">Week 4 - AS Relationships and Interdomain Routing</a></li>
<li><a href="/cs6250/week-5-router-design-and-algorithems-part-1/index.html">Week 5 - Router Design and Algorithms (Part 1)</a></li>
<li><a href="/cs6250/week-6-router-design-and-algorithems-part-2/index.html">Week 6 - Router Design and Algorithms (Part 2)</a></li>
<li><a href="/cs6250/week-7-software-defined-networking-part-1/index.html">Week 7 - Software Defined Networking (Part 1)</a></li>
<li><a href="/cs6250/week-8-software-defined-networking-part-2/index.html">Week 8 - Software Defined Networking (Part 2)</a></li>
<li><a href="/cs6250/week-9-internet-security/index.html">Week 9 - Internet Security</a></li>
<li><a href="/cs6250/week-10-internet-surveillance-and-censorship/index.html">Week 10 - Internet Surveillance and Censorship</a></li>
<li><a href="/cs6250/week-11-applications-video/index.html">Week 11 - Applications Videos</a></li>
<li><a href="/cs6250/week-12-applications-cdns-and-overlay-networks/index.html">Week 12 - Applications CDNs and Overlay Networks</a></li>
</ul>
<h2 id="cs6200-graduate-introduction-to-operating-systems"><a class="markdownIt-Anchor" href="#cs6200-graduate-introduction-to-operating-systems"></a> CS6200 Graduate Introduction to Operating Systems</h2>
<ul>
<li><a href="/cs6200/p1-preparation/index.html">P0 - Preparation</a></li>
<li><a href="/cs6200/p1l2-introduction/index.html">P1L2 - Introduction</a></li>
<li><a href="/cs6200/p2l1-processes-and-process-management/index.html">P2L1 - Processes and Process Management</a></li>
<li><a href="/cs6200/p2l2-threads-and-concurrency/index.html">P2L2 - Threads and Concurrency</a></li>
<li><a href="/cs6200/p2l3-pthread/index.html">P2L3 - PThread</a></li>
<li><a href="/cs6200/p2l4-thread-design-consideration/index.html">P2L4 - Thread Design Considerations</a></li>
<li><a href="/cs6200/p2l5-thread-performance-consideration/index.html">P2L5 - Thread Performance Considerations</a></li>
<li><a href="/cs6200/p3l1-scheduling/index.html">P3L1 - Scheduling</a></li>
<li><a href="/cs6200/p3l2-memory-management/index.html">P3L2 - Memory Management</a></li>
<li><a href="/cs6200/p3l3-inter-process-communication/index.html">P3L3 - Inter-Process Communication</a></li>
<li><a href="/cs6200/p3l4-synchronization-constructs/index.html">P3L4 - Synchronization Constructs</a></li>
<li><a href="/cs6200/p3l5-io-management/index.html">P3L5 - I/O Management</a></li>
<li><a href="/cs6200/p3l6-virtualization/index.html">P3L6 - Virtualization</a></li>
</ul>
<!--
* [P4L1 - Remote Procedure Calls](/cs6200/p4l1-remote-procedure-calls/index.html) 
* [P4L2 - Distributed File Systems](/cs6200/p4l2-distributed-file-systems/index.html) 
* [P4L3 - Distributed Shared Memory](/cs6200/p4l3-distributed-shared-memory/index.html) 
* [P4L4 - Datacenter Technologies](/cs6200/p4l4-datacenter-technologies/index.html) 
-->
<h2 id="algorithms-part-ii"><a class="markdownIt-Anchor" href="#algorithms-part-ii"></a> Algorithms: Part II</h2>
<ul>
<li><a href="/algorithms-2/week-1/index.html">Week 1 - Undirected Graph &amp; Directed Graph</a></li>
<li><a href="/algorithms-2/week-2/index.html">Week 2 - Minimum Spanning Trees &amp; Shortest Path</a></li>
<li><a href="/algorithms-2/week-3/index.html">Week 3 - Maximum Flow and Minimum Cut &amp; String Sort</a></li>
<li><a href="/algorithms-2/week-4/index.html">Week 4 - Tries &amp; Substring Search</a></li>
<li><a href="/algorithms-2/week-5/index.html">Week 5 - Regular Expressions</a></li>
<li><a href="/algorithms-2/week-6/index.html">Week 6 - Reductions</a></li>
</ul>
<h2 id="algorithms-part-i"><a class="markdownIt-Anchor" href="#algorithms-part-i"></a> Algorithms: Part I</h2>
<ul>
<li><a href="/algorithms-1/week-1/index.html">Week 1 - Union-Find &amp; Analysis of Algorithms</a></li>
<li><a href="/algorithms-1/week-2/index.html">Week 2 - Stacks and Queues &amp; Elementary Sorts</a></li>
<li><a href="/algorithms-1/week-3/index.html">Week 3 - Mergesort &amp; Quicksort</a></li>
<li><a href="/algorithms-1/week-4/index.html">Week 4 - Priority Queues &amp; Elementary Symbols</a></li>
<li><a href="/algorithms-1/week-5/index.html">Week 5 - Balanced Search Trees</a></li>
<li><a href="/algorithms-1/week-6/index.html">Week 6 - Hash Tables</a></li>
</ul>
<h2 id="introduction-to-software-design-and-architecture"><a class="markdownIt-Anchor" href="#introduction-to-software-design-and-architecture"></a> Introduction to Software Design and Architecture</h2>
<ul>
<li><a href="/introduction-to-software-design-and-architecture/design-pattern/index.html">Design Pattern</a></li>
</ul>
<h2 id="calculus-two-sequences-and-series"><a class="markdownIt-Anchor" href="#calculus-two-sequences-and-series"></a> Calculus Two: Sequences and Series</h2>
<ul>
<li><a href="/calculus-two/week-1/index.html">Week 1 - Sequences</a></li>
<li><a href="/calculus-two/week-2/index.html">Week 2 - Series</a></li>
<li><a href="/calculus-two/week-3/index.html">Week 3 - Convergence Tests</a></li>
<li><a href="/calculus-two/week-4/index.html">Week 4 - Alternating Series</a></li>
<li><a href="/calculus-two/week-5/index.html">Week 5 - Power Series</a></li>
<li><a href="/calculus-two/week-6/index.html">Week 6 - Taylor Series</a></li>
</ul>
<h2 id="laff-linear-algebra"><a class="markdownIt-Anchor" href="#laff-linear-algebra"></a> LAFF Linear Algebra</h2>
<ul>
<li><a href="/laff-linear-algebra/week-1/index.html">Week 1 - Vectors in Linear Algebra</a></li>
<li><a href="/laff-linear-algebra/week-2/index.html">Week 2 - Linear Transformations and Matrices</a></li>
<li><a href="/laff-linear-algebra/week-3/index.html">Week 3 - Matrix-Vector Operations</a></li>
<li><a href="/laff-linear-algebra/week-4/index.html">Week 4 - Matrix-Vector to Matrix-Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-5/index.html">Week 5 - Matrix- Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-6/index.html">Week 6 - Gaussian Elimination</a></li>
<li><a href="/laff-linear-algebra/week-7/index.html">Week 7 - More Gaussian Elimination and Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-8/index.html">Week 8 - More on Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-9/index.html">Week 9 - Vector Spaces</a></li>
<li><a href="/laff-linear-algebra/week-10/index.html">Week 10 - Vector Spaces, Orthogonality, and Linear Least-Squares</a></li>
<li><a href="/laff-linear-algebra/week-11/index.html">Week 11 - Orthogonal Projection, Low Rank Approximation, and Orthogonal Bases</a></li>
<li><a href="/laff-linear-algebra/week-12/index.html">Week 12 - Eigenvalues and Eigenvectors</a></li>
</ul>
<h2 id="stanford-machine-learning"><a class="markdownIt-Anchor" href="#stanford-machine-learning"></a> Stanford Machine Learning</h2>
<ul>
<li><a href="/stanford-machine-learning/week-1/index.html">Week 1 - Introduction</a></li>
<li><a href="/stanford-machine-learning/week-2/index.html">Week 2 - Linear Regression with Multiple Variables</a></li>
<li><a href="/stanford-machine-learning/week-3/index.html">Week 3 - Logistic Regression &amp; Regularization</a></li>
<li><a href="/stanford-machine-learning/week-4/index.html">Week 4 - Neural Networks: Representation</a></li>
<li><a href="/stanford-machine-learning/week-5/index.html">Week 5 - Neural Networks: Learning</a></li>
<li><a href="/stanford-machine-learning/week-6a/index.html">Week 6a - Advice for Applying Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-6b/index.html">Week 6b - Machine Learning System Design</a></li>
<li><a href="/stanford-machine-learning/week-7/index.html">Week 7 - Support Vector Machines</a></li>
<li><a href="/stanford-machine-learning/week-8/index.html">Week 8 - Unsupervised Learning &amp; Dimensionality Reduction</a></li>
<li><a href="/stanford-machine-learning/week-9a/index.html">Week 9a - Anomaly Detection</a></li>
<li><a href="/stanford-machine-learning/week-9b/index.html">Week 9b - Recommender Systems</a></li>
<li><a href="/stanford-machine-learning/week-10/index.html">Week 10 - Large Scale Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-11/index.html">Week 11 - Application Example: Photo OCR</a></li>
</ul>
<h2 id="calculus-one"><a class="markdownIt-Anchor" href="#calculus-one"></a> Calculus One</h2>
<ul>
<li><a href="/calculus-one/week-2-3/index.html">Week 2-3 - Functions &amp; Limits</a></li>
<li><a href="/calculus-one/week-4/index.html">Week 4 - The Beginning of Derivatives</a></li>
<li><a href="/calculus-one/week-5/index.html">Week 5 - Techniques of Differentiation</a></li>
<li><a href="/calculus-one/week-6/index.html">Week 6 - Chain Rule</a></li>
<li><a href="/calculus-one/week-7/index.html">Week 7 - Derivatives of Trigonometric Functions</a></li>
<li><a href="/calculus-one/week-8/index.html">Week 8 - Derivatives in the Real World</a></li>
<li><a href="/calculus-one/week-9/index.html">Week 9 - Optimization</a></li>
<li><a href="/calculus-one/week-10/index.html">Week 10 - Linear Approximation</a></li>
<li><a href="/calculus-one/week-11-12/index.html">Week 11-12 - Antidifferentiation &amp; Integration</a></li>
<li><a href="/calculus-one/week-13/index.html">Week 13 - Fundamental Theorem of Calculus</a></li>
<li><a href="/calculus-one/week-14/index.html">Week 14 - Substitution Rule</a></li>
<li><a href="/calculus-one/week-15/index.html">Week 15 - Techniques of Integration</a></li>
<li><a href="/calculus-one/week-16/index.html">Week 16 - Applications of Integration</a></li>
</ul>
<h2 id="computational-thinking"><a class="markdownIt-Anchor" href="#computational-thinking"></a> Computational Thinking</h2>
<ul>
<li><a href="/computational-thinking/lecture-1/index.html">Lecture 1 - Optimization and Knapsack Problem</a></li>
<li><a href="/computational-thinking/lecture-2/index.html">Lecture 2 - Decision Trees and Dynamic Programming</a>
<ul>
<li><a href="/computational-thinking/lecture-2-powerset/index.html">Exercise: Power Set Function</a></li>
</ul>
</li>
<li><a href="/computational-thinking/lecture-3/index.html">Lecture 3 - Graphs</a></li>
<li><a href="/computational-thinking/lecture-4-5/index.html">Lecture 4-5 - Plotting</a></li>
<li><a href="/computational-thinking/lecture-6-7/index.html">Lecture 6-7 - Stochastic Programs &amp; Inferential Statistics</a></li>
<li><a href="/computational-thinking/lecture-8/index.html">Lecture 8 - Monte Carlo Simulation</a></li>
<li><a href="/computational-thinking/lecture-9/index.html">Lecture 9 - Sampling and Standard Error</a></li>
<li><a href="/computational-thinking/lecture-10-11/index.html">Lecture 10-11 - Experimental Data</a></li>
<li><a href="/computational-thinking/lecture-12/index.html">Lecture 12 - Machine Learning</a></li>
<li><a href="/computational-thinking/lecture-13/index.html">Lecture 13 - Statistical Abuses</a></li>
</ul>
<h2 id="effective-thinking-through-mathematics"><a class="markdownIt-Anchor" href="#effective-thinking-through-mathematics"></a> Effective Thinking Through Mathematics</h2>
<ul>
<li><a href="/effective-thinking-through-mathematics/note/index.html">Note</a></li>
<li><a href="/effective-thinking-through-mathematics/week-4-telling-the-story-of-infinity/index.html">Week 4 (/Telling the Story of Infinity)</a></li>
<li><a href="/effective-thinking-through-mathematics/week-5-telling-the-story-of-the-euler-circuit-theorem/index.html">Week 5 (/Telling the Story of Euler Circuit Theorem)</a></li>
</ul>
<h2 id="cs50-introduction-to-computer-science"><a class="markdownIt-Anchor" href="#cs50-introduction-to-computer-science"></a> CS50 Introduction to Computer Science</h2>
<ul>
<li><a href="/cs50/week-1/index.html">Week 1 - C</a></li>
<li><a href="/cs50/week-2/index.html">Week 2 - Arrays</a></li>
<li><a href="/cs50/week-3/index.html">Week 3 - Algorithms</a></li>
<li><a href="/cs50/week-4/index.html">Week 4 - Memory</a></li>
<li><a href="/cs50/week-5/index.html">Week 5 - Data Structures</a></li>
<li><a href="/cs50/week-6/index.html">Week 6 - HTTP</a></li>
<li><a href="/cs50/week-7-10/index.html">Week 7-10 - Machine Learning/Python/SQL/Javascript</a></li>
</ul>
<h2 id="others"><a class="markdownIt-Anchor" href="#others"></a> Others</h2>
<ul>
<li><a href="/symbols/index.html">Symbols of Mathematics</a></li>
<li><a href="/glossary/index.html">Glossary</a></li>
</ul>
<h2 id="about-me"><a class="markdownIt-Anchor" href="#about-me"></a> <a target="_blank" rel="noopener" href="https://ericy.me/about/">About Me</a></h2>

</div>


<script src="/js/book-menu.js"></script>

  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1 id="p3l3-inter-process-communication"><a class="markdownIt-Anchor" href="#p3l3-inter-process-communication"></a> P3L3: Inter-Process Communication</h1>
<!-- toc -->
<ul>
<li><a href="#inter-process-communication">Inter Process Communication</a></li>
<li><a href="#message-based-ipc">Message Based IPC</a>
<ul>
<li><a href="#forms-of-message-passing">Forms of Message Passing</a></li>
</ul>
</li>
<li><a href="#shared-memory-ipc">Shared Memory IPC</a></li>
<li><a href="#copymessages-vs-mapshared-memory">Copy(messages) vs. Map(shared memory)</a></li>
<li><a href="#sysv-shared-memory">SysV Shared Memory</a>
<ul>
<li><a href="#sysv-shared-memory-apis">SysV Shared Memory APIs</a></li>
</ul>
</li>
<li><a href="#posix-shared-memory">POSIX Shared Memory</a>
<ul>
<li><a href="#posix-shared-memory-apis">POSIX Shared Memory APIs</a></li>
</ul>
</li>
<li><a href="#shared-memory-and-sync">Shared Memory and Sync</a>
<ul>
<li><a href="#pthreads-sync-for-ipc">PThreads Sync for IPC</a></li>
<li><a href="#sync-for-other-ipc">Sync for Other IPC</a></li>
<li><a href="#ipc-command-line-tools">IPC Command Line Tools</a></li>
</ul>
</li>
<li><a href="#shared-memory-design-considerations">Shared Memory Design Considerations</a></li>
</ul>
<!-- tocstop -->
<hr>
<h2 id="inter-process-communication"><a class="markdownIt-Anchor" href="#inter-process-communication"></a> Inter Process Communication</h2>
<ul>
<li><strong>Inter process communication (IPC)</strong> is a set of mechanisms that OS supported for interactions among processes (coordination &amp; communication). The mechanism can be categorized as either <strong>message-based</strong> or <strong>memory-based</strong>.
<ul>
<li>message-based. e.g. sockets, pipes, message queue, etc.</li>
<li>memory-based: shared memory, memory mapped files.</li>
</ul>
</li>
<li>A high-level semantics is RPC, it provides some additional detail as to the protocol(s) that will be used. We will talk about it later.</li>
<li>One important requirement for IPC is <strong>synchronization primitives</strong>.</li>
</ul>
<h2 id="message-based-ipc"><a class="markdownIt-Anchor" href="#message-based-ipc"></a> Message Based IPC</h2>
<ul>
<li>In messaged-based IPC, the operating system is responsible for creating and maintaining the channel that is used to send these messages, i.e. socket/port.</li>
<li>OS create and maintains a channel, such as buffer, FIFO queue.</li>
<li>OS provides interface to processes – port
<ul>
<li>Processes send/write message to a port</li>
<li>Other processes recv/read message from a port</li>
</ul>
</li>
<li>The kernel required to establish communication and perform each IPC operation</li>
<li>The interaction between process require
<ul>
<li>send: system call + data copy</li>
<li>recv: system call + data copy</li>
</ul>
</li>
<li>In total request-response interaction requires <strong>four user/kernel crossings and four data copying operations</strong>.</li>
<li>drawback: overheads, too many ops: user/kernel crossing ,and copying data in and out of the kernel</li>
<li>advantage: simplicity: kernel does channel management and synchronization</li>
</ul>
<h3 id="forms-of-message-passing"><a class="markdownIt-Anchor" href="#forms-of-message-passing"></a> Forms of Message Passing</h3>
<ul>
<li>
<p>Several ways to implement, we will talk about <strong>pipes</strong>, <strong>message queue</strong> and <strong>sockets</strong>.</p>
</li>
<li>
<p>Pipes</p>
<ul>
<li>Pipes are characterized by two endpoints, so <strong>only two processes can communicate via a pipe</strong>. There is no notion of a message with pipes; instead, there is just a stream of bytes pushed into the pipe from one process and read from the pipe by the other process.
<ul>
<li>Think about the pipe: <code>|</code> in the command line</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Message Queues</p>
<ul>
<li>Messages queues understand the notion of messages that they can deliver. A sending process must submit a properly formatted message to the channel, and then the channel can deliver this message to the receiving process.</li>
<li>The OS level functionality regarding message queues includes mechanisms for message priority, custom message scheduling and more.</li>
<li>The use of message queues is supported via different APIs in Unix-based systems. Two common APIs are <strong>SysV</strong> and <strong>POSIX</strong>.</li>
</ul>
</li>
<li>
<p>Socket</p>
<ul>
<li>With sockets, processes send and receive messages through the socket interface. The socket API supports <strong>send</strong> and <strong>recv</strong> operations that allow processes to send message buffers in and out of the kernel-level communication buffer.</li>
<li>For instance, the socket may be a TCP/IP socket, which means that the entire TCP/IP protocol stack is associated with the socket buffer.</li>
</ul>
</li>
<li>
<p>For message queues, the linux system calls that used for</p>
<ul>
<li>send message to a message queue: <code>msgsnd</code></li>
<li>receive messages from a message queue: <code>msgrcv</code></li>
<li>perform a message control operation: <code>msgctl</code></li>
<li>get a message identifier: <code>msgget</code></li>
</ul>
</li>
</ul>
<h2 id="shared-memory-ipc"><a class="markdownIt-Anchor" href="#shared-memory-ipc"></a> Shared Memory IPC</h2>
<ul>
<li>In shared memory IPC, processes read and write into a shared memory region. The operating system is involved in establishing the shared memory channel between the processes. What this means is that the OS will map certain physical memory pages into the virtual address spaces of both processes.
<ul>
<li>The virtual addresses in each process pointing to the shared physical location do not have to be the same.</li>
<li>In addition, the shared physical memory section does not need to be contiguous.</li>
</ul>
</li>
<li>The benefit of this approach is that once the physical memory is mapped into both address spaces, the operating system is out of the way. System calls are used only in the setup phase.</li>
<li>Data copies are reduced, but not necessarily avoided. For data to be available to both processes, it needs to explicitly be allocated from the virtual addresses the belong to the shared memory region. If that is not the case, the data within the same address space needs to be copied in and out of the shared memory region.</li>
<li>Since the shared memory area can be concurrently accessed by both processes, this means that processes must explicitly synchronize their shared memory operations. In addition, it is now the developer’s responsibility to handle any protocol-related implementations, which adds to the complexity of the application.</li>
<li>Unix-based system support two popular shared memory APIs: SysV and POSIX. In addition, shared memory IPC can be established between processes by using a memory-mapped file.</li>
</ul>
<h2 id="copymessages-vs-mapshared-memory"><a class="markdownIt-Anchor" href="#copymessages-vs-mapshared-memory"></a> Copy(messages) vs. Map(shared memory)</h2>
<ul>
<li>
<img src="https://i.imgur.com/svs0b6F.jpg" style="width: 600px" />
</li>
<li>Windows systems leverage this difference. If the data that needs to be transferred is smaller than a certain threshold, the data is copied in and out of a communication channel via a port-like interface. Otherwise the data is mapped into the address space of the target process. This mechanism is called <strong>Local Procedure Calls (LPC).</strong></li>
</ul>
<h2 id="sysv-shared-memory"><a class="markdownIt-Anchor" href="#sysv-shared-memory"></a> SysV Shared Memory</h2>
<ul>
<li>The operating systems supports <strong>segments</strong> of shared memory, which don’t need to correspond to contiguous physical pages. The operating system treats shared memory as a shared resource using <strong>system wide</strong> policies. That means that there is a limit on the total number of segments and the total size of the shared memory. Currently in Linux the limit is 4000 segments, although in the past it was as few as 6.</li>
<li>functions for managing shared memory
<ul>
<li>create
<ul>
<li>OS allocates the required amount of physical memory and then it assigns to it a unique key. This key is used to uniquely identify the segment within the operating system. Another other process can refer to this segment using this key.</li>
</ul>
</li>
<li>attach
<ul>
<li>OS establishes a valid mapping between the virtual addresses of that process and the physical addresses that back the segment.</li>
</ul>
</li>
<li>detach
<ul>
<li>invalidating the virtual address mappings</li>
</ul>
</li>
<li>destroy
<ul>
<li>Once a segment is created, it’s essentially a persistent entity until there is an explicit request for it to be destroyed.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="sysv-shared-memory-apis"><a class="markdownIt-Anchor" href="#sysv-shared-memory-apis"></a> SysV Shared Memory APIs</h3>
<ul>
<li><code>shmget(shmid, size, flag)</code> &lt;-- create or open a segment
<ul>
<li>specify the size of the segment through the size argument, and we can set various flags, like permission flags, with the flag argument.</li>
<li>The shmid is the key that references the shared memory segment. This is not created by the operating system, but rather has to be passed to it by the application.</li>
</ul>
</li>
<li><code>ftok(pathname, proj_id)</code> &lt;-- generate the key
<ul>
<li>This function generates a token based on its arguments. If you pass it the same arguments you will always get the same key. It’s basically a hashing function. This is how different processes can agree upon how they will obtain a unique key for the memory segment they wish to share.</li>
</ul>
</li>
<li><code>shmat(shmid, addr, flags)</code> &lt;-- attach the shared memory segment
<ul>
<li>The programmer has an option to provide the virtual addresses to which the segment should be mapped, using the addr argument. If NULL is passed, the operating system will choose some suitable addresses.</li>
<li>The returned virtual memory address can be interpreted in various ways, so it is the programmer’s responsibility to cast the address to that memory region to the appropriate type.</li>
</ul>
</li>
<li><code>shmdt(shmid)</code> &lt;-- detach a segment
<ul>
<li>This call invalidates the virtual to physical mappings associated with this shared segment.</li>
</ul>
</li>
<li><code>shmctl(shmid, cmd, buf)</code>
<ul>
<li>To send commands to the operating system in reference to the shared memory segment.</li>
<li>If we specify IPC_RMID as the cmd, we can destroy the segment.</li>
</ul>
</li>
<li>more detail: <a target="_blank" rel="noopener" href="https://tldp.org/LDP/lpg/node21.html">https://tldp.org/LDP/lpg/node21.html</a></li>
</ul>
<h2 id="posix-shared-memory"><a class="markdownIt-Anchor" href="#posix-shared-memory"></a> POSIX Shared Memory</h2>
<ul>
<li>The POSIX shared memory standard doesn’t use segments, but files. They are not “real” files that live in a filesystem that are used elsewhere by the operating system. Instead they are files that live in the <strong>tmpfs</strong> filesystem.</li>
<li>Since shared memory segments are now referenced by a file descriptor, there is no longer a need for the key generation process.</li>
</ul>
<h3 id="posix-shared-memory-apis"><a class="markdownIt-Anchor" href="#posix-shared-memory-apis"></a> POSIX Shared Memory APIs</h3>
<ul>
<li>The functions:
<ul>
<li>created/opened:  <code>shm_open()</code>.</li>
<li>attach/detach shared memory: <code>mmap()</code> and <code>munmap()</code></li>
<li>destroy a shared memory region: <code>shm_unlink()</code></li>
<li>remove file descriptor from the address space of the process: <code>shm_close()</code>, not destroy</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man7/shm_overview.7.html">https://man7.org/linux/man-pages/man7/shm_overview.7.html</a></li>
</ul>
<h2 id="shared-memory-and-sync"><a class="markdownIt-Anchor" href="#shared-memory-and-sync"></a> Shared Memory and Sync</h2>
<ul>
<li>Shared memory has the same situation we encountered in multithreaded environments – synchronization.</li>
<li>Couple of options for handling inter-process synchronization:
<ol>
<li>mechanism supported by process threading library (PThread)</li>
<li>OS-supported IPC for synchronization</li>
</ol>
</li>
<li>Either method must coordinate
<ul>
<li>number of concurrent accesses to shared segment (i.e. mutexes)</li>
<li>when data is available and ready for consmption(i.e. signals)</li>
<li><a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man3/mq_notify.3.html">mq_notify()</a> and <a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man3/sem_wait.3.html">sem_wait()</a>  in Linux</li>
</ul>
</li>
</ul>
<h3 id="pthreads-sync-for-ipc"><a class="markdownIt-Anchor" href="#pthreads-sync-for-ipc"></a> PThreads Sync for IPC</h3>
<ul>
<li>The property of the mutex or the condition variable when they are created is whether or not that synchronization variable is private to a process or shared amongst processes.</li>
<li>The keyword for this is <strong>PTHREAD_PROCESS_SHARED</strong>. If we specify this in the attribute structs that are passed to mutex/condition variable initialization we will ensure that our synchronization variables will be visible across processes.</li>
<li>One very important thing is that these data structures for the synchronization construct are allocated from the shared memory region must be visible to both processes!</li>
<li>
<img src="https://i.imgur.com/zK6k5Je.jpg" style="width: 600px" />
</li>
<li>To create the shared memory segment, we first need to create our <strong>segment identifier</strong>. We do this with <code>ftok</code>, passing <code>arg[0]</code> which is the pathname for the program executable as well as some integer parameter. We pass this <strong>id</strong> into <code>shmget</code>, where we specify a <strong>segment size of 1KB</strong> and also pass in some flags.</li>
<li>Using the segment id, we attach the segment with <code>shmat</code>, which returns a shared memory address - which we assign to <code>shm_address</code> here. <code>shm_address</code> is the <strong>virtual address</strong> in this process’s address space that points to the physically shared memory.</li>
<li>Then we cast that address to the datatype of the struct we defined - <code>shm_data_struct_t</code>. This struct has two fields.
<ul>
<li>One field is the actual buffer of information, the data.</li>
<li>The other component is the mutex. In this example, the mutex will control access to the data.</li>
</ul>
</li>
<li>To actually create the mutex, we first have to create the <code>mutexattr</code> struct. Once we create this struct, we can set the pshared attribute with <strong>PTHREAD_PROCESS_SHARED</strong>. Then we initialize the mutex with that data structure, using the pointer to the mutex inside the struct that lives in the shared memory region.</li>
<li>This set of operations will properly allocate and initialize a mutex that is shared amongst processes.</li>
</ul>
<h3 id="sync-for-other-ipc"><a class="markdownIt-Anchor" href="#sync-for-other-ipc"></a> Sync for Other IPC</h3>
<ul>
<li>Pthreads isn’t necessarily always supported on every platform. Sometimes, we can rely on other means of synchronization in those cases, such as <strong>message queues</strong> and <strong>semaphores</strong>.</li>
<li>Message queues. Implement mutual exclusion via send/recv operations.
<ul>
<li>For example, process A can write to the data in shared memory and then send a “ready” message into the queue. Process B can receive the msg, read the data, and send an “ok” message back.</li>
</ul>
</li>
<li>Semaphores are an OS support synchronization construct and a binary semaphore can have two states, 0 or 1.
<ul>
<li>When a semaphore has a value of 0, the process will be blocked. If the semaphore has a value of 1, the process will decrement the value (to 0) and will proceed.</li>
</ul>
</li>
</ul>
<h3 id="ipc-command-line-tools"><a class="markdownIt-Anchor" href="#ipc-command-line-tools"></a> IPC Command Line Tools</h3>
<ul>
<li>Linux provided some command line utilities for using IPC in general.
<ul>
<li><code>ipcs</code> -&gt; list all IPC facilities
<ul>
<li><code>-m</code> display info on shared memory IPC only</li>
</ul>
</li>
<li><code>ipcrm</code> -&gt; delete IPC facility
<ul>
<li><code>-m [shmid]</code> deletes shm segment with given id</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="shared-memory-design-considerations"><a class="markdownIt-Anchor" href="#shared-memory-design-considerations"></a> Shared Memory Design Considerations</h2>
<ul>
<li>Consider
<ul>
<li>different APIs/mechanisms for synchronization</li>
<li>OS provides shared memory, and is out of the way</li>
<li>data passing/sync protocols are up to the programmer</li>
</ul>
</li>
<li>Ask
<ul>
<li>How many segments you need?
<ul>
<li>1 large segment -&gt; manager for allocating/freeing memory from shared segment</li>
<li>multiple segments, one for each pairwise communication
<ul>
<li>use pool of segments to avoid creating in the middle of execution</li>
<li>use a queue of segment ids  to manage the segments for communicating among processes
<ul>
<li>or via some other mechanism like message queue.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>How large  the segment it should be?
<ul>
<li>if you know the size up front like static size, you can set up the segment size == data size</li>
<li>if want to support arbitrary messages sizes that are potentially much larger than the segment size,
<ul>
<li>One option is to transfer the data in rounds. The sending process sends the message in chunks, and the receiving process reads in those chunks and saves them somewhere until the entire message is received. In this case, the programmer will need to include some protocol to track the progress of the data movement through the shared memory region.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>


  <div class="book-comments">
    




  </div>



<script src="/js/book-post.js"></script>


<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">
  
  <div class="divider"></div>
</div>

  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>


<script src="/js/book-toc.js"></script>

</div>

      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>


<script src="/js/book.js"></script>
