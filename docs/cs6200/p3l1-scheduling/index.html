<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/favicon.png" />
    

    <title>
        
          Eric&#39;s CS Notes
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    
<link rel="stylesheet" href="/css/book.css">

    
<script src="/js/book.js"></script>


    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">
    
    <!-- katex -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/">
    <img src="/favicon.png">
    <span>ERIC&#39;S CS NOTES</span>
  </a>
</div>

    <div class="book-menu">
  <!--
## Introduction to Probability

* [Unit 1: Probability models and axioms](/introduction-to-probability/unit-1/index.html)
* [Unit 2: Conditioning and independence](/introduction-to-probability/unit-2/index.html)
* [Unit 3: Counting](/introduction-to-probability/unit-3/index.html)
* [Unit 4: Discrete random variables](/introduction-to-probability/unit-4/index.html)
* [Unit 5: Continuous random variables](/introduction-to-probability/unit-5/index.html)
* [Unit 6: Further topics on random variables](/introduction-to-probability/unit-6/index.html)
* [Unit 7: Bayesian inference](/introduction-to-probability/unit-7/index.html)
* [Unit 8: Limit theorems and classical statistics](/introduction-to-probability/unit-8/index.html)
* [Unit 9: Bernoulli and Poisson processes](/introduction-to-probability/unit-9/index.html)
* [Unit 10: Markov chains](/introduction-to-probability/unit-10/index.html)
-->
<!--
## Multivariable Calculus

* [Unit 1: Thinking about multivariable functions](/multivariable-calculus/unit-1/index.html)
* [Unit 2: Derivatives of multivariable functions](/multivariable-calculus/unit-2/index.html)

* [Unit 3: Applications of multivariable derivatives](/multivariable-calculus/unit-3/index.html)
* [Unit 4: Integrating multivariable functions](/multivariable-calculus/unit-4/index.html)
* [Unit 5: Green's, Stokes', and the divergence theorems](/multivariable-calculus/unit-5/index.html)
-->
<h2 id="cs6250-computer-networks"><a class="markdownIt-Anchor" href="#cs6250-computer-networks"></a> CS6250 Computer Networks</h2>
<ul>
<li><a href="/cs6250/week-1-internet-architecture/index.html">Week 1 - Internet Architecture</a></li>
<li><a href="/cs6250/week-2-transport-and-application-layers/index.html">Week 2 - Transport and Application Layers</a></li>
<li><a href="/cs6250/week-3-intradomain-routing/index.html">Week 3 - Intradomain Routing</a></li>
<li><a href="/cs6250/week-4-as-relationships-and-interdomain-routing/index.html">Week 4 - AS Relationships and Interdomain Routing</a></li>
<li><a href="/cs6250/week-5-router-design-and-algorithems-part-1/index.html">Week 5 - Router Design and Algorithms (Part 1)</a></li>
<li><a href="/cs6250/week-6-router-design-and-algorithems-part-2/index.html">Week 6 - Router Design and Algorithms (Part 2)</a></li>
</ul>
<!--
* [Week 7 - Software Defined Networking (Part 1)](/cs6250/week-7-software-defined-networking-part-1/index.html)
* [Week 8 - Software Defined Networking (Part 2)](/cs6250/week-8-software-defined-networking-part-2/index.html)
* [Week 9 - Internet Security](/cs6250/week-9-internet-security/index.html)
* [Week 10 - Internet Surveillance and Censorship](/cs6250/week-10-internet-surveillance-and-censorship/index.html)
* [Week 11 - Applications Videos](/cs6250/week-11-applications-video/index.html)
* [Week 12 - Applications CDNs and Overlay Networks](/cs6250/week-12-applications-cdns-and-overlay-networks/index.html)
-->
<h2 id="cs6200-graduate-introduction-to-operating-systems"><a class="markdownIt-Anchor" href="#cs6200-graduate-introduction-to-operating-systems"></a> CS6200 Graduate Introduction to Operating Systems</h2>
<ul>
<li><a href="/cs6200/p1-preparation/index.html">P0 - Preparation</a></li>
<li><a href="/cs6200/p1l2-introduction/index.html">P1L2 - Introduction</a></li>
<li><a href="/cs6200/p2l1-processes-and-process-management/index.html">P2L1 - Processes and Process Management</a></li>
<li><a href="/cs6200/p2l2-threads-and-concurrency/index.html">P2L2 - Threads and Concurrency</a></li>
<li><a href="/cs6200/p2l3-pthread/index.html">P2L3 - PThread</a></li>
<li><a href="/cs6200/p2l4-thread-design-consideration/index.html">P2L4 - Thread Design Considerations</a></li>
<li><a href="/cs6200/p2l5-thread-performance-consideration/index.html">P2L5 - Thread Performance Considerations</a></li>
<li><a href="/cs6200/p3l1-scheduling/index.html">P3L1 - Scheduling</a></li>
<li><a href="/cs6200/p3l2-memory-management/index.html">P3L2 - Memory Management</a></li>
<li><a href="/cs6200/p3l3-inter-process-communication/index.html">P3L3 - Inter-Process Communication</a></li>
</ul>
<!--
* [P3L4 - Synchronization Constructs](/cs6200/p3l4-synchronization-constructs/index.html) 
* [P3L5 - I/O Management](/cs6200/p3l5-io-management/index.html) 
* [P3L6 - Virtualization](/cs6200/p3l6-virtualization/index.html) 
* [P4L1 - Remote Procedure Calls](/cs6200/p4l1-remote-procedure-calls/index.html) 
* [P4L2 - Distributed File Systems](/cs6200/p4l2-distributed-file-systems/index.html) 
* [P4L3 - Distributed Shared Memory](/cs6200/p4l3-distributed-shared-memory/index.html) 
* [P4L4 - Datacenter Technologies](/cs6200/p4l4-datacenter-technologies/index.html) 
* [P5L1 - Memory Management](/cs6200/p5l1-memory-management-t/index.html)
-->
<h2 id="algorithms-part-ii"><a class="markdownIt-Anchor" href="#algorithms-part-ii"></a> Algorithms: Part II</h2>
<ul>
<li><a href="/algorithms-2/week-1/index.html">Week 1 - Undirected Graph &amp; Directed Graph</a></li>
<li><a href="/algorithms-2/week-2/index.html">Week 2 - Minimum Spanning Trees &amp; Shortest Path</a></li>
<li><a href="/algorithms-2/week-3/index.html">Week 3 - Maximum Flow and Minimum Cut &amp; String Sort</a></li>
<li><a href="/algorithms-2/week-4/index.html">Week 4 - Tries &amp; Substring Search</a></li>
<li><a href="/algorithms-2/week-5/index.html">Week 5 - Regular Expressions</a></li>
<li><a href="/algorithms-2/week-6/index.html">Week 6 - Reductions</a></li>
</ul>
<h2 id="algorithms-part-i"><a class="markdownIt-Anchor" href="#algorithms-part-i"></a> Algorithms: Part I</h2>
<ul>
<li><a href="/algorithms-1/week-1/index.html">Week 1 - Union-Find &amp; Analysis of Algorithms</a></li>
<li><a href="/algorithms-1/week-2/index.html">Week 2 - Stacks and Queues &amp; Elementary Sorts</a></li>
<li><a href="/algorithms-1/week-3/index.html">Week 3 - Mergesort &amp; Quicksort</a></li>
<li><a href="/algorithms-1/week-4/index.html">Week 4 - Priority Queues &amp; Elementary Symbols</a></li>
<li><a href="/algorithms-1/week-5/index.html">Week 5 - Balanced Search Trees</a></li>
<li><a href="/algorithms-1/week-6/index.html">Week 6 - Hash Tables</a></li>
</ul>
<h2 id="introduction-to-software-design-and-architecture"><a class="markdownIt-Anchor" href="#introduction-to-software-design-and-architecture"></a> Introduction to Software Design and Architecture</h2>
<ul>
<li><a href="/introduction-to-software-design-and-architecture/design-pattern/index.html">Design Pattern</a></li>
</ul>
<h2 id="calculus-two-sequences-and-series"><a class="markdownIt-Anchor" href="#calculus-two-sequences-and-series"></a> Calculus Two: Sequences and Series</h2>
<ul>
<li><a href="/calculus-two/week-1/index.html">Week 1 - Sequences</a></li>
<li><a href="/calculus-two/week-2/index.html">Week 2 - Series</a></li>
<li><a href="/calculus-two/week-3/index.html">Week 3 - Convergence Tests</a></li>
<li><a href="/calculus-two/week-4/index.html">Week 4 - Alternating Series</a></li>
<li><a href="/calculus-two/week-5/index.html">Week 5 - Power Series</a></li>
<li><a href="/calculus-two/week-6/index.html">Week 6 - Taylor Series</a></li>
</ul>
<h2 id="laff-linear-algebra"><a class="markdownIt-Anchor" href="#laff-linear-algebra"></a> LAFF Linear Algebra</h2>
<ul>
<li><a href="/laff-linear-algebra/week-1/index.html">Week 1 - Vectors in Linear Algebra</a></li>
<li><a href="/laff-linear-algebra/week-2/index.html">Week 2 - Linear Transformations and Matrices</a></li>
<li><a href="/laff-linear-algebra/week-3/index.html">Week 3 - Matrix-Vector Operations</a></li>
<li><a href="/laff-linear-algebra/week-4/index.html">Week 4 - Matrix-Vector to Matrix-Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-5/index.html">Week 5 - Matrix- Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-6/index.html">Week 6 - Gaussian Elimination</a></li>
<li><a href="/laff-linear-algebra/week-7/index.html">Week 7 - More Gaussian Elimination and Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-8/index.html">Week 8 - More on Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-9/index.html">Week 9 - Vector Spaces</a></li>
<li><a href="/laff-linear-algebra/week-10/index.html">Week 10 - Vector Spaces, Orthogonality, and Linear Least-Squares</a></li>
<li><a href="/laff-linear-algebra/week-11/index.html">Week 11 - Orthogonal Projection, Low Rank Approximation, and Orthogonal Bases</a></li>
<li><a href="/laff-linear-algebra/week-12/index.html">Week 12 - Eigenvalues and Eigenvectors</a></li>
</ul>
<h2 id="stanford-machine-learning"><a class="markdownIt-Anchor" href="#stanford-machine-learning"></a> Stanford Machine Learning</h2>
<ul>
<li><a href="/stanford-machine-learning/week-1/index.html">Week 1 - Introduction</a></li>
<li><a href="/stanford-machine-learning/week-2/index.html">Week 2 - Linear Regression with Multiple Variables</a></li>
<li><a href="/stanford-machine-learning/week-3/index.html">Week 3 - Logistic Regression &amp; Regularization</a></li>
<li><a href="/stanford-machine-learning/week-4/index.html">Week 4 - Neural Networks: Representation</a></li>
<li><a href="/stanford-machine-learning/week-5/index.html">Week 5 - Neural Networks: Learning</a></li>
<li><a href="/stanford-machine-learning/week-6a/index.html">Week 6a - Advice for Applying Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-6b/index.html">Week 6b - Machine Learning System Design</a></li>
<li><a href="/stanford-machine-learning/week-7/index.html">Week 7 - Support Vector Machines</a></li>
<li><a href="/stanford-machine-learning/week-8/index.html">Week 8 - Unsupervised Learning &amp; Dimensionality Reduction</a></li>
<li><a href="/stanford-machine-learning/week-9a/index.html">Week 9a - Anomaly Detection</a></li>
<li><a href="/stanford-machine-learning/week-9b/index.html">Week 9b - Recommender Systems</a></li>
<li><a href="/stanford-machine-learning/week-10/index.html">Week 10 - Large Scale Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-11/index.html">Week 11 - Application Example: Photo OCR</a></li>
</ul>
<h2 id="calculus-one"><a class="markdownIt-Anchor" href="#calculus-one"></a> Calculus One</h2>
<ul>
<li><a href="/calculus-one/week-2-3/index.html">Week 2-3 - Functions &amp; Limits</a></li>
<li><a href="/calculus-one/week-4/index.html">Week 4 - The Beginning of Derivatives</a></li>
<li><a href="/calculus-one/week-5/index.html">Week 5 - Techniques of Differentiation</a></li>
<li><a href="/calculus-one/week-6/index.html">Week 6 - Chain Rule</a></li>
<li><a href="/calculus-one/week-7/index.html">Week 7 - Derivatives of Trigonometric Functions</a></li>
<li><a href="/calculus-one/week-8/index.html">Week 8 - Derivatives in the Real World</a></li>
<li><a href="/calculus-one/week-9/index.html">Week 9 - Optimization</a></li>
<li><a href="/calculus-one/week-10/index.html">Week 10 - Linear Approximation</a></li>
<li><a href="/calculus-one/week-11-12/index.html">Week 11-12 - Antidifferentiation &amp; Integration</a></li>
<li><a href="/calculus-one/week-13/index.html">Week 13 - Fundamental Theorem of Calculus</a></li>
<li><a href="/calculus-one/week-14/index.html">Week 14 - Substitution Rule</a></li>
<li><a href="/calculus-one/week-15/index.html">Week 15 - Techniques of Integration</a></li>
<li><a href="/calculus-one/week-16/index.html">Week 16 - Applications of Integration</a></li>
</ul>
<h2 id="computational-thinking"><a class="markdownIt-Anchor" href="#computational-thinking"></a> Computational Thinking</h2>
<ul>
<li><a href="/computational-thinking/lecture-1/index.html">Lecture 1 - Optimization and Knapsack Problem</a></li>
<li><a href="/computational-thinking/lecture-2/index.html">Lecture 2 - Decision Trees and Dynamic Programming</a>
<ul>
<li><a href="/computational-thinking/lecture-2-powerset/index.html">Exercise: Power Set Function</a></li>
</ul>
</li>
<li><a href="/computational-thinking/lecture-3/index.html">Lecture 3 - Graphs</a></li>
<li><a href="/computational-thinking/lecture-4-5/index.html">Lecture 4-5 - Plotting</a></li>
<li><a href="/computational-thinking/lecture-6-7/index.html">Lecture 6-7 - Stochastic Programs &amp; Inferential Statistics</a></li>
<li><a href="/computational-thinking/lecture-8/index.html">Lecture 8 - Monte Carlo Simulation</a></li>
<li><a href="/computational-thinking/lecture-9/index.html">Lecture 9 - Sampling and Standard Error</a></li>
<li><a href="/computational-thinking/lecture-10-11/index.html">Lecture 10-11 - Experimental Data</a></li>
<li><a href="/computational-thinking/lecture-12/index.html">Lecture 12 - Machine Learning</a></li>
<li><a href="/computational-thinking/lecture-13/index.html">Lecture 13 - Statistical Abuses</a></li>
</ul>
<h2 id="effective-thinking-through-mathematics"><a class="markdownIt-Anchor" href="#effective-thinking-through-mathematics"></a> Effective Thinking Through Mathematics</h2>
<ul>
<li><a href="/effective-thinking-through-mathematics/note/index.html">Note</a></li>
<li><a href="/effective-thinking-through-mathematics/week-4-telling-the-story-of-infinity/index.html">Week 4 (/Telling the Story of Infinity)</a></li>
<li><a href="/effective-thinking-through-mathematics/week-5-telling-the-story-of-the-euler-circuit-theorem/index.html">Week 5 (/Telling the Story of Euler Circuit Theorem)</a></li>
</ul>
<h2 id="cs50-introduction-to-computer-science"><a class="markdownIt-Anchor" href="#cs50-introduction-to-computer-science"></a> CS50 Introduction to Computer Science</h2>
<ul>
<li><a href="/cs50/week-1/index.html">Week 1 - C</a></li>
<li><a href="/cs50/week-2/index.html">Week 2 - Arrays</a></li>
<li><a href="/cs50/week-3/index.html">Week 3 - Algorithms</a></li>
<li><a href="/cs50/week-4/index.html">Week 4 - Memory</a></li>
<li><a href="/cs50/week-5/index.html">Week 5 - Data Structures</a></li>
<li><a href="/cs50/week-6/index.html">Week 6 - HTTP</a></li>
<li><a href="/cs50/week-7-10/index.html">Week 7-10 - Machine Learning/Python/SQL/Javascript</a></li>
</ul>
<h2 id="others"><a class="markdownIt-Anchor" href="#others"></a> Others</h2>
<ul>
<li><a href="/symbols/index.html">Symbols of Mathematics</a></li>
<li><a href="/glossary/index.html">Glossary</a></li>
</ul>
<h2 id="about-me"><a class="markdownIt-Anchor" href="#about-me"></a> <a target="_blank" rel="noopener" href="https://ericyy.me/about/">About Me</a></h2>

</div>


<script src="/js/book-menu.js"></script>

  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1 id="p3l1-scheduling"><a class="markdownIt-Anchor" href="#p3l1-scheduling"></a> P3L1 : Scheduling</h1>
<!-- toc -->
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#scheduling-algorithm">Scheduling Algorithm</a>
<ul>
<li><a href="#run-to-completion">Run To Completion</a></li>
<li><a href="#preemptive">Preemptive</a></li>
<li><a href="#round-robin-scheduling">Round Robin Scheduling</a></li>
</ul>
</li>
<li><a href="#timesharing-and-timeslices">Timesharing and Timeslices</a>
<ul>
<li><a href="#how-long-should-a-timeslice-be">How Long Should a Timeslice Be</a></li>
<li><a href="#summarizing-timeslice-length">Summarizing Timeslice Length</a></li>
</ul>
</li>
<li><a href="#runqueue-data-structure">Runqueue Data Structure</a>
<ul>
<li><a href="#linux-o1-scheduler">Linux O(1) Scheduler</a></li>
<li><a href="#linux-cfs-scheduler">Linux CFS Scheduler</a></li>
</ul>
</li>
<li><a href="#scheduling-on-multiprocessors">Scheduling on Multiprocessors</a>
<ul>
<li><a href="#hyperthreading">Hyperthreading</a></li>
<li><a href="#scheduling-for-hyperthreading-platforms">Scheduling for Hyperthreading Platforms</a></li>
<li><a href="#how-do-tell-a-thread-is-cpu-bound-or-memory-bound">How do tell a thread is CPU bound or memory bound?</a></li>
<li><a href="#scheduling-with-hardware-counters">Scheduling with Hardware Counters</a></li>
</ul>
</li>
<li><a href="#-">----</a></li>
<li><a href="#scheduler-choose-what-to-run">Scheduler – choose what to run</a>
<ul>
<li><a href="#scheduling-multi-level-feedback-queue-mlfq">Scheduling - Multi-level Feedback Queue (MLFQ)</a></li>
<li><a href="#scheduling-proportional-share">Scheduling - Proportional Share</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<hr />
<h2 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h2>
<ul>
<li>The CPU scheduler
<ul>
<li>decides how and when the processes (and their threads) access the shared CPUs.</li>
<li>schedules tasks running on both user level and kernel level.</li>
</ul>
</li>
<li>The CPU scheduler choose one of the ready tasks to run on CPU, and it runs when
<ul>
<li>CPU becomes idle</li>
<li>new task becomes ready</li>
<li>timeslice expired timeout</li>
</ul>
</li>
<li>Once the thread is dispatched on CPU, the CPU will do all of the jobs: context switch, enter user mode, set PC, and go.</li>
<li>The questions are:
<ul>
<li>which task should be selected? -&gt; schedule policy/algorithm</li>
<li>how is this done? -&gt; depends on runqueue data structure</li>
</ul>
</li>
</ul>
<h2 id="scheduling-algorithm"><a class="markdownIt-Anchor" href="#scheduling-algorithm"></a> Scheduling Algorithm</h2>
<h3 id="run-to-completion"><a class="markdownIt-Anchor" href="#run-to-completion"></a> Run To Completion</h3>
<ul>
<li><strong>Run To Completion</strong> scheduling assumes that once a task is assigned to a CPU, it will run on that CPU until it is finished.</li>
<li>Initial assumptions:
<ul>
<li>group of tasks/jobs</li>
<li>known execution times</li>
<li>no preemption</li>
<li>single CPU</li>
</ul>
</li>
<li>common metrics we use for measuring the performance of the algorithms:
<ul>
<li>throughput</li>
<li>average job completion time</li>
<li>average job wait time</li>
<li>CPU utilization</li>
</ul>
</li>
<li>Let’s compare two implementations:
<ul>
<li><strong>First Come First Serve (FCFS)</strong>, schedule the tasks in the order of arrival.
<ul>
<li>e.g. T1(1s), T2(10s), T3(1s), arriving order: T1 - T2 - T3</li>
<li>average completion time is (1s + 11s + 12s) / 3 = 8s.</li>
<li>average wait time is (0s + 1s + 11s) / 3 = 4s.</li>
</ul>
</li>
<li><strong>Shortest Job First (SJF)</strong>, schedule the order base on their execution time.
<ul>
<li>e.g. T1(1s), T2(10s), T3(1s), arriving at the same time</li>
<li>the execution order will be: T1 -&gt; T3 -&gt; T2</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="preemptive"><a class="markdownIt-Anchor" href="#preemptive"></a> Preemptive</h3>
<ul>
<li>
<p>Preemptive means the job can be interrupted after it’s execution started.</p>
</li>
<li>
<p>SJF + Preempt</p>
<ul>
<li>
<p>T2 arrives at 0s, T1 and T3 arrives at 2s, so T2 should be preempted</p>
</li>
<li>
<img src="https://i.imgur.com/J1Qwqim.jpg" style="width: 400px" />
</li>
<li>
<p>In this case, we assumed we know the execution time. But it’s not realistic. What we can do is, generate heuristics base on the similar jobs in the past.</p>
<ul>
<li>It can base on a single task, or base on the average execution time for n past tasks <strong>(windowed average)</strong>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Priority</p>
<ul>
<li>
<p>This means we run the tasks base on their <strong>priority levels</strong>, and run the highest priority task next(preemption)</p>
</li>
<li>
<img src="https://i.imgur.com/22Dl6io.jpg" style="width: 400px" />
</li>
<li>
<p>This algorithm might causes <strong>starvation</strong>, in which a low priority task never gets executed due to high priority tasks keep jumping in.</p>
<ul>
<li>The solution is <strong>priority aging</strong>, so priority = f(actual priority, time spent in runqueue) so if a job’s priority will increase as it stays in the runqueue for long enough.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="priority-inversion"><a class="markdownIt-Anchor" href="#priority-inversion"></a> Priority Inversion</h4>
<ul>
<li>
<img src="https://i.imgur.com/b9JScO5.jpg" style="width: 600px" />
</li>
</ul>
<h3 id="round-robin-scheduling"><a class="markdownIt-Anchor" href="#round-robin-scheduling"></a> Round Robin Scheduling</h3>
<ul>
<li>each task gets to run for a <strong>time slice</strong> alternatively.
<ul>
<li>similar to FCFS, we pick up the first available task from the queue</li>
<li>each task runs a certain amount of time, or
<ul>
<li>the task yield if it waits on I/O</li>
</ul>
</li>
<li>This algorithm can work with priorities(including preemption) as well.</li>
</ul>
</li>
</ul>
<h2 id="timesharing-and-timeslices"><a class="markdownIt-Anchor" href="#timesharing-and-timeslices"></a> Timesharing and Timeslices</h2>
<ul>
<li><strong>Timeslice</strong> = maximum amount of uninterrupted time given to a task
<ul>
<li>also called <strong>time quantum</strong></li>
</ul>
</li>
<li>task may run less than timeslice time, if
<ul>
<li>the task has to wait on I/O, synchronization. The task will be placed on a queue and preempted.</li>
<li>higher priority task becomes runnable before the lower priority task’s timeslice has expired.</li>
</ul>
</li>
<li>using timeslices allows for the tasks to be interleaved. And it’s also the only way to achieve timesharing of the CPU for the CPU bound tasks.
<ul>
<li>I/O tasks are not critical though.</li>
</ul>
</li>
<li>e.g.
<ul>
<li>
<img src="https://i.imgur.com/8cscM2e.jpg" style="width: 600px" />
</li>
<li>
<p>For metrics,</p>
<ul>
<li>the throughput stays the same,</li>
<li>the average wait and average completion time are close to SJF, but no need for priority knowledge of execution times, which was said was unfeasible in a real system.</li>
</ul>
</li>
</ul>
</li>
<li>The downside of timeslicing is the overhead. We have exaggerated in our graphs that there is no latency between tasks, but this is not the case. In real case, we have to interrupt the running task, execute the scheduler, and context switch to the new task. <strong>Even when there is only one task, the scheduler sill needs to run at the timeslice intervals.</strong>
<ul>
<li>Consider this, our throughput will be lower than 0.25, and avg. wait and avg. comp. will be higher.</li>
</ul>
</li>
</ul>
<h3 id="how-long-should-a-timeslice-be"><a class="markdownIt-Anchor" href="#how-long-should-a-timeslice-be"></a> How Long Should a Timeslice Be</h3>
<ul>
<li>Depends on whether the tasks are CPU bounded or I/O bounded.</li>
</ul>
<h4 id="cpu-bound-timeslice-length"><a class="markdownIt-Anchor" href="#cpu-bound-timeslice-length"></a> CPU Bound Timeslice Length</h4>
<ul>
<li>
<img src="https://i.imgur.com/eOrJGaQ.jpg" style="width: 600px" />
</li>
</ul>
<h4 id="io-bound-timeslice-length"><a class="markdownIt-Anchor" href="#io-bound-timeslice-length"></a> I/O Bound Timeslice Length</h4>
<ul>
<li>
<img src="https://i.imgur.com/NZx7FCP.jpg" style="width: 600px" />
</li>
</ul>
<h3 id="summarizing-timeslice-length"><a class="markdownIt-Anchor" href="#summarizing-timeslice-length"></a> Summarizing Timeslice Length</h3>
<ul>
<li>CPU bound tasks prefer longer timeslices
<ul>
<li>limits the number of context switching overheads</li>
<li>keep CPU utilization and throughput high</li>
</ul>
</li>
<li>I/O bound tasks prefer short timeslices
<ul>
<li>I/O bound tasks can issue I/O earlier</li>
<li>keeps CPU and device utilization high</li>
<li>better user-perceived performance - wait time is low</li>
</ul>
</li>
</ul>
<h2 id="runqueue-data-structure"><a class="markdownIt-Anchor" href="#runqueue-data-structure"></a> Runqueue Data Structure</h2>
<ul>
<li>Runqueue is either implemented with multiple queues or a tree. The data structure is designed to help scheduler to determine which task to run next easily.</li>
<li>For example,  we want I/O and CPU bound tasks to have different timeslice values. We can either
<ol>
<li>use the same runqueue, and check the type of tasks</li>
<li>use two different data structures.</li>
</ol>
</li>
<li>Common way for the example, is to build a multi-queue data structure. Each queue associated with different timeslice values:
<ul>
<li>
<img src="https://i.imgur.com/u4Kh5jg.jpg" style="width: 500px" />
</li>
<li>The I/O intensive tasks are assigned to the queue with shorter timeslices, The CPU intensive tasks are assigned to the queue that has infinite timeslice but lowest priority.</li>
<li>The benefits with this design are:
<ul>
<li>timeslicing benefits for I/O bound tasks,</li>
<li>timeslicing overheads avoided for CPU bound tasks.</li>
</ul>
</li>
<li>To determine whether a task is CPU or I/O intensive, we can use history based heuristics. However, it won’t help with the new tasks or the tasks with dynamic behaviors.</li>
<li>To fix the problem, we can initially put every new tasks into the the queue with top priority. If the task yields before timeslice expire, then it stay in the queue, otherwise, move it down to next queue with lower priority, and keep going until it gets pushed into the last queue.</li>
<li>The resulted data structure is called <strong>Multi-Level Feedback Queue(MLFQ)</strong>, which is a group of queues that associated with different scheduling policies. The data structure provides feedback to tasks and help to adjust the tasks in different levels.</li>
</ul>
</li>
</ul>
<h3 id="linux-o1-scheduler"><a class="markdownIt-Anchor" href="#linux-o1-scheduler"></a> Linux O(1) Scheduler</h3>
<ul>
<li>
<p>The Linux O(1) scheduler add/select tasks in constant time. It’s a preemptive, priority-based scheduler, with 140 priority levels. level:0-99 are real-time tasks, level: 100-139 are timesharing tasks. The default value for a user process is 120, and can be adjusted with the <strong>nice value</strong>: (-20 - 19).</p>
<ul>
<li>
<img src="https://i.imgur.com/hngR40I.jpg" style="width: 400px" />
</li>
</ul>
</li>
<li>
<p>The O(1) scheduler use the same ideas as the MLFQ scheduler. It sets up <strong>different timeslice values to different priorities</strong>(smallest for low priority, highest for high priority), and <strong>use feedback to adjust the tasks</strong> in the future.</p>
<ul>
<li>The feedback for the task is depends on how long the task spend on sleep(waiting/idling).
<ul>
<li>longer sleep -&gt; interactive -&gt; priority -5 (boost),</li>
<li>smaller sleep -&gt; compute-intensive -&gt; priority+5(lowered)</li>
</ul>
</li>
</ul>
</li>
<li>
<p>The scheduler is implemented with two arrays: <strong>active</strong> and <strong>expired</strong>.</p>
<ul>
<li>
<img src="https://i.imgur.com/mo2lVrN.jpg" style="width: 400px" />
</li>
<li>The active list is the primary one that the scheduler uses to select the next task to run. Once the task runs, it will be put on expired array. And the two arrays will be swapped when the active array is empty.</li>
</ul>
</li>
<li>
<p>The problem of O(1) scheduler is, the task could wait unpredictable amount of time to be scheduled. Because the task will not get a chance to run again until all other tasks in the active queue have been executed.</p>
<ul>
<li>Meaning it doesn’t work well with the applications that have <strong>realtime/interactive needs</strong>, like gaming, video streaming, etc.</li>
<li>Plus, it doesn’t offer fairness guarantees as well -&gt; a task should be able to run for an amount of time that is relative to it’s priority.</li>
</ul>
</li>
</ul>
<h3 id="linux-cfs-scheduler"><a class="markdownIt-Anchor" href="#linux-cfs-scheduler"></a> Linux CFS Scheduler</h3>
<ul>
<li>As a replacement for the O(1) scheduler, the CFS scheduler was introduced to solve the problem O(1) scheduler has.</li>
<li>CFS uses a <a href="/algorithms-1/week-5/index.html#red-black-bsts">read-black tree</a> as the runqueue data structure.
<ul>
<li>
<img src="https://i.imgur.com/m2zvO5A.jpg" style="width: 400px" />
  * Red-black tree is self-balancing trees
</li>
</ul>
</li>
<li>Tasks are ordered in the tree <strong>based on the amount of time that they spent running on the CPU</strong>, a quantity known as <strong>vruntime</strong> (virtual runtime). CFS tracks this virtual runtime in a nanosecond granularity.</li>
<li>This runqueue has the property that for a given node, all nodes to the left have lower vruntimes and therefore need to be scheduled sooner, while all nodes to the right, have larger vruntimes and therefore can wait longer.</li>
<li>The CFS algorithm always schedules the task with the least amount of vruntime in the system, which is typically the leftmost node of the tree. Periodically, CFS will increment the vruntime of the task that is currently executing on the CPU, at which point it will compare this vruntime with the vruntime of the leftmost task in the tree. If the currently running task has a smaller vruntime than the leftmost node, it will keep running; otherwise, it will be preempted in favor of the leftmost node, and will be inserted appropriately back into the tree.</li>
<li>CFS changes the effective rate at which the task’s virtual time progresses. For lower priority tasks, time passes more quickly. There virtual run time value progresses faster. And therefore, they will lose their CPU more quickly. On the contrary, for the high priority tasks, time passes more slowly.</li>
<li>Performance of CFS:
<ul>
<li>select task: O(1)</li>
<li>add task: O(logN)</li>
</ul>
</li>
</ul>
<h2 id="scheduling-on-multiprocessors"><a class="markdownIt-Anchor" href="#scheduling-on-multiprocessors"></a> Scheduling on Multiprocessors</h2>
<ul>
<li><strong>multiprocessors vs multicores</strong>
<ul>
<li>Multiprocessors means there are multiple CPUs. Each CPU has its own private L1/L2 and LL(last-level)  cache which may or may not be shared among the CPUs. Although the system memory(DRAM) is shared.</li>
<li>Multicore means each CPU has multiple internal cores. Each core has it’s own private L1/L2 cache. The CPU as a whole shares LLC(last-level cache). DRAM is shared as well.</li>
<li>The performance of processes/threads is highly dependent on the amount of execution state that is present in the <strong>CPU cache</strong> or <strong>memory</strong>.
<ul>
<li>The goal is to schedule the thread onto the same CPU that it has executed before because it’s likely that the CPU cache is hot. This is called <strong>cache affinity</strong>.</li>
</ul>
</li>
<li>To achieve cache affinity, we want to keep tasks on the same CPU as much as possible. To do so, we maintain a <strong>hierarchical scheduling architecture</strong> which has a load balancing component that dividing the tasks into CPUs. Each CPU has its own scheduler with its own runqueue and responsible for scheduling tasks on that CPU exclusively.</li>
<li>To load balance across CPUs, we look at the length of each of the runqueue, and also rebalance the queues when a CPU is idle.</li>
<li>In addition to having multiple processors, it is possible to have <strong>multiple memory</strong> nodes. The CPUs and the memory nodes will be connected via some physical interconnect.  In most configurations it is common that a memory node will be closer to a socket of multiple processors, which means that access to this memory node from those processors is faster than accessing some remote memory node. We call these: <strong>non-uniform memory access (NUMA)</strong> platforms.
<ul>
<li>From a scheduling perspective, what makes sense is to keep tasks on the CPU closest to the memory node where their state is, in order to maximize the speed of memory access. We refer to this as <strong>NUMA-aware scheduling</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="hyperthreading"><a class="markdownIt-Anchor" href="#hyperthreading"></a> Hyperthreading</h3>
<ul>
<li>The reason we have to context switch among threads is because the CPU only has one set of registers to describe an execution context. Over time, hardware architects have realized they can hide some of the latency associated with context switching. One of the ways that this has been achieved is to have CPUs with multiple sets of registers where each set of registers can describe the context of a separate thread. One term is to refer this is <strong>hyperthreading</strong>.
<ul>
<li>Also called:
<ul>
<li>hardware multithreading</li>
<li>chip multithreading (CMT)</li>
<li>simultaneous multithreading <strong>(SMT)</strong></li>
</ul>
</li>
<li>In hyperthreading, we have multiple hardware-supported execution context, one CPU. So the context switch is really fast.</li>
</ul>
</li>
<li>Modern platforms often support two hardware threads, though some high performance platforms may support up to eight. Modern systems allow for hyperthreading to be enabled/disabled at boot time, as there are tradeoffs to this approach. If hyperthreading is enabled, each of these hardware contexts appears to the scheduler as an entity upon which it can schedule tasks.</li>
<li>Another feature that hyperthreading has is, <strong>hide memory access latency</strong>, because
<ul>
<li>SMT ctx_switch is in order of cycles(O(cyles)), but memory load is in order of 100 cycles(O(100 cycles)).</li>
</ul>
</li>
<li>What kinds of threads should be co-scheduled on hardware threads?
<ul>
<li><a target="_blank" rel="noopener" href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud923/references/ud923-fedorova-paper.pdf">“Chip Multithreading Systems Need a New Operating System Scheduler” by Fedorova, Alexandra, et. al.</a></li>
</ul>
</li>
</ul>
<h3 id="scheduling-for-hyperthreading-platforms"><a class="markdownIt-Anchor" href="#scheduling-for-hyperthreading-platforms"></a> Scheduling for Hyperthreading Platforms</h3>
<ul>
<li>Lets first make some assumptions:
<ol>
<li>thread can issue instruction on every single cycle
<ul>
<li>max <strong>instruction-per-cycle(IPC)</strong> = 1: <strong>CPU bound</strong> thread will be able to maximize the <strong>IPC</strong> matrix.</li>
</ul>
</li>
<li>memory access = 4 cycles
<ul>
<li>a <strong>memory bound</strong> thread will experience some idle cycles while it is waiting for the memory access to return.</li>
</ul>
</li>
<li>hardware switching instantaneous</li>
<li>SMT with 2 hardware threads</li>
</ol>
</li>
<li>Now compare different scenarios:
<ol>
<li>
<img src="https://i.imgur.com/hfj0Wg3.jpg" style="width: 400px" />
 * threads "interfere" each other,
 * "contend" for CPU pipeline resources
 * performance for each task degrades by 2x
 * memory is idle
</li>
<li>
<img src="https://i.imgur.com/KSjqhq8.jpg" style="width: 400px" />
 * CPU idle, waste CPU cycles
</li>
<li>
<img src="https://i.imgur.com/Ir847Rb.jpg" style="width: 400px" />
 * mix of CPU and memory-intensive threads
     * avoid/limit contention of processor pipeline
     * all components (CPU and memory) well utilized  
</li>
</ol>
</li>
</ul>
<h3 id="how-do-tell-a-thread-is-cpu-bound-or-memory-bound"><a class="markdownIt-Anchor" href="#how-do-tell-a-thread-is-cpu-bound-or-memory-bound"></a> How do tell a thread is CPU bound or memory bound?</h3>
<ul>
<li>Previously, we used sleep time to determine a process is interactive or CPU intensive. But it won’t work for two reasons:
<ul>
<li>The thread is not really sleeping when it is waiting on memory <a target="_blank" rel="noopener" href="http://access.It">access.It</a> is waiting at some stage in the processor pipeline, not on some software queue.</li>
<li>To keep track of the sleep time we were using software methods and that is too slow at this level. The context switch takes on the order of cycles, so we need to be able to make our decision on what to run very quickly.</li>
</ul>
</li>
<li>We need some hardware-level information in order to help make our decision.</li>
<li>Most modern platforms contain <strong>hardware counters</strong> that get updated as the processor executes and keep information about various aspects of execution, like
<ul>
<li>L1, L2 … LLC cache misses</li>
<li>Instructions Per Cycle (IPC) metrics</li>
<li>Power/Energy usage data</li>
</ul>
</li>
<li>Tools  for accessing these hardware counters, such as oprofile, linux perf tool.</li>
<li>So how can hardware counters help us make scheduling decisions?
<ul>
<li>With hardware counters, we can (g)estimate what kind of resource(CPU or memory) a thread needs.  The scheduler can use this information to pick a good mix of the threads that are available in the runqueue to schedule in the system so that all of the components of the system are well utilized and the threads interfere with each other as little as possible.</li>
<li>For example, a thread scheduler can look at the number of LLC misses - a metric stored by the hardware counter - and determine that if this number is great enough then the thread is most likely memory bound.</li>
</ul>
</li>
<li>Even though different hardware counters provide different metrics, schedulers can still make informed decisions from them.
<ul>
<li>Schedulers often look at multiple counters across the CPU and can rely on models that have built for a specific platform and that have been trained using some well-understood workloads.</li>
</ul>
</li>
</ul>
<h3 id="scheduling-with-hardware-counters"><a class="markdownIt-Anchor" href="#scheduling-with-hardware-counters"></a> Scheduling with Hardware Counters</h3>
<ul>
<li>Fedorova speculates that a more concrete metric to help determine if a thread is CPU bound or memory bound is <strong>cycles per instruction (CPI)</strong>. A memory bound thread will take a lot of cycles to complete an instruction; therefore, it has a high CPI. A CPU bound thread will have a CPI of 1 (or some low number) as it can complete an instruction every cycle (or close to every cycle).</li>
<li>Given that there is no CPI counter on the processor that Fedorova uses - and computing something like 1 / IPC would require unacceptable software intervention - she uses a simulator.</li>
<li>Testbed: 4 cores x 4-way SMT, total 16 hardware contexts</li>
<li>Workload: CPI of 1, 6, 11, 16
<ul>
<li>1 will be most CPU-intensive, 16: most memory-intensive</li>
<li>4 threads of each kind</li>
</ul>
</li>
<li>Use IPC as the metric. The overall workload, max IPC = 4</li>
<li>
<img src="https://i.imgur.com/HZJlgUR.png" style="width: 600px" />
</li>
<li>CPI Experiment Results
<ul>
<li>
<img src="https://i.imgur.com/WBkCwSw.jpg" style="width: 400px" />
</li>
<li>With mixed CPI =&gt; processor pipeline well utilized =&gt; high IPC</li>
<li>With same CPI =&gt; contention on some cores; wasted cycles on other cores</li>
<li>So mixed CPI is good.</li>
</ul>
</li>
<li>Another question is, is this simulation realistic? The answer is no. Fedorova profiled a number of applications from several respected benchmark suites and computed the CPI values, and got:
<ul>
<li>
<img src="https://i.imgur.com/HqCft2O.jpg" style="width: 600px" />
</li>
<li>You can see most of the values are cluttered together around 2.5-4.5. Since CPI isn’t very different across applications, it may not  be the most instructive metric to inform scheduling decisions.</li>
</ul>
</li>
<li>Post Mortem / The key takeways
<ul>
<li>resource contention in SMTs for processor pipeline</li>
<li>hardware counters can be used to characterize workload</li>
<li>schedulers should be aware of resource contention, not just load balancing</li>
</ul>
</li>
<li>PS: LLC usage would have been a better choice.</li>
</ul>
<h2 id="-"><a class="markdownIt-Anchor" href="#-"></a> ----</h2>
<p>Note from book: Operating Systems Three Easy Pieces by Remzi H Arpaci-Dusseau, Andrea C Arpaci-Dusseau</p>
<h2 id="scheduler-choose-what-to-run"><a class="markdownIt-Anchor" href="#scheduler-choose-what-to-run"></a> Scheduler – choose what to run</h2>
<ul>
<li>
<p><strong>Scheduling Metrics</strong></p>
<ol>
<li>turnaround time – <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mtext>turnaround</mtext></msub><mo>=</mo><msub><mi>T</mi><mtext>complete</mtext></msub><mo>−</mo><msub><mi>T</mi><mtext>arrives</mtext></msub></mrow><annotation encoding="application/x-tex">T_{\text{turnaround}} = T_{\text{complete}} - T_{\text{arrives}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">turnaround</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">complete</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">arrives</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
</ol>
</li>
<li>
<p>Some assumptions about the “workload”(the set of processes that OS needs to run) to simplify the problem:</p>
<ol>
<li>all jobs(processes) arrive at once</li>
<li>just use CPU (no I/O)</li>
<li>running time of each job is known</li>
</ol>
</li>
<li>
<p>Algorithm #1: FIFO</p>
<ul>
<li>Base on the assumption, if we have three jobs: A, B, C, and each takes 10s, then the average turnaround time = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>10</mn><mo>+</mo><mn>20</mn><mo>+</mo><mn>30</mn></mrow><mn>3</mn></mfrac><mo>=</mo><mn>20</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">\frac{10+20+30}{3} = 20s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span><span class="mbin mtight">+</span><span class="mord mtight">20</span><span class="mbin mtight">+</span><span class="mord mtight">30</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">20</span><span class="mord mathnormal">s</span></span></span></span></li>
<li>if B needs 100s, then the average turnaround time = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>10</mn><mo>+</mo><mn>110</mn><mo>+</mo><mn>120</mn></mrow><mn>3</mn></mfrac><mo>=</mo><mn>110</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">\frac{10+110+120}{3} = 110s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span><span class="mbin mtight">+</span><span class="mord mtight">110</span><span class="mbin mtight">+</span><span class="mord mtight">120</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">110</span><span class="mord mathnormal">s</span></span></span></span>.</li>
<li>The problem here is called <strong>convoy effect</strong>, a short job was queued behind a heavyweight job.</li>
</ul>
</li>
<li>
<p>Algorithm #2: SJF(Short Job First)</p>
<ul>
<li>This solves the convoy effect problem because A and B get to run at first, the turnaround time = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>10</mn><mo>+</mo><mn>20</mn><mo>+</mo><mn>120</mn></mrow><mn>3</mn></mfrac><mo>=</mo><mn>50</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">\frac{10+20+120}{3} = 50s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span><span class="mbin mtight">+</span><span class="mord mtight">20</span><span class="mbin mtight">+</span><span class="mord mtight">120</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">50</span><span class="mord mathnormal">s</span></span></span></span>.</li>
<li>What if we relex the assumption #1, and job A and C come after 10s?
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mfrac><mrow><mn>100</mn><mo>+</mo><mo stretchy="false">(</mo><mn>110</mn><mo>−</mo><mn>10</mn><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>120</mn><mo>−</mo><mn>10</mn><mo stretchy="false">)</mo></mrow><mn>3</mn></mfrac><mo>=</mo><mn>103.33</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">T = \frac{100+(110-10)+(120-10)}{3} = 103.33s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">100</span><span class="mbin mtight">+</span><span class="mopen mtight">(</span><span class="mord mtight">110</span><span class="mbin mtight">−</span><span class="mord mtight">10</span><span class="mclose mtight">)</span><span class="mbin mtight">+</span><span class="mopen mtight">(</span><span class="mord mtight">120</span><span class="mbin mtight">−</span><span class="mord mtight">10</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">103.33</span><span class="mord mathnormal">s</span></span></span></span></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Algorithm #3: STCF(Shortest Time-to-Complietion First</p>
<ul>
<li>In this case, even A and C come later after 10s, the CPU will switch to them immediately after they jump in. So, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mfrac><mrow><mo stretchy="false">(</mo><mn>120</mn><mo>−</mo><mn>0</mn><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>20</mn><mo>−</mo><mn>10</mn><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>30</mn><mo>−</mo><mn>10</mn><mo stretchy="false">)</mo></mrow><mn>3</mn></mfrac><mo>=</mo><mn>50</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">T = \frac{(120-0)+(20-10)+(30-10)}{3} = 50s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">120</span><span class="mbin mtight">−</span><span class="mord mtight">0</span><span class="mclose mtight">)</span><span class="mbin mtight">+</span><span class="mopen mtight">(</span><span class="mord mtight">20</span><span class="mbin mtight">−</span><span class="mord mtight">10</span><span class="mclose mtight">)</span><span class="mbin mtight">+</span><span class="mopen mtight">(</span><span class="mord mtight">30</span><span class="mbin mtight">−</span><span class="mord mtight">10</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">50</span><span class="mord mathnormal">s</span></span></span></span>.</li>
</ul>
</li>
<li>
<p>A New Metric for later algorithm comparison: <strong>Response Time</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mtext>response</mtext></msub><mo>=</mo><msub><mi>T</mi><mtext>firstrun</mtext></msub><mo>−</mo><msub><mi>T</mi><mtext>arrival</mtext></msub></mrow><annotation encoding="application/x-tex">T_{\text{response}} = T_{\text{firstrun}} - T_{\text{arrival}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">response</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">firstrun</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">arrival</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
</li>
<li>
<p>Algorithm #4: Round Robin</p>
<ul>
<li>each job gets to run for a <strong>time slice</strong> alternatively.</li>
<li>Then:
<ul>
<li>the average of turnaround time of RR is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>28</mn><mo>+</mo><mn>30</mn><mo>+</mo><mn>110</mn></mrow><mn>3</mn></mfrac><mo>=</mo><mn>56</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">\frac{28+30+110}{3}=56s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">28</span><span class="mbin mtight">+</span><span class="mord mtight">30</span><span class="mbin mtight">+</span><span class="mord mtight">110</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">56</span><span class="mord mathnormal">s</span></span></span></span></li>
<li>And the average of response time of RR is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>0</mn><mo>+</mo><mn>1</mn><mo>+</mo><mn>2</mn></mrow><mn>3</mn></mfrac><mo>=</mo><mn>1</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">\frac{0+1+2}{3} = 1s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mord mathnormal">s</span></span></span></span> but SJC is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>0</mn><mo>+</mo><mn>100</mn><mo>+</mo><mn>110</mn></mrow><mn>3</mn></mfrac><mo>=</mo><mn>70</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">\frac{0+100+110}{3}=70s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mbin mtight">+</span><span class="mord mtight">100</span><span class="mbin mtight">+</span><span class="mord mtight">110</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">70</span><span class="mord mathnormal">s</span></span></span></span> and STCF is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>0</mn><mo>+</mo><mn>10</mn><mo>+</mo><mn>20</mn></mrow><mn>3</mn></mfrac><mo>=</mo><mn>10</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">\frac{0+10+20}{3}=10s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mbin mtight">+</span><span class="mord mtight">10</span><span class="mbin mtight">+</span><span class="mord mtight">20</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span><span class="mord mathnormal">s</span></span></span></span></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Summarize:</p>
<ul>
<li>two types of schedulers:
<ul>
<li>SJF, STCF: good turnaround time, bad response time.</li>
<li>RR: good response time, bad turnaround time.</li>
</ul>
</li>
<li>And still haven’t relexed assumptions: 2, 3</li>
</ul>
</li>
</ul>
<h3 id="scheduling-multi-level-feedback-queue-mlfq"><a class="markdownIt-Anchor" href="#scheduling-multi-level-feedback-queue-mlfq"></a> Scheduling - Multi-level Feedback Queue (MLFQ)</h3>
<ul>
<li>No assumptions, aka: 1) don’t know job length; 2) do I/O as well; 3) workload can be interactive or long-running as background jobs.
<ul>
<li>interactive jobs are short-running and may frequently relinquish the CPU</li>
</ul>
</li>
<li>Used in Windows and Unix(not Linux)</li>
<li>Definition of MLFQ:
<ul>
<li>Create a number of distinct queues, each assigned a different priority level.</li>
<li>At any given time, a job can only be on one queue.</li>
<li>Use priority to decide which job should run at a given time: a job with higher priority is chosen to run.
<ul>
<li>If more than one on the same priority, use round-robin to run them alternatively.</li>
</ul>
</li>
</ul>
</li>
<li>Rules:
<ul>
<li>Rule 1: If Priority(A) &gt; Priority(B), A runs (B doesn’t).</li>
<li>Rule 2: If Priority(A) = Priority(B), A &amp; B run in RR.</li>
<li>Rule 3: When a job enters the system, it is placed at the highest priority (the topmost queue).</li>
<li>Rule 4: Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).
<ul>
<li>e.g. the time slice in Queue 8 is 10ms, and job A only spent 3ms and starts to wait for an I/O. In this case, the job stays in Queue 8 until the I/O gets back and A consumes the entire 10ms before moving it to next level.</li>
</ul>
</li>
<li>Rule 5: After some time period S, move all the jobs in the system to the topmost queue.
<ul>
<li>This is to avoid the problem of <strong>starvation</strong>: too many interactive jobs consumed all CPU times and the long-running jobs never recieve any CPU time.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="scheduling-proportional-share"><a class="markdownIt-Anchor" href="#scheduling-proportional-share"></a> Scheduling - Proportional Share</h3>
<ul>
<li>
<p>Propotional share means: a scheduler trys to guarantee that each job obtain a certain percentage of CPU time. There are three approaches: <strong>lottery scheduling</strong>, <strong>stride scheduling</strong>, and <strong>the Completely Fair Scheduler (CFS)</strong> of Linux.</p>
</li>
<li>
<p>Lottery scheduling</p>
<ul>
<li>
<p>Each process are assigned certain amount of <strong>tickets</strong>, and the scheduler randomly picks a number, and the process holding the number gets scheduled.</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// counter: used to track if we’ve found the winner yet int counter = 0;</span><br><span class="line">// winner: use some call to a random number generator to // get a value, between 0 and the total # of tickets int winner = getrandom(0, totaltickets);</span><br><span class="line">// current: use this to walk through the list of jobs node_t * current = head; while (current) &#123;</span><br><span class="line">counter = counter + current-&gt;tickets;</span><br><span class="line">if (counter &gt; winner)</span><br><span class="line">    break; // found the winner</span><br><span class="line">current = current-&gt;next; &#125; // ’current’ is the winner: schedule it...</span><br></pre></td></tr></table></figure>
<ul>
<li>
<img src="https://i.imgur.com/GHp42Lz.jpg" style="width:500px" />
</li>
</ul>
</li>
<li>
<p>Question 1: how many tickets should we assign to each process?</p>
<ul>
<li>The shares are base on users. For example, we have two Users A and B, A has jobs: A1, A2, B has one job: B1. And the total tickets are 100, then A1 and A2 gets 25 each, and B1 gets 50.</li>
</ul>
</li>
<li>
<p>Question 2: How to calculate the fairness?</p>
<ul>
<li>use <strong>unfaireness metric U</strong>. Assuming two jobs both needs 10s to finish and A finished in 10, and B finished in 20. Then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo>=</mo><mfrac><mn>10</mn><mn>20</mn></mfrac><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">U=\frac{10}{20} = 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">20</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.5</span></span></span></span>. Our goal is to achieve <code>U=1</code>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Stride scheduling - a deterministic fair-share scheduler</p>
<ul>
<li>Each job in the system has a <strong>stride</strong>, which is inverse in proportion to the number of tickets it has. The scheduler then uses the stride and <strong>pass</strong> to determine which process should run next.</li>
<li>The basic idea is simple: at any given time, pick the process to run that has the <strong>lowest pass value</strong> so far; when you run a process, increment its <strong>pass counter</strong> by its stride.</li>
<li>For example, A, B and C have 100, 50 and 250 tickets. Devided 10,000 by each’s stride value, we gets: A: 100, B: 200, C: 40. Then decide which to run as:
<ul>
<li>
<img src="https://i.imgur.com/8tYgG78.jpg" style="width:400px" />
</li>
<li>A B and C all start at 0, so pick A at first. when reaching 100, run B and C in a sequence. Then C has the minimum pass value, the scheduler runs C until it reach 120, then switch to A.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>The Completely Fair Scheduler (CFS) of Linux</p>
<ul>
<li>Fairly divide a CPU evenly among all competing processes. It does so through a simple counting-based technique known as <strong>virtual runtime</strong> (<strong>vruntime</strong>): the amount of time the process has spent on the processor.</li>
<li>Several main configs that the scheduler used:
<ul>
<li>
<p><strong>sched_latency</strong>: The scheduler period is a period of time during which all runnable tasks should be allowed to run at least once. a typical value is 48ms, so if there are 4 processes, the per-process time slice is 12ms.</p>
</li>
<li>
<p><strong>min_granularity</strong>: the minimum time slice of a process. usually 6ms. so if there are more than 8 processes, each will have at least 6ms time slice.</p>
</li>
<li>
<p><strong>weighting(niceness)</strong>: enable control over process priority. CFS maps the <strong>nice</strong> value of each process to a weight, as shown here:</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">static const int prio_to_weight[40] = &#123; </span><br><span class="line">    / * -20 * / 88761, 71755, 56483, 46273, 36291, </span><br><span class="line">    / * -15 * / 29154, 23254, 18705, 14949, 11916, </span><br><span class="line">    / * -10 * / 9548, 7620, 6100, 4904, 3906, </span><br><span class="line">    / * -5 * / 3121, 2501, 1991, 1586, 1277, </span><br><span class="line">    / * 0 * / 1024, 820, 655, 526, 423, </span><br><span class="line">    / * 5 * / 335, 272, 215, 172, 137, </span><br><span class="line">    / * 10 * / 110, 87, 70, 56, 45, </span><br><span class="line">    / * 15 * / 36, 29, 23, 18, 15,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>time</mtext><mi mathvariant="normal">_</mi><msub><mtext>slice</mtext><mi>k</mi></msub><mo>=</mo><mfrac><msub><mtext>weight</mtext><mi>k</mi></msub><mrow><msubsup><mo>∑</mo><mn>0</mn><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mtext>weight</mtext><mi>i</mi></msub></mrow></mfrac><mo>⋅</mo><mtext>sched</mtext><mi mathvariant="normal">_</mi><mtext>latency</mtext></mrow><annotation encoding="application/x-tex">\text{time}\_\text{slice}_k = \frac{\text{weight}_k}{\sum_{0}^{n-1}\text{weight}_i} \cdot  \text{sched}\_\text{latency}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord text"><span class="mord">time</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord"><span class="mord text"><span class="mord">slice</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.6174em;vertical-align:-0.6352em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9822em;"><span style="top:-2.5898em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8575em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span><span style="top:-2.8971em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">weight</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2052em;"><span style="top:-2.2341em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2659em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4961em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">weight</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2302em;"><span style="top:-2.2341em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2659em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6352em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord text"><span class="mord">sched</span></span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord text"><span class="mord">latency</span></span></span></span></span></li>
<li>To improve the efficiency, the scheduler uses <a target="_blank" rel="noopener" href="https://cs.ericyy.me/algorithms-1/week-5/index.html#red-black-bsts">Red-Black Trees</a> with the <strong>vruntime</strong> values of each process and run the <strong>min-vrumtime</strong> process at each time and push it back to the tree after the time slice.</li>
</ul>
</li>
</ul>
</li>
<li>What about I/O and sleeping process?
<ul>
<li>if the process gone for sleeping for a long time, when it wakes up, it might monopolize the CPU for a long time. To avoid this, CFS sets the vruntime of that job to the minimum value that found in the tree.</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>


  <div class="book-comments">
    




  </div>



<script src="/js/book-post.js"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">
  
  <div class="divider"></div>
</div>

  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>


<script src="/js/book-toc.js"></script>

</div>

      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>


<script src="/js/book.js"></script>
