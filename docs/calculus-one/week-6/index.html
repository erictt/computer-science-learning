<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/favicon.png" />
    

    <title>
        
          calculus-one/week-6 - Eric&#39;s CS Notes
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    
<link rel="stylesheet" href="/css/book.css">

    
<script src="/js/book.js"></script>


    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">
    
    <!-- katex -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

<meta name="generator" content="Hexo 4.2.0"></head>

<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/">
    <img src="/favicon.png">
    <span>ERIC&#39;S CS NOTES</span>
  </a>
</div>
    <div class="book-menu">
  <h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2>
<ul>
<li><a href="/symbols/index.html">Symbols of Mathematics</a></li>
<li><a href="/glossary/index.html">Glossary</a></li>
</ul>
<!--
## Stanford Statistical Learning

* [Chapter 2 - Overview of Statistical Learning](/statistical-learning/chapter-2/index.html)
* Chapter 3 - Linear Regression
* Chapter 4 - Classification
* Chapter 5 - Resampling Methods
* Chapter 6 - Linear Model Selection and Regularization
* Chapter 7 - Moving Beyond Linearity
* Chapter 8 - Tree-Based Methods
* Chapter 9 - Support Vector Machines
* Chapter 10 - Unsupervised Learning
-->
<h2 id="introduction-to-probability"><a class="markdownIt-Anchor" href="#introduction-to-probability"></a> Introduction to Probability</h2>
<ul>
<li><a href="/introduction-to-probability/unit-1/index.html">Unit 1: Probability models and axioms</a></li>
<li><a href="/introduction-to-probability/unit-2/index.html">Unit 2: Conditioning and independence</a></li>
<li><a href="/introduction-to-probability/unit-3/index.html">Unit 3: Counting</a></li>
</ul>
<!--
* [Unit 4: Discrete random variables](/introduction-to-probability/unit-4/index.html)
* [Unit 5: Continuous random variables](/introduction-to-probability/unit-5/index.html)
* [Unit 6: Further topics on random variables](/introduction-to-probability/unit-6/index.html)
* [Unit 7: Bayesian inference](/introduction-to-probability/unit-7/index.html)
* [Unit 8: Limit theorems and classical statistics](/introduction-to-probability/unit-8/index.html)
* [Unit 9: Bernoulli and Poisson processes](/introduction-to-probability/unit-9/index.html)
* [Unit 10: Markov chains](/introduction-to-probability/unit-10/index.html)
-->
<h2 id="multivariable-calculus"><a class="markdownIt-Anchor" href="#multivariable-calculus"></a> Multivariable Calculus</h2>
<ul>
<li><a href="/multivariable-calculus/unit-1/index.html">Unit 1: Thinking about multivariable functions</a></li>
<li><a href="/multivariable-calculus/unit-2/index.html">Unit 2: Derivatives of multivariable functions</a></li>
</ul>
<!--
* [Unit 3: Applications of multivariable derivatives](/multivariable-calculus/unit-3/index.html)
* [Unit 4: Integrating multivariable functions](/multivariable-calculus/unit-4/index.html)
* [Unit 5: Green's, Stokes', and the divergence theorems](/multivariable-calculus/unit-5/index.html)
-->
<h2 id="algorithms-part-ii"><a class="markdownIt-Anchor" href="#algorithms-part-ii"></a> Algorithms: Part II</h2>
<ul>
<li><a href="/algorithms-2/week-1/index.html">Week 1 - Undirected Graph &amp; Directed Graph</a></li>
<li><a href="/algorithms-2/week-3/index.html">Week 3 - Maximum Flow and Minimum Cut &amp; Radix Sort</a></li>
<li><a href="/algorithms-2/week-4/index.html">Week 4 - Tries &amp; Substring Search</a></li>
</ul>
<h2 id="algorithms-part-i"><a class="markdownIt-Anchor" href="#algorithms-part-i"></a> Algorithms: Part I</h2>
<ul>
<li><a href="/algorithms-1/week-1/index.html">Week 1 - Union-Find &amp; Analysis of Algorithms</a></li>
<li><a href="/algorithms-1/week-2/index.html">Week 2 - Stacks and Queues &amp; Elementary Sorts</a></li>
<li><a href="/algorithms-1/week-3/index.html">Week 3 - Mergesort &amp; Quicksort</a></li>
<li><a href="/algorithms-1/week-4/index.html">Week 4 - Priority Queues &amp; Elementary Symbols</a></li>
<li><a href="/algorithms-1/week-5/index.html">Week 5 - Balanced Search Trees</a></li>
<li><a href="/algorithms-1/week-6/index.html">Week 6 - Hash Tables</a></li>
</ul>
<h2 id="introduction-to-software-design-and-architecture"><a class="markdownIt-Anchor" href="#introduction-to-software-design-and-architecture"></a> Introduction to Software Design and Architecture</h2>
<ul>
<li><a href="/introduction-to-software-design-and-architecture/design-pattern/index.html">Design Pattern</a></li>
</ul>
<h2 id="calculus-two-sequences-and-series"><a class="markdownIt-Anchor" href="#calculus-two-sequences-and-series"></a> Calculus Two: Sequences and Series</h2>
<ul>
<li><a href="/calculus-two/week-1/index.html">Week 1 - Sequences</a></li>
<li><a href="/calculus-two/week-2/index.html">Week 2 - Series</a></li>
<li><a href="/calculus-two/week-3/index.html">Week 3 - Convergence Tests</a></li>
<li><a href="/calculus-two/week-4/index.html">Week 4 - Alternating Series</a></li>
<li><a href="/calculus-two/week-5/index.html">Week 5 - Power Series</a></li>
<li><a href="/calculus-two/week-6/index.html">Week 6 - Taylor Series</a></li>
</ul>
<h2 id="laff-linear-algebra"><a class="markdownIt-Anchor" href="#laff-linear-algebra"></a> LAFF Linear Algebra</h2>
<ul>
<li><a href="/laff-linear-algebra/week-1/index.html">Week 1 - Vectors in Linear Algebra</a></li>
<li><a href="/laff-linear-algebra/week-2/index.html">Week 2 - Linear Transformations and Matrices</a></li>
<li><a href="/laff-linear-algebra/week-3/index.html">Week 3 - Matrix-Vector Operations</a></li>
<li><a href="/laff-linear-algebra/week-4/index.html">Week 4 - Matrix-Vector to Matrix-Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-5/index.html">Week 5 - Matrix- Matrix Multiplication</a></li>
<li><a href="/laff-linear-algebra/week-6/index.html">Week 6 - Gaussian Elimination</a></li>
<li><a href="/laff-linear-algebra/week-7/index.html">Week 7 - More Gaussian Elimination and Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-8/index.html">Week 8 - More on Matrix Inversion</a></li>
<li><a href="/laff-linear-algebra/week-9/index.html">Week 9 - Vector Spaces</a></li>
<li><a href="/laff-linear-algebra/week-10/index.html">Week 10 - Vector Spaces, Orthogonality, and Linear Least-Squares</a></li>
<li><a href="/laff-linear-algebra/week-11/index.html">Week 11 - Orthogonal Projection, Low Rank Approximation, and Orthogonal Bases</a></li>
<li><a href="/laff-linear-algebra/week-12/index.html">Week 12 - Eigenvalues and Eigenvectors</a></li>
</ul>
<h2 id="stanford-machine-learning"><a class="markdownIt-Anchor" href="#stanford-machine-learning"></a> Stanford Machine Learning</h2>
<ul>
<li><a href="/stanford-machine-learning/week-1/index.html">Week 1 - Introduction</a></li>
<li><a href="/stanford-machine-learning/week-2/index.html">Week 2 - Linear Regression with Multiple Variables</a></li>
<li><a href="/stanford-machine-learning/week-3/index.html">Week 3 - Logistic Regression &amp; Regularization</a></li>
<li><a href="/stanford-machine-learning/week-4/index.html">Week 4 - Neural Networks: Representation</a></li>
<li><a href="/stanford-machine-learning/week-5/index.html">Week 5 - Neural Networks: Learning</a></li>
<li><a href="/stanford-machine-learning/week-6a/index.html">Week 6a - Advice for Applying Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-6b/index.html">Week 6b - Machine Learning System Design</a></li>
<li><a href="/stanford-machine-learning/week-7/index.html">Week 7 - Support Vector Machines</a></li>
<li><a href="/stanford-machine-learning/week-8/index.html">Week 8 - Unsupervised Learning &amp; Dimensionality Reduction</a></li>
<li><a href="/stanford-machine-learning/week-9a/index.html">Week 9a - Anomaly Detection</a></li>
<li><a href="/stanford-machine-learning/week-9b/index.html">Week 9b - Recommender Systems</a></li>
<li><a href="/stanford-machine-learning/week-10/index.html">Week 10 - Large Scale Machine Learning</a></li>
<li><a href="/stanford-machine-learning/week-11/index.html">Week 11 - Application Example: Photo OCR</a></li>
</ul>
<h2 id="calculus-one"><a class="markdownIt-Anchor" href="#calculus-one"></a> Calculus One</h2>
<ul>
<li><a href="/calculus-one/week-2-3/index.html">Week 2-3 - Functions &amp; Limits</a></li>
<li><a href="/calculus-one/week-4/index.html">Week 4 - The Beginning of Derivatives</a></li>
<li><a href="/calculus-one/week-5/index.html">Week 5 - Techniques of Differentiation</a></li>
<li><a href="/calculus-one/week-6/index.html">Week 6 - Chain Rule</a></li>
<li><a href="/calculus-one/week-7/index.html">Week 7 - Derivatives of Trigonometric Functions</a></li>
<li><a href="/calculus-one/week-8/index.html">Week 8 - Derivatives in the Real World</a></li>
<li><a href="/calculus-one/week-9/index.html">Week 9 - Optimization</a></li>
<li><a href="/calculus-one/week-10/index.html">Week 10 - Linear Approximation</a></li>
<li><a href="/calculus-one/week-11-12/index.html">Week 11-12 - Antidifferentiation &amp; Integration</a></li>
<li><a href="/calculus-one/week-13/index.html">Week 13 - Fundamental Theorem of Calculus</a></li>
<li><a href="/calculus-one/week-14/index.html">Week 14 - Substitution Rule</a></li>
<li><a href="/calculus-one/week-15/index.html">Week 15 - Techniques of Integration</a></li>
<li><a href="/calculus-one/week-16/index.html">Week 16 - Applications of Integration</a></li>
</ul>
<h2 id="computational-thinking"><a class="markdownIt-Anchor" href="#computational-thinking"></a> Computational Thinking</h2>
<ul>
<li><a href="/computational-thinking/lecture-1/index.html">Lecture 1 - Optimization and Knapsack Problem</a></li>
<li><a href="/computational-thinking/lecture-2/index.html">Lecture 2 - Decision Trees and Dynamic Programming</a>
<ul>
<li><a href="/computational-thinking/lecture-2-powerset/index.html">Exercise: Power Set Function</a></li>
</ul>
</li>
<li><a href="/computational-thinking/lecture-3/index.html">Lecture 3 - Graphs</a></li>
<li><a href="/computational-thinking/lecture-4-5/index.html">Lecture 4-5 - Plotting</a></li>
<li><a href="/computational-thinking/lecture-6-7/index.html">Lecture 6-7 - Stochastic Programs &amp; Inferential Statistics</a></li>
<li><a href="/computational-thinking/lecture-8/index.html">Lecture 8 - Monte Carlo Simulation</a></li>
<li><a href="/computational-thinking/lecture-9/index.html">Lecture 9 - Sampling and Standard Error</a></li>
<li><a href="/computational-thinking/lecture-10-11/index.html">Lecture 10-11 - Experimental Data</a></li>
<li><a href="/computational-thinking/lecture-12/index.html">Lecture 12 - Machine Learning</a></li>
<li><a href="/computational-thinking/lecture-13/index.html">Lecture 13 - Statistical Abuses</a></li>
</ul>
<h2 id="effective-thinking-through-mathematics"><a class="markdownIt-Anchor" href="#effective-thinking-through-mathematics"></a> Effective Thinking Through Mathematics</h2>
<ul>
<li><a href="/effective-thinking-through-mathematics/note/index.html">Note</a></li>
<li><a href="/effective-thinking-through-mathematics/week-4-telling-the-story-of-infinity/index.html">Week 4 (/Telling the Story of Infinity)</a></li>
<li><a href="/effective-thinking-through-mathematics/week-5-telling-the-story-of-the-euler-circuit-theorem/index.html">Week 5 (/Telling the Story of Euler Circuit Theorem)</a></li>
</ul>
<h2 id="cs50-introduction-to-computer-science"><a class="markdownIt-Anchor" href="#cs50-introduction-to-computer-science"></a> CS50 Introduction to Computer Science</h2>
<ul>
<li><a href="/cs50/week-1/index.html">Week 1 - C</a></li>
<li><a href="/cs50/week-2/index.html">Week 2 - Arrays</a></li>
<li><a href="/cs50/week-3/index.html">Week 3 - Algorithms</a></li>
<li><a href="/cs50/week-4/index.html">Week 4 - Memory</a></li>
<li><a href="/cs50/week-5/index.html">Week 5 - Data Structures</a></li>
<li><a href="/cs50/week-6/index.html">Week 6 - HTTP</a></li>
<li><a href="/cs50/week-7-10/index.html">Week 7-10 - Machine Learning/Python/SQL/Javascript</a></li>
</ul>

</div>


<script src="/js/book-menu.js"></script>

  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1 id="week-6-chain-rule"><a class="markdownIt-Anchor" href="#week-6-chain-rule"></a> Week 6 - Chain Rule</h1>
<h2 id="differentiation-rules"><a class="markdownIt-Anchor" href="#differentiation-rules"></a> Differentiation Rules</h2>
<h3 id="the-chain-rule"><a class="markdownIt-Anchor" href="#the-chain-rule"></a> The Chain Rule</h3>
<ul>
<li>Definition
<ul>
<li>If <code>g</code> is differentiable at <code>x</code> and <code>f</code> is differentiable at <code>g(x)</code>, then the composite function \(F = f \circ g\) defined by \(F(x) = f(g(x))\) is differentiable at <code>x</code> and <code>F'</code> is given by the product \[F’(x)=f’(g(x)) \cdot g’(x)\]</li>
</ul>
</li>
</ul>
<h3 id="implicit-differentiation"><a class="markdownIt-Anchor" href="#implicit-differentiation"></a> Implicit Differentiation</h3>
<ul>
<li>
<p>This consists of differentiating both sides of the equation with respect to <code>x</code> and then solving the resulting equation for <code>y'</code>.</p>
</li>
<li>
<p>Sample 1: \(x<sup>2+y</sup>2=25\), find \(\frac{d}{dx}y\), and the tangent to the circle at point <code>(3, 4)</code>.</p>
<ul>
<li>
<img src="https://i.imgur.com/MzPu9NF.jpg" style="width:400px" />
  * \\[\begin{aligned}
      \frac{d}{dx}(x^2+y^2) &= \frac{d}{dx}(25) \\
      \frac{d}{dx}(x^2) + \frac{d}{dx}(y^2) &= 0 \\
      2x + 2y \cdot \frac{d}{dx}y &= 0 \\
      \frac{d}{dx}y &= -\frac{x}{y}
    \end{aligned}\\]
  * PS: `y` is a function of `x` and using the Chain Rule, we have \\[\frac{d}{dx}(y^2) = \frac{d}{dy}(y^2) \cdot \frac{d}{dx}y = 2y\frac{d}{dx}y\\]
</li>
<li>At the point <code>(3, 4)</code> we have <code>x = 3</code> and <code>y = 4</code>, so \[\frac{d}{dx}y = -\frac{3}{4}\]</li>
</ul>
</li>
<li>
<p>Sample 2: \(x<sup>3+y</sup>3=axy\) (<strong>folium of Descartes</strong>)</p>
<ul>
<li>\(x<sup>3+y</sup>3=6xy\), find \(\frac{d}{dx}y\)</li>
<li>
<img src="https://i.imgur.com/LKMBPBb.jpg" style="width:150px" />
</li>
<li>\[\begin{aligned}<br />
3x^2 + 3y^2y’ &amp;= 6xy’ + 6y \<br />
x^2 + y^2y’ &amp;= 2xy’ + 2y \<br />
(y^2 - 2x)y’ &amp;= 2y - x^2 \<br />
y’ &amp;= \frac{2y - x<sup>2}{y</sup>2 - 2x}<br />
\end{aligned}\]</li>
</ul>
</li>
</ul>
<h3 id="derivatives-of-inverse-function"><a class="markdownIt-Anchor" href="#derivatives-of-inverse-function"></a> Derivatives of Inverse Function</h3>
<ul>
<li>If <code>f</code> is a differentiable function, and <code>f'</code> is continuous, and \(f’(a) \ne 0\), then
<ul>
<li>\(f^{-1}(y)\) is defined for <code>y</code> near <code>f(a)</code>, \(f^{-1}\) is differentiable near <code>f(a)</code>, \((f^{-1})’\) is continuous near <code>f(a)</code>, and \[(f<sup>{-1})’(y)=\frac{1}{f’(f</sup>{-1}(y))}\]</li>
</ul>
</li>
<li>Sample:<br />
\[\begin{aligned}<br />
f(x) &amp;= x^2\ (x&gt;0),\ f’(x) = 2x \<br />
f^{-1}(x) &amp;= \sqrt{x} \<br />
(f^{-1})’(x) &amp;= \frac{1}{f’(f^{-1}(x))} = \frac{1}{f’(\sqrt{x})} = \frac{1}{2\sqrt{x}}<br />
\end{aligned}\]</li>
</ul>
<h3 id="derivatives-of-logarithmic-functions"><a class="markdownIt-Anchor" href="#derivatives-of-logarithmic-functions"></a> Derivatives of Logarithmic Functions</h3>
<ul>
<li>Sample 1:<br />
\[\begin{aligned}<br />
f(x) &amp;= e^x,\ f’(x) = e^x \text{(proved in the end of week 5)} \<br />
f^{-1}(x) &amp;= \log{x} \<br />
(f^{-1})’(x) &amp;= \frac{1}{f’(f^{-1}(x))} = \frac{1}{f’(\log{x})} = \frac{1}{e^{\log{x}}} \<br />
&amp;= \frac{1}{x}<br />
\end{aligned}\]</li>
<li>Sample 2:<br />
\[\begin{aligned}<br />
f(x) &amp;= \log_{b}{x} \<br />
f’(x) &amp;= \frac{d}{dx}\frac{\log{x}}{\log{b}} = \frac{1}{\log{b}} \cdot \frac{d}{dx}\log{x} = \frac{1}{\log{b}} \cdot \frac{1}{x} \<br />
&amp;= \frac{1}{x \cdot \log{b}}<br />
\end{aligned}\]</li>
<li>Sample 3:<br />
\[\begin{aligned}<br />
f(x) &amp;= b^x \<br />
&amp;= (e<sup>{\log{b}})</sup>x = e^{\log{b} \cdot x} \<br />
f’(x) &amp;= e^{\log{b} \cdot x} \cdot \frac{d}{dx}(\log{b} \cdot x)\ \text{(chain rules)} \<br />
&amp;= (e<sup>{\log{b}})</sup>{\cdot x} \cdot \log{b} \<br />
&amp;= b^x \cdot \log{b}<br />
\end{aligned}\]</li>
</ul>
<h4 id="logarithmic-differentiation"><a class="markdownIt-Anchor" href="#logarithmic-differentiation"></a> Logarithmic Differentiation</h4>
<ul>
<li>The calculation of derivatives of complicated functions involving products, quotients, or powers can often be simplified by taking logarithms.</li>
<li>Sample: Differentiate \(f(x)=\frac{(1+x<sup>2)</sup>5 \cdot (1+x<sup>3)</sup>8}{(1+x<sup>4)</sup>7}\),<br />
\[\begin{aligned}<br />
y &amp;= \frac{(1+x<sup>2)</sup>5 \cdot (1+x<sup>3)</sup>8}{(1+x<sup>4)</sup>7} \<br />
\log{y} &amp;= \log{\frac{(1+x<sup>2)</sup>5 \cdot (1+x<sup>3)</sup>8}{(1+x<sup>4)</sup>7}} \<br />
\frac{d}{dx}\log{y} &amp;= \frac{d}{dx}\log{\frac{(1+x<sup>2)</sup>5 \cdot (1+x<sup>3)</sup>8}{(1+x<sup>4)</sup>7}} \<br />
\frac{d}{dx}\log{y} &amp;= \frac{d}{dx}(5\log{(1+x^2)} + 8\log{(1+x^3)} - 7\log{(1+x^4)}) \<br />
\frac{1}{y} \cdot \frac{d}{dx}y &amp;= 5\frac{d}{dx}\log{(1+x^2)} + 8\frac{d}{dx}\log{(1+x^3)} - 7\frac{d}{dx}\log{(1+x^4)} \<br />
\frac{1}{y} \cdot \frac{d}{dx}y &amp;= 5\frac{2x}{1+x^2} + 8\frac{3x<sup>2}{1+x</sup>3} - 7\frac{4x<sup>3}{1+x</sup>4} \<br />
\frac{d}{dx}y &amp;= (5\frac{2x}{1+x^2} + 8\frac{3x<sup>2}{1+x</sup>3} - 7\frac{4x<sup>3}{1+x</sup>4}) \cdot \frac{(1+x<sup>2)</sup>5 \cdot (1+x<sup>3)</sup>5}{(1+x<sup>4)</sup>7}\<br />
\end{aligned}\]</li>
</ul>
<h2 id="justify-the-derivative-rules"><a class="markdownIt-Anchor" href="#justify-the-derivative-rules"></a> Justify the Derivative Rules</h2>
<h3 id="the-power-rule"><a class="markdownIt-Anchor" href="#the-power-rule"></a> The Power Rule</h3>
<ul>
<li>\(\frac{d}{dx}x<sup>{-n}=-nx</sup>{-n-1}\)
<ul>
<li>Before, the power rule only apply for the real numbers, this formula apply for all rational numbers.</li>
</ul>
</li>
<li>Use chain rules to find the derivative of \(f(x)=\frac{1}{x^n}\) :
<ul>
<li>First use the limit theorem to find the derivative of \(f(x)=\frac{1}{x}\):<br />
\[\begin{aligned}<br />
\frac{d}{dx}\frac{1}{x} &amp;= \lim_{h \to 0}\frac{\frac{1}{x+h}-\frac{1}{x}}{h} \<br />
&amp;= \lim_{h \to 0}\frac{\frac{x-h-x}{x(x+h)}}{h} \<br />
&amp;= \lim_{h \to 0}\frac{\frac{-h}{x(x+h)}}{h} \<br />
&amp;= \lim_{h \to 0}\frac{-1}{x(x+h)} \<br />
&amp;= -\frac{1}{x^2} \<br />
\end{aligned}\]</li>
<li>Then use chain rules to find the derivative of \(f(x)=\frac{1}{x^n}\):<br />
\[\begin{aligned}<br />
\frac{d}{dx}\frac{1}{x^n} &amp;= - \frac{1}{(x<sup>n)</sup>2} \cdot \frac{d}{dx}x^n \<br />
&amp;= - \frac{1}{(x<sup>n)</sup>2} \cdot nx^{n-1} \<br />
&amp;= - nx^{-2n+n-1} \<br />
&amp;= - nx^{-n-1}<br />
\end{aligned}\]</li>
</ul>
</li>
<li>Sample: Differentiate \(y=x^{\sqrt{2}},\ (x&gt;0)\), \[\begin{aligned}<br />
\log{y} &amp;= \log{x^{\sqrt{2}}} \<br />
\frac{d}{dx}\log{y} &amp;= \frac{d}{dx}\log{x^{\sqrt{2}}} \<br />
\frac{1}{y} \cdot \frac{d}{dx}y &amp;= \frac{d}{dx}\sqrt{2}\log{x} \<br />
\frac{1}{x^{\sqrt{2}}} \cdot \frac{d}{dx}y &amp;= \sqrt{2} \cdot \frac{1}{x} \<br />
\frac{d}{dx}y &amp;= \sqrt{2} \cdot \frac{1}{x} \cdot x^{\sqrt{2}} \<br />
\frac{d}{dx}y &amp;= \sqrt{2} \cdot x^{\sqrt{2}-1} \<br />
\end{aligned}\]</li>
</ul>
<h3 id="the-product-rule"><a class="markdownIt-Anchor" href="#the-product-rule"></a> The Product Rule</h3>
<ul>
<li>Use logarithms to prove:<br />
\[\begin{aligned}<br />
f(x) &amp;&gt; 0,\ g(x) &gt; 0, \<br />
\log(f(x)g(x)) &amp;= \log(f(x)) + \log(g(x)) \<br />
\frac{d}{dx} \log(f(x)g(x)) &amp;= \frac{d}{dx} \log(f(x)) + \frac{d}{dx} \log(g(x)) \<br />
\frac{1}{f(x)g(x)} \cdot \frac{d}{dx}f(x)g(x) &amp;= \frac{1}{f(x)} \cdot \frac{d}{dx}f(x) + \frac{1}{g(x)} \cdot \frac{d}{dx}g(x) \<br />
\frac{d}{dx}f(x)g(x) &amp;= g(x) \cdot \frac{d}{dx}f(x) + f(x) \cdot \frac{d}{dx}g(x)<br />
\end{aligned}\]</li>
</ul>
<h3 id="the-quotient-rule"><a class="markdownIt-Anchor" href="#the-quotient-rule"></a> The Quotient Rule</h3>
<ul>
<li>
<p>First we need to calculate the derivative of \(\frac{1}{g(x)}\) :<br />
\[\begin{aligned}<br />
\text{we have proved this:} f(x) &amp;= \frac{1}{x},\ f’(x) = -\frac{1}{x^2} \<br />
so,\ \frac{d}{dx}\frac{1}{g(x)} &amp;= - \frac{1}{(g(x))^2} \cdot g’(x)<br />
\end{aligned}\]</p>
</li>
<li>
<p>Then: \[\begin{aligned}<br />
\frac{d}{dx}\frac{f(x)}{g(x)} &amp;= \frac{d}{dx}(f(x) \cdot \frac{1}{g(x)}) \<br />
&amp;= f’(x) \cdot \frac{1}{g(x)} + f(x) \cdot (- \frac{1}{(g(x))^2} \cdot g’(x)) \<br />
&amp;= \frac{f’(x) \cdot g(x) -  f(x) \cdot g’(x)}{(g(x))^2} \<br />
\end{aligned}\]</p>
</li>
</ul>
<h3 id="proof-the-chain-rule"><a class="markdownIt-Anchor" href="#proof-the-chain-rule"></a> Proof the Chain Rule</h3>
<ul>
<li><strong>Recall</strong> If <code>y = f(x)</code> and <code>x</code> changes from <code>a</code> to <code>a + ∆x</code>, we define the increment of <code>y</code> as<br />
\[\Delta y = f(a+\Delta x)-f(a)\].<br />
According to the definition of a derivative, we have<br />
\[\lim_{\Delta x \to o}\frac{\Delta y}{\Delta x}=f’(a)\]. So if we denote by \(\epsilon\) the difference between the difference quotient and the derivative, we obtain<br />
\[\lim_{\Delta x \to 0}\epsilon = \lim_{\Delta x \to 0}(\frac{\Delta y}{\Delta x}-f’(a)) = f’(a)-f’(a) = 0\].<br />
But<br />
\[\epsilon = \frac{\Delta y}{\Delta x}-f’(a)\ \Rightarrow \Delta y = f’(a)\Delta x + \epsilon \Delta x\ \].<br />
If we define \(\epsilon\) to be 0 when <code>∆x = 0</code>, then \(\epsilon\) become a continuous function of <code>∆x</code>. Thus, for a differentiable function <code>f</code>, we can write<br />
\[\Delta y = f’(a)\Delta x + \epsilon \Delta x \text{ where } \epsilon \to 0\ as\ \Delta x \to 0\]<br />
and \(\epsilon\) is a continuous function of <code>∆x</code>. This property of differentiable functions is what enables us to prove the Chain Rule.</li>
<li><strong>Now to Prove</strong>: Suppose <code>u=g(x)</code> is differentiable at <code>a</code> and <code>y=f(u)</code> is differentiable at <code>b=g(a)</code>, If <code>∆x</code> is an increment in <code>x</code> and <code>∆u</code> and   <code>∆y</code> are corresponding increments in <code>u</code> and <code>y</code>, then we can use last equation to write<br />
\[\Delta u = g’(a)\Delta x + \epsilon_1\Delta x = (g’(a) + \epsilon_1)\Delta x\]<br />
where \(\epsilon_1 \to 0\) as \(\Delta x \to 0\).<br />
Similarly<br />
\[\Delta y = f’(b)\Delta u + \epsilon_2\Delta u = (f’(b) + \epsilon_2)\Delta u\]<br />
where \(\epsilon_2 \to 0\) as \(\Delta x \to 0\). If we now substitute the expression for <code>∆u</code>, we get<br />
\[\Delta y = [f’(b) + \epsilon_2][g’(a) + \epsilon_1]\Delta x\], so \[\frac{\Delta y}{\Delta x} = [f’(b) + \epsilon_2][g’(a) + \epsilon_1]\]<br />
As \(\Delta x \to 0\). So both \(\epsilon_2 \to 0\) and \(\epsilon_1 \to 0\) as \(\Delta x \to 0\). Therefore<br />
\[\begin{aligned}<br />
\frac{dy}{dx} &amp;= \lim_{\Delta x \to 0}\frac{\Delta y}{\Delta x} =   \lim_{\Delta x \to 0}[f’(b) + \epsilon_2][g’(a) + \epsilon_1] \<br />
&amp;= f’(b)g’(a) = f’(g(a))g’(a)<br />
\end{aligned}\].<br />
This prove the <strong>Chain Rule</strong>.</li>
</ul>

</div>


  <div class="book-comments">
    




  </div>



<script src="/js/book-post.js"></script>

        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">

  <div class="author">

    <!-- Author image -->
    <div class="author-img">
      
        <figure
          class="avatar avatar-lg"
          data-initial="E"
          style="background-color: #3b4351;">
        </figure>
      
    </div>

    <!-- Author title -->
    <div class="author-title">
      <div>Eric Yang</div>
      <div>2020-04-13</div>
    </div>
  </div>

  

  <div class="divider"></div>
</div>
  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>


<script src="/js/book-toc.js"></script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "\\(", right: "\\)", display: false},
                {left: "\\[", right: "\\]", display: true}
            ]
        });
    });
</script>

</div>

      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>


<script src="/js/book.js"></script>
